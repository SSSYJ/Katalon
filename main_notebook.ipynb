{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f3f7f86-6a9a-4a22-9f69-d3a58385512c",
   "metadata": {},
   "source": [
    "# Main Translation Pipeline Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd8adf7-fcdb-4f85-9f63-6ee3a5be14b7",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9af5fc5b-1647-49a6-8d51-c3aa781a1af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download/install required packages\n",
    "# !pip install openpyxl\n",
    "# !pip install transformers\n",
    "# !pip install allennlp\n",
    "# !pip install allennlp-models\n",
    "# !pip install --upgrade google-cloud-storage\n",
    "# !pip install cached-path==1.1.2\n",
    "# !pip install spacy\n",
    "# !python -m spacy download en_core_web_md\n",
    "# !pip install regex\n",
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install nltk\n",
    "# !pip install flair\n",
    "# !pip install Levenshtein\n",
    "# !pip install tqdm\n",
    "# !pip install torch\n",
    "# !pip install sklearn\n",
    "#!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "971529c1-8642-4a13-9b16-5c9ef4001643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other imports\n",
    "import pickle as pkl\n",
    "from collections import *\n",
    "import Levenshtein\n",
    "import spacy\n",
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizerFast, BertForTokenClassification\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import SGD\n",
    "from tqdm import tqdm\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b39b0d03-727a-414b-a290-d0020c00936c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions from utility modules\n",
    "from util.data_preprocess import align_scripts\n",
    "from util.data_preprocess import segregate_test_cases\n",
    "from util.data_preprocess.process_steps import process_steps\n",
    "from util.parsing.frame_parser import FrameParser\n",
    "from util.script_generation.script_generation import generate_script\n",
    "from util.evaluation.evaluator import preprocess_test_case\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from util.evaluation.evaluator import SmoothingFunction\n",
    "from util.evaluation.evaluator import BLEU_evaluation \n",
    "from util.evaluation.evaluator import f1_score\n",
    "from util.evaluation.evaluator import f1_evaluation\n",
    "from util.evaluation.evaluator import groovy_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64927b9e-dc1b-4f2b-b47a-204f7234d15f",
   "metadata": {},
   "source": [
    "## **Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518583a9-bcb1-4b45-9d3c-4dcc55858104",
   "metadata": {},
   "source": [
    "### 1) Load-in data and align scripts with the test cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9500ecc4-2f86-4894-8e61-4c74bf5e90c7",
   "metadata": {},
   "source": [
    "#### Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f126e86f-5df1-4964-a725-435e46f6e91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases_df = pd.read_excel('data/Katalon Capstone - Manual Test Cases.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4ab2ea-61b8-4031-bae0-90f89eb2460e",
   "metadata": {},
   "source": [
    "#### Align scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "623058f0-1caa-4b9d-a232-667d0089cf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases_df = align_scripts.align_scripts(test_cases_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa642e1e-acde-4d1a-9cd8-3d4c9042320d",
   "metadata": {},
   "source": [
    "#### Convert dataframe to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0945df9f-2fad-4118-9881-9bfad5847f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases_df.to_csv('data/test_cases_with_scripts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fc8a45-901c-4985-9744-ab1ce5939551",
   "metadata": {},
   "source": [
    "### 2) Extract and save manual test case steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ba2fd0-df1d-43f1-b267-fffa5c2d82aa",
   "metadata": {},
   "source": [
    "#### Load in updated dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f34ef8d7-fe82-40f1-bad3-036f61b32daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases_with_scripts_df = pd.read_csv('data/test_cases_with_scripts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcd800d-f665-409c-a9c6-badf803eea6a",
   "metadata": {},
   "source": [
    "#### Segregate steps, pre_conditions and expected results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "952d79a9-7957-446d-96ac-b7bf03b02f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_conditions, steps, expected_results = segregate_test_cases.process_test_cases(test_cases_with_scripts_df['Full manual test cases'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c13dbe32-7dcd-41f7-8a78-2bbe7e49de95",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases_with_scripts_df['pre_conditions'] = pre_conditions\n",
    "test_cases_with_scripts_df['steps'] = steps\n",
    "test_cases_with_scripts_df['expected_results'] = expected_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f17092d-5d32-41b6-a600-f4e3749b866c",
   "metadata": {},
   "source": [
    "#### Process steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75cb47b1-eae5-423b-a1ed-ad6795dbade1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tc_df = pd.read_excel('data/new_tc.xlsx', header=1, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d61fae8d-3ccc-413e-b774-7e1c5fd9b890",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_list = process_steps(new_tc_df['New Test Cases'].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5259946d-4b04-4471-9323-aeb122da0ecb",
   "metadata": {},
   "source": [
    "#### Remove null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50003ae1-2017-47ba-8f0a-ea98a134d467",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_steps = []\n",
    "for steps in steps_list:\n",
    "    # remove null values\n",
    "    if isinstance(steps, float):\n",
    "        continue\n",
    "    else:\n",
    "        updated_steps.append(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cdc78c-dbe4-4835-aeae-7d45301dd3de",
   "metadata": {},
   "source": [
    "#### Save updated_steps as a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6534dd21-5fdd-4152-8417-a3beba59fbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickle_files/pickle_files_for_parsing/steps_updated.pkl', 'wb') as handle:\n",
    "    pkl.dump(updated_steps, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72952cc-81ec-4554-8e4d-4dffb84bb167",
   "metadata": {},
   "source": [
    "#### Get pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9cc31e6-f008-471d-a941-1fe6034f9e0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pages_list = test_cases_with_scripts_df['Feature'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be8121f-aaa7-49cb-aa83-3380b6a7bf1d",
   "metadata": {},
   "source": [
    "#### Remove values where rewritten test cases are null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "262d127d-bca8-49e6-a935-e52f184fc1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_pages = []\n",
    "for idx, page in enumerate(pages_list):\n",
    "    if isinstance(new_tc_df.iloc[idx]['New Test Cases'], float):\n",
    "        continue\n",
    "    else:\n",
    "        updated_pages.append(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc016220-c73a-4f58-bb25-8bb2fc1f8912",
   "metadata": {},
   "source": [
    "#### Save updated_pages as a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f6ba276-3e0f-4bf3-aef4-eba28b9e9e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickle_files/pickle_files_for_parsing/pages.pkl', 'wb') as handle:\n",
    "    pkl.dump(updated_pages, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024c8ddf-8cb1-4790-98e2-3b451f5d477e",
   "metadata": {},
   "source": [
    "## **Tagging**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d92fe8-e4c5-46be-8b63-715aec3d0901",
   "metadata": {},
   "source": [
    "### 1) Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341ec39e-dddb-4b17-9ef3-4be8192c1cf6",
   "metadata": {},
   "source": [
    "#### Load in annotated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e3a206d-dfde-4d89-83f1-370e2fadb6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_file_path = 'data/anno_14_tc.csv'\n",
    "df = pd.read_csv(annotated_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be4396c-ed69-4058-a094-b83aaf15ac63",
   "metadata": {},
   "source": [
    "#### Reformat Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1ac3bdc-4bfa-4d4f-bc8c-89c883bb9c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sents -- list of tuples (sentence, tags)\n",
    "sents = []\n",
    "current_sent, current_tags = [], []\n",
    "for idx, row in df.iterrows():\n",
    "    word, tag = row['Word'], row['IOB-tag']\n",
    "    if tag == '*':\n",
    "        if len(current_sent) > 0:\n",
    "            sents.append((current_sent, current_tags))\n",
    "            current_sent, current_tags = [], []\n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        current_sent.append(word)\n",
    "        current_tags.append(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddc6cb8-1666-471c-93c6-033e5d1857de",
   "metadata": {},
   "source": [
    "#### Build tag-id dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "312fe1fe-701f-4c1a-98b8-3ff4bc4cc110",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tags = df['IOB-tag'].values.tolist()\n",
    "unique_tags = set(all_tags) - set('*')\n",
    "\n",
    "tags2ids = {k: v for v, k in enumerate(sorted(unique_tags))}\n",
    "ids2tags = {v: k for v, k in enumerate(sorted(unique_tags))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b4442f-d4b3-43e0-8396-2bfae042b057",
   "metadata": {},
   "source": [
    "#### Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df620f55-a418-41c9-8e53-5dc50003e094",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = max(len(sent) for sent, _ in sents)\n",
    "LEARNING_RATE = 1e-2\n",
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4552c33c-96ba-45c0-b904-7020c1fa7d56",
   "metadata": {},
   "source": [
    "### 2) Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a41b49-f4b0-4658-9612-5411b0e9221a",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3504f07-031a-4bb3-8531-020409bff4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e5258b-ac9f-40a5-9872-2c8093b098e9",
   "metadata": {},
   "source": [
    "#### Align tags to tokenized texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc014543-4d34-4c4b-a82a-83923d548cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_label(texts, labels):\n",
    "    tokenized_inputs = tokenizer(texts, padding='max_length', max_length=MAX_LENGTH)\n",
    "\n",
    "    word_ids = tokenized_inputs.word_ids()\n",
    "\n",
    "    previous_word_idx = None\n",
    "    label_ids = []\n",
    "\n",
    "    for word_idx in word_ids:\n",
    "\n",
    "        if word_idx is None:\n",
    "            label_ids.append(-100)\n",
    "\n",
    "        elif word_idx != previous_word_idx:\n",
    "            try:\n",
    "                label_ids.append(tags2ids[labels[word_idx]])\n",
    "            except:\n",
    "                label_ids.append(-100)\n",
    "        else:\n",
    "            try:\n",
    "                label_ids.append(tags2ids[labels[word_idx]])\n",
    "            except:\n",
    "                label_ids.append(-100)\n",
    "        previous_word_idx = word_idx\n",
    "\n",
    "    return label_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e652d4b-7fd2-4aa3-aa48-a7fd7866f666",
   "metadata": {},
   "source": [
    "#### Data class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "708726a7-84b3-48de-abf7-ea11093be8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSequence(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, tagged_sents):\n",
    "        self.sents = [' '.join(sent) for sent, _ in tagged_sents]\n",
    "        self.tags = [tags for _, tags in tagged_sents]\n",
    "        self.texts = [tokenizer(' '.join(sent), padding='max_length', max_length = MAX_LENGTH, return_tensors=\"pt\") for sent, _ in tagged_sents]\n",
    "        self.labels = [align_label(' '.join(sent), tag) for sent, tag in tagged_sents]\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_data(self, idx):\n",
    "\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "\n",
    "        return torch.LongTensor(self.labels[idx])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_data = self.get_batch_data(idx)\n",
    "        batch_labels = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512c4fa3-abe2-4abc-a1c2-7c077349b54a",
   "metadata": {},
   "source": [
    "#### Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3310e97a-b189-499c-a6e9-e53814851578",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, dev_set = train_test_split(sents, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118a8a22-66a5-4909-a063-779a01f53473",
   "metadata": {},
   "source": [
    "### 3) Build Tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a232172b-1048-4ca0-a349-87e490326b5e",
   "metadata": {},
   "source": [
    "#### Load pre-trained BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df587bee-d8da-4ce4-b7f8-ed1f539ea43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(BertModel, self).__init__()\n",
    "\n",
    "        self.bert = BertForTokenClassification.from_pretrained('bert-base-cased', num_labels=len(unique_tags))\n",
    "\n",
    "    def forward(self, input_id, mask, label):\n",
    "\n",
    "        output = self.bert(input_ids=input_id, attention_mask=mask, labels=label, return_dict=False)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84aa6bd-2323-404b-bc07-58ac1a72df00",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a066813d-973f-4037-be5a-1f19d6d90b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sys_spacy_data, gold_spacy_data):\n",
    "    precision, recall, fscore = 0, 0, 0\n",
    "\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "\n",
    "    for sys_ex, gold_ex in zip(sys_spacy_data, gold_spacy_data):\n",
    "        gold_annotations = set([tuple(e) for e in gold_ex])\n",
    "        sys_annotations = set([tuple(e) for e in sys_ex])\n",
    "\n",
    "        tp += len(sys_annotations.intersection(gold_annotations))\n",
    "        fp += len(sys_annotations.difference(gold_annotations))\n",
    "        fn += len(gold_annotations.difference(sys_annotations))\n",
    "\n",
    "    if tp != 0:\n",
    "        recall = (tp/(tp+fn)) * 100\n",
    "        precision = (tp/(tp+fp)) * 100\n",
    "        fscore = 2*recall*precision/(recall+precision)\n",
    "\n",
    "    return precision, recall, fscore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99726e4e-d611-4d67-9a75-923aa9df0952",
   "metadata": {},
   "source": [
    "#### Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ffda31c-fbcc-4aa2-8e96-d5ba35405191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict tags for sentences\n",
    "def align_word_ids(texts):\n",
    "    tokenized_inputs = tokenizer(texts, padding='max_length', max_length=MAX_LENGTH)\n",
    "\n",
    "    word_ids = tokenized_inputs.word_ids()\n",
    "\n",
    "    previous_word_idx = None\n",
    "    label_ids = []\n",
    "\n",
    "    for word_idx in word_ids:\n",
    "\n",
    "        if word_idx is None:\n",
    "            label_ids.append(-100)\n",
    "\n",
    "        elif word_idx != previous_word_idx:\n",
    "            try:\n",
    "                label_ids.append(1)\n",
    "            except:\n",
    "                label_ids.append(-100)\n",
    "        else:\n",
    "            label_ids.append(-100)\n",
    "        previous_word_idx = word_idx\n",
    "\n",
    "    return label_ids\n",
    "\n",
    "\n",
    "def predict(model, sentence):\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    text = tokenizer(sentence, padding='max_length', max_length=MAX_LENGTH, return_tensors=\"pt\")\n",
    "\n",
    "    mask = text['attention_mask'][0].unsqueeze(0).to(device)\n",
    "\n",
    "    input_id = text['input_ids'][0].unsqueeze(0).to(device)\n",
    "    label_ids = torch.Tensor(align_word_ids(sentence)).unsqueeze(0).to(device)\n",
    "\n",
    "    logits = model(input_id, mask, None)\n",
    "    logits_clean = logits[0][label_ids != -100]\n",
    "\n",
    "    predictions = logits_clean.argmax(dim=1).tolist()\n",
    "    prediction_label = [ids2tags[i] for i in predictions]\n",
    "    return prediction_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935b7364-7764-4d63-ac3a-f1f6b6b95387",
   "metadata": {},
   "source": [
    "### 4) Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "487afff8-529f-48be-bca2-17a52431987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, train_set, dev_set):\n",
    "\n",
    "    train_dataset = DataSequence(train_set)\n",
    "    dev_dataset = DataSequence(dev_set)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, num_workers=4, batch_size=1, shuffle=True)\n",
    "    dev_dataloader = DataLoader(dev_dataset, num_workers=4, batch_size=1)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    optimizer = SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    best_acc = 0\n",
    "    best_loss = 1000\n",
    "\n",
    "    for epoch_num in range(EPOCHS):\n",
    "\n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for train_data, train_label in tqdm(train_dataloader):\n",
    "\n",
    "            train_label = train_label[0].to(device)\n",
    "            mask = train_data['attention_mask'][0].to(device)\n",
    "            input_id = train_data['input_ids'][0].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss, logits = model(input_id, mask, train_label)\n",
    "\n",
    "            logits_clean = logits[0][train_label != -100]\n",
    "            label_clean = train_label[train_label != -100]\n",
    "\n",
    "            predictions = logits_clean.argmax(dim=1)\n",
    "\n",
    "            acc = (predictions == label_clean).float().mean()\n",
    "            total_acc_train += acc\n",
    "            total_loss_train += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        predictions = [predict(model, sent) for sent in dev_dataset.sents]\n",
    "        p,r,f = evaluate(predictions, dev_dataset.tags)\n",
    "        print(\"  PRECISION: %.2f%%, RECALL: %.2f%%, F-SCORE: %.2f%%\" % (p,r,f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04dfe45-6067-43dd-a793-0b1a265a3a7a",
   "metadata": {},
   "source": [
    "#### Download katalon-bert-tagger.pt here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01174d2-a8c6-4e4b-ace8-b68c53c83cf5",
   "metadata": {},
   "source": [
    "For running the main notebook, if you want to use the trained tagger directly, you need to download the model [pickle file](https://drive.google.com/file/d/1VXX8jcqaZY7p5K1ZQ8NSq3xIqZ8XSj2q/view?usp=sharing) and save it in the `pickle_files/pickle_files_for_parsing/`. (Sorry for the inconvenience as the tagger is too large to upload on Github.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e07ed6a1-6ec6-4da9-9087-be98b8dc1607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here instead of training once again, we load the trained model\n",
    "# model = BertModel()\n",
    "# train_loop(model, train_set, dev_set)\n",
    "model_path = 'pickle_files/pickle_files_for_parsing/katalon-bert-tagger.pt'\n",
    "model = BertModel()\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a837d1c-4607-4855-907b-73ae3ff669cd",
   "metadata": {},
   "source": [
    "### 5) Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60eaed89-972e-43b5-8225-d79290bac913",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for steps in updated_steps:\n",
    "    predictions.append([])\n",
    "    for sent in steps:\n",
    "        predictions[-1].append(predict(model, sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5cef226a-9e1e-4720-980f-ee94568f3de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_cases = []\n",
    "for case in updated_steps:\n",
    "    tokenized_steps = []\n",
    "    for step in case:\n",
    "        text_tokenized = tokenizer(step, padding='max_length', max_length=MAX_LENGTH, return_tensors=\"pt\")\n",
    "        sent = tokenizer.decode(text_tokenized[\"input_ids\"][0], skip_special_tokens=True)\n",
    "        tokenized_steps.append(sent)\n",
    "    tokenized_cases.append(tokenized_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b909e7-4ef6-4952-80c9-154913e207b3",
   "metadata": {},
   "source": [
    "## **Parsing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "94a6a458-deab-4aa6-b91f-3af88a611f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the frame parser\n",
    "frame_parser = FrameParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8874ef2b-b543-4864-a6ef-464691315b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error (enter & input): NO SECOND OBJECT! \n",
      "{'V': 'set', 'ARG1': 'name field text'}\n",
      "Error (enter & input): NO SECOND OBJECT! \n",
      "{'V': 'input', 'ARG1': 'the name field'}\n"
     ]
    }
   ],
   "source": [
    "# Using rule-based parsing (if you are using rule-based, comment the BERT parsed_test_cases and uncomment the code below)\n",
    "parsed_test_cases = frame_parser.parse(updated_steps, pages_list, predictions, rule_base=True)\n",
    "\n",
    "# Using BERT tagger (if you are using tagger, comment the previus parsed_test_cases and uncomment the code below)\n",
    "#parsed_test_cases = frame_parser.parse(tokenized_cases, pages_list, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b01f058a-eb36-4b9f-aeb3-6e1ced157c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'V': 'enter',\n",
       "  'value': 'admin1@mail.com',\n",
       "  'location': 'to email textbox',\n",
       "  'page': 'Login'},\n",
       " {'V': 'enter',\n",
       "  'value': 'Admin@123',\n",
       "  'location': 'to password textbox',\n",
       "  'page': 'Login'},\n",
       " {'V': 'click', 'value': 'Login', 'page': 'Login'},\n",
       " {'V': 'wait',\n",
       "  'value': 'for title to be present for seconds',\n",
       "  'time': 30,\n",
       "  'page': 'Login'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demo showing first parsed test case\n",
    "parsed_test_cases[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ceb49e-1f90-4eeb-b2cc-a36b687202af",
   "metadata": {},
   "source": [
    "## **Generate Test Scripts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2aa6d5f4-e8d2-44ad-b99b-f16c398013c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WebUI.setText(findTestObject('Page_Login/tbx_Email'), 'admin1@mail.com')\n",
      "WebUI.setText(findTestObject('Page_Login/tbx_Password'), 'Admin@123')\n",
      "WebUI.click(findTestObject('Page_Login/btn_Login'))\n",
      "WebUI.waitForElementPresent(findTestObject('Page_Login/txt_EmailErrorMessage'), 30, FailureHandling.STOP_ON_FAILURE)\n"
     ]
    }
   ],
   "source": [
    "scripts = [generate_script(test_case) for test_case in parsed_test_cases]\n",
    "\n",
    "# Demo showing first parsed test case\n",
    "print(scripts[0])\n",
    "\n",
    "# for i, script in enumerate(scripts):\n",
    "#     print(\"Script \" + str(i)+'\\n')\n",
    "#     print(script)\n",
    "#     print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ad974a-b937-4d59-a2bf-b19403de8254",
   "metadata": {},
   "source": [
    "## **Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d8066f-cebf-4925-b7d8-4a301a554a44",
   "metadata": {},
   "source": [
    "### 1) Load the generated scripts and gold scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ac31c24c-87c2-48e6-858b-8da0452a30b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the generated scripts by splitting\n",
    "scripts = [script.split('\\n') for script in scripts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78eda003-f835-463f-99cb-7303174c9f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_folder = 'pickle_files/pickle_files_for_script_generation/'\n",
    "\n",
    "with open(pkl_folder+\"script_list.pkl\", \"rb\") as f:\n",
    "    gold_scripts = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "498911c5-2730-4d6a-ae58-763cc656be4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the test cases to remove precondition and verification parts and also the WebUI we ignored like WebUI.comment\n",
    "gold_scripts = [preprocess_test_case(gold) for gold in gold_scripts[:14]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9d6aa7c6-4523-43cd-92cb-6ddabf266554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty script which is test case 6 here\n",
    "gold_scripts.remove(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2926fa8-f1e2-4013-b9a8-0c09965ac5d4",
   "metadata": {},
   "source": [
    "### 2) F1 evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8140df66-19f3-4c29-be93-38cb851571c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.64240217616462\n"
     ]
    }
   ],
   "source": [
    "f1_evaluation(gold_scripts, scripts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8365ef6c-7f97-412c-912b-7eb0f83e65f0",
   "metadata": {},
   "source": [
    "### 3) BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eaf4a8ed-ff33-4c62-b465-5db5d22f6aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 gram BLEU Score is: 0.46538338910220767\n",
      "2 gram BLEU Score is: 0.35910166938106725\n",
      "3 gram BLEU Score is: 0.29529716592636013\n",
      "4 gram BLEU Score is: 0.25111982298579294\n"
     ]
    }
   ],
   "source": [
    "BLEU_evaluation(gold_scripts, scripts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8303397-e2cd-47b9-b77a-88bc2cb411cd",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
