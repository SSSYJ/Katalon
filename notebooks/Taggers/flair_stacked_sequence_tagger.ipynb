{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yDN347uHXsV"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7ElOSYKRECP0"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import io\n",
        "import os\n",
        "#you may need to install the packages by\n",
        "#!pip install csv\n",
        "#!pip install io\n",
        "#!pip install os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FW2Avk_nECSa",
        "outputId": "936fbb4e-a07c-47bc-ced7-0826ea6fb760"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XMPcUYUxECVU"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/drive/MyDrive/Colab Notebooks/data/anno_8_tc.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfPryO18JyqR"
      },
      "source": [
        "# Load in data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "X2-T7mchECYe"
      },
      "outputs": [],
      "source": [
        "with open(file_path) as f:\n",
        "    f.readline()\n",
        "    reader = csv.reader(f)\n",
        "    data = list(reader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3BYT77xECbX",
        "outputId": "6790b329-ec37-4698-bda9-978e8e3e1aac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['S1', '*'], ['Enter', 'O'], ['email', 'O'], ['address', 'O'], ['to', 'O']]\n"
          ]
        }
      ],
      "source": [
        "print(data[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSu6u20lKNa5",
        "outputId": "8e556b49-2f6f-4aad-9b6b-3ab344ec8454"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['S1', '*'], ['Enter', 'O'], ['email', 'O'], ['address', 'O'], ['to', 'O'], ['Email', 'B-location'], ['textbox', 'I-location'], ['admin1@mail.com', 'B-value'], ['S2', '*'], ['Enter', 'O'], ['password', 'O'], ['to', 'O'], ['Password', 'B-location'], ['textbox', 'I-location'], ['Admin@123', 'B-value'], ['S3', '*'], ['Click', 'O'], ['button', 'B-value'], ['Login', 'I-value'], ['S4', '*']]\n"
          ]
        }
      ],
      "source": [
        "print(data[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_irvfVY9PMH"
      },
      "source": [
        "# Clean the sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "c1LzlGwtKNTQ"
      },
      "outputs": [],
      "source": [
        "sents = []\n",
        "sent = []\n",
        "for word, tag in data:\n",
        "  if tag == '*':\n",
        "    if len(sent) > 0:\n",
        "        sents.append(sent)\n",
        "        sent = []\n",
        "    else:\n",
        "        continue\n",
        "  else:\n",
        "    sent.append((word, tag))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xWx7duyP6usw"
      },
      "outputs": [],
      "source": [
        "texts_sents = []\n",
        "for sent in sents:\n",
        "  words = []\n",
        "  for word, tag in sent:\n",
        "    words.append(word)\n",
        "  texts_sents.append(\" \".join(words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BYUiCnmW8hra",
        "outputId": "db118c4e-f00f-4b9a-db37-8201ee07d84b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Enter email address to Email textbox admin1@mail.com'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texts_sents[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfwtoOM79B-v"
      },
      "source": [
        "# Trying out Flair models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH8ojK5LEChE",
        "outputId": "901c3ce5-d2c5-4f97-86ac-368a6a27688f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flair\n",
            "  Downloading flair-0.11.3-py3-none-any.whl (401 kB)\n",
            "\u001b[K     |████████████████████████████████| 401 kB 27.8 MB/s \n",
            "\u001b[?25hCollecting konoha<5.0.0,>=4.0.0\n",
            "  Downloading konoha-4.6.5-py3-none-any.whl (20 kB)\n",
            "Collecting wikipedia-api\n",
            "  Downloading Wikipedia-API-0.5.4.tar.gz (18 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair) (2.8.2)\n",
            "Collecting janome\n",
            "  Downloading Janome-0.4.2-py2.py3-none-any.whl (19.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.7 MB 429 kB/s \n",
            "\u001b[?25hCollecting mpld3==0.3\n",
            "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
            "\u001b[K     |████████████████████████████████| 788 kB 61.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from flair) (8.13.0)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from flair) (3.2.2)\n",
            "Collecting pptree\n",
            "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
            "Collecting bpemb>=0.3.2\n",
            "  Downloading bpemb-0.3.3-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: gdown==4.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.4.0)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.4 MB/s \n",
            "\u001b[?25hCollecting segtok>=1.5.7\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 7.1 MB/s \n",
            "\u001b[?25hCollecting conllu>=4.0\n",
            "  Downloading conllu-4.4.2-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair) (1.0.2)\n",
            "Collecting hyperopt>=0.2.7\n",
            "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 65.6 MB/s \n",
            "\u001b[?25hCollecting deprecated>=1.2.4\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (3.6.0)\n",
            "Collecting sentencepiece==0.1.95\n",
            "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 60.9 MB/s \n",
            "\u001b[?25hCollecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 55.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair) (4.2.6)\n",
            "Collecting sqlitedict>=1.6.0\n",
            "  Downloading sqlitedict-2.0.0.tar.gz (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 4.8 MB/s \n",
            "\u001b[?25hCollecting transformers>=4.0.0\n",
            "  Downloading transformers-4.19.4-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 61.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair) (2019.12.20)\n",
            "Requirement already satisfied: torch!=1.8,>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.11.0+cu113)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair) (0.8.9)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.64.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown==4.4.0->flair) (1.15.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown==4.4.0->flair) (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown==4.4.0->flair) (4.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown==4.4.0->flair) (3.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bpemb>=0.3.2->flair) (1.21.6)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair) (1.14.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->flair) (6.0.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->flair) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.7->flair) (1.3.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.7->flair) (2.6.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.7->flair) (0.16.0)\n",
            "Collecting py4j\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 78.3 MB/s \n",
            "\u001b[?25hCollecting overrides<4.0.0,>=3.0.0\n",
            "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
            "Collecting importlib-metadata<4.0.0,>=3.7.0\n",
            "  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n",
            "Collecting requests\n",
            "  Downloading requests-2.28.0-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (4.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (3.0.9)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.24.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (3.1.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 71.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 67.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->flair) (0.2.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.7.1)\n",
            "Building wheels for collected packages: mpld3, overrides, sqlitedict, langdetect, pptree, wikipedia-api\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116702 sha256=1bbbfa0f86a7c12a158b0ad5a1bb28a5111e2320cdb435923a654fceafa7c18b\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/70/6a/1c79e59951a41b4045497da187b2724f5659ca64033cf4548e\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10187 sha256=f78c41d3a936263b07656c263af04ce641bfcc4033d428784cc1a5321e54cc2a\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/0d/38/01a9bc6e20dcfaf0a6a7b552d03137558ba1c38aea47644682\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.0.0-py3-none-any.whl size=15736 sha256=7b78f6be641d6151a3900a3373d817e82b967c8cde668d830d618cfa6c3edc8f\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/dd/2e/0ed4a25cb73fc30c7ea8d10b50acb7226175736067e40a7ea3\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=911b72638dc837630e747bb5f5c8acee08707f1d8550fa29309e81e2b2f01318\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
            "  Building wheel for pptree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4629 sha256=cca1a4d2fbd2b1cdb417fef877b97730987feca6f5e0e0e3f99efa8da1b11600\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/e8/7d/a9c3c19b4722608a0d8b05a38c36bc3f230c43becd2a46794b\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.5.4-py3-none-any.whl size=13477 sha256=749cae81da535e9ca3ab56c244be2cff963fb07fb5da6d0d94e62a7cc8be37a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/24/56/58ba93cf78be162451144e7a9889603f437976ef1ae7013d04\n",
            "Successfully built mpld3 overrides sqlitedict langdetect pptree wikipedia-api\n",
            "Installing collected packages: requests, pyyaml, importlib-metadata, tokenizers, sentencepiece, py4j, overrides, huggingface-hub, wikipedia-api, transformers, sqlitedict, segtok, pptree, mpld3, langdetect, konoha, janome, hyperopt, ftfy, deprecated, conllu, bpemb, flair\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.11.4\n",
            "    Uninstalling importlib-metadata-4.11.4:\n",
            "      Successfully uninstalled importlib-metadata-4.11.4\n",
            "  Attempting uninstall: hyperopt\n",
            "    Found existing installation: hyperopt 0.1.2\n",
            "    Uninstalling hyperopt-0.1.2:\n",
            "      Successfully uninstalled hyperopt-0.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "markdown 3.3.7 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 3.10.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed bpemb-0.3.3 conllu-4.4.2 deprecated-1.2.13 flair-0.11.3 ftfy-6.1.1 huggingface-hub-0.7.0 hyperopt-0.2.7 importlib-metadata-3.10.1 janome-0.4.2 konoha-4.6.5 langdetect-1.0.9 mpld3-0.3 overrides-3.1.0 pptree-3.1 py4j-0.10.9.5 pyyaml-6.0 requests-2.28.0 segtok-1.5.11 sentencepiece-0.1.95 sqlitedict-2.0.0 tokenizers-0.12.1 transformers-4.19.4 wikipedia-api-0.5.4\n"
          ]
        }
      ],
      "source": [
        "!pip install flair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CnRzl7HAECj2"
      },
      "outputs": [],
      "source": [
        "from flair.models import SequenceTagger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "e5970413cbef4286b561549f8e5c0908",
            "964fd675176148d4bf5163e7bfe695a5",
            "bb99e1d726bb45d4949eff4ad9d251d6",
            "54233e83ac964e32bc14fabe6cd3a2d2",
            "f266e33f613946ceac5faae3a9f8b865",
            "9da5e83bd300484c90c1ce1358860155",
            "58563cd15871480491cdde3d369a0044",
            "ee3c2b13b1f746e3b85ff8eba7762842",
            "0eadd28db21443ff8fdd928267904d02",
            "0e44730a994049ee89e31a0d3b27cbe6",
            "81b7ea20f30748d88a353c1ef18aa1b8"
          ]
        },
        "id": "U08yXATIECmr",
        "outputId": "16dc00aa-439f-4574-d16b-8d58b771d246"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5970413cbef4286b561549f8e5c0908",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/432M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-06-12 22:11:40,159 loading file /root/.flair/models/ner-english/4f4cdab26f24cb98b732b389e6cebc646c36f54cfd6e0b7d3b90b25656e4262f.8baa8ae8795f4df80b28e7f7b61d788ecbb057d1dc85aacb316f1bd02837a4a4\n",
            "2022-06-12 22:11:42,291 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n"
          ]
        }
      ],
      "source": [
        "tagger = SequenceTagger.load('ner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QvgEOmFi-maH"
      },
      "outputs": [],
      "source": [
        "from flair.data import Sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GBtRrrH293ok"
      },
      "outputs": [],
      "source": [
        "sentence = Sentence(\"George Washington went to Washington.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "t2WnOizV-qq0"
      },
      "outputs": [],
      "source": [
        "tagger.predict(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26leOD8z_DhM",
        "outputId": "132b8a29-fd0c-44da-9ba8-153f18f2a348"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: \"George Washington went to Washington .\" → [\"George Washington\"/PER, \"Washington\"/LOC]\n"
          ]
        }
      ],
      "source": [
        "print(sentence.to_tagged_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjoWJRt3_Iay",
        "outputId": "645531a9-0293-4709-b732-2ff2c83c2b17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Span[0:2]: \"George Washington\" → PER (0.9989)\n",
            "Span[4:5]: \"Washington\" → LOC (0.9942)\n"
          ]
        }
      ],
      "source": [
        "for entity in sentence.get_spans('ner'):\n",
        "  print(entity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzQsZ4vwBDkZ",
        "outputId": "75cad84f-803f-4bf2-fc8a-50175f2bde67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'text': 'George Washington went to Washington.', 'ner': [{'value': 'PER', 'confidence': 0.998886227607727}, {'value': 'LOC', 'confidence': 0.9942097663879395}]}\n"
          ]
        }
      ],
      "source": [
        "print(sentence.to_dict(tag_type='ner'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "nCdK3GLLCtCu"
      },
      "outputs": [],
      "source": [
        "from flair.data import Corpus \n",
        "from flair.datasets import ColumnCorpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "P2-wN39ZCzhZ"
      },
      "outputs": [],
      "source": [
        "columns = {0: 'text', 1:'ner'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Oe3ysLKEE9Yn"
      },
      "outputs": [],
      "source": [
        "data_folder = '/content/drive/MyDrive/Colab Notebooks/data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNMjk_1wFo4s",
        "outputId": "3487e084-645a-467b-c81e-20d221d798e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[('Enter', 'O'),\n",
              "  ('email', 'O'),\n",
              "  ('address', 'O'),\n",
              "  ('to', 'O'),\n",
              "  ('Email', 'B-location'),\n",
              "  ('textbox', 'I-location'),\n",
              "  ('admin1@mail.com', 'B-value')],\n",
              " [('Enter', 'O'),\n",
              "  ('password', 'O'),\n",
              "  ('to', 'O'),\n",
              "  ('Password', 'B-location'),\n",
              "  ('textbox', 'I-location'),\n",
              "  ('Admin@123', 'B-value')],\n",
              " [('Click', 'O'), ('button', 'B-value'), ('Login', 'I-value')],\n",
              " [('Wait', 'O'),\n",
              "  ('title', 'B-value'),\n",
              "  ('to', 'O'),\n",
              "  ('be', 'O'),\n",
              "  ('present', 'O'),\n",
              "  ('for', 'O'),\n",
              "  ('30', 'B-time'),\n",
              "  ('seconds', 'I-time')],\n",
              " [('Enter', 'O'),\n",
              "  ('email', 'O'),\n",
              "  ('address', 'O'),\n",
              "  ('to', 'O'),\n",
              "  ('Email', 'B-location'),\n",
              "  ('textbox', 'I-location'),\n",
              "  ('invalid@wrong', 'B-value')],\n",
              " [('Enter', 'O'),\n",
              "  ('password', 'O'),\n",
              "  ('to', 'O'),\n",
              "  ('Password', 'B-location'),\n",
              "  ('textbox', 'I-location'),\n",
              "  ('invalidpassword', 'B-value')],\n",
              " [('Click', 'O'), ('Login', 'B-value'), ('button', 'I-value')],\n",
              " [('Wait', 'O'),\n",
              "  ('email', 'B-value'),\n",
              "  ('error', 'I-value'),\n",
              "  ('message', 'I-value'),\n",
              "  ('to', 'O'),\n",
              "  ('appear', 'O'),\n",
              "  ('for', 'O'),\n",
              "  ('3', 'B-time'),\n",
              "  ('seconds', 'I-time')],\n",
              " [('Get', 'O'),\n",
              "  ('email', 'B-value'),\n",
              "  ('error', 'I-value'),\n",
              "  ('message', 'I-value')],\n",
              " [('Check', 'O'),\n",
              "  ('if', 'O'),\n",
              "  ('actual', 'B-value'),\n",
              "  ('error', 'B-value'),\n",
              "  ('message', 'B-value'),\n",
              "  ('is', 'O'),\n",
              "  ('correct', 'O')],\n",
              " [('Wait', 'O'),\n",
              "  ('password', 'B-value'),\n",
              "  ('error', 'I-value'),\n",
              "  ('message', 'I-value'),\n",
              "  ('to', 'O'),\n",
              "  ('appear', 'O'),\n",
              "  ('for', 'O'),\n",
              "  ('3', 'B-time'),\n",
              "  ('seconds', 'B-time')],\n",
              " [('Get', 'O'),\n",
              "  ('password', 'B-value'),\n",
              "  ('error', 'I-value'),\n",
              "  ('message', 'I-value')],\n",
              " [('Check', 'O'),\n",
              "  ('if', 'O'),\n",
              "  ('actual', 'B-value'),\n",
              "  ('password', 'I-value'),\n",
              "  ('message', 'I-value'),\n",
              "  ('is', 'O'),\n",
              "  ('correct', 'O')],\n",
              " [('On', 'O'),\n",
              "  ('the', 'O'),\n",
              "  ('Dashboard', 'O'),\n",
              "  ('page', 'O'),\n",
              "  (',', 'O'),\n",
              "  ('click', 'O'),\n",
              "  ('the', 'O'),\n",
              "  ('avatar', 'B-value'),\n",
              "  ('on', 'O'),\n",
              "  ('the', 'O'),\n",
              "  ('top', 'O'),\n",
              "  ('right', 'O'),\n",
              "  ('corner', 'O'),\n",
              "  ('to', 'O'),\n",
              "  ('open', 'O'),\n",
              "  ('menu', 'O')],\n",
              " [('Click', 'O'),\n",
              "  ('button', 'B-value'),\n",
              "  ('Sign', 'I-value'),\n",
              "  ('out', 'I-value')],\n",
              " [('Wait', 'O'),\n",
              "  ('Login', 'B-value'),\n",
              "  ('button', 'I-value'),\n",
              "  ('to', 'O'),\n",
              "  ('appear', 'O'),\n",
              "  ('for', 'O'),\n",
              "  ('10s', 'B-time')],\n",
              " [('Click', 'O'),\n",
              "  (\"User's\", 'B-value'),\n",
              "  ('avatar', 'I-value'),\n",
              "  ('on', 'O'),\n",
              "  ('the', 'O'),\n",
              "  ('top', 'O'),\n",
              "  ('right', 'O')],\n",
              " [('Click', 'O'),\n",
              "  ('Change', 'B-value'),\n",
              "  ('Password', 'I-value'),\n",
              "  ('link', 'I-value')],\n",
              " [('Wait', 'O'),\n",
              "  ('title', 'B-value'),\n",
              "  ('to', 'O'),\n",
              "  ('appear', 'O'),\n",
              "  ('for', 'O'),\n",
              "  ('10', 'B-time')],\n",
              " [('Enter', 'O')],\n",
              " [('to', 'O'),\n",
              "  ('current', 'B-location'),\n",
              "  ('password', 'I-location'),\n",
              "  ('text', 'I-location'),\n",
              "  ('box', 'I-location'),\n",
              "  ('Admin@123', 'B-value')],\n",
              " [('Enter', 'O'),\n",
              "  ('new', 'O'),\n",
              "  ('password', 'O'),\n",
              "  ('to', 'O'),\n",
              "  ('new', 'B-location'),\n",
              "  ('password', 'I-location'),\n",
              "  ('text', 'I-location'),\n",
              "  ('box', 'I-location'),\n",
              "  ('Admin@1234', 'B-value')],\n",
              " [('Enter', 'O'),\n",
              "  ('new', 'O'),\n",
              "  ('password', 'O'),\n",
              "  ('again', 'O'),\n",
              "  ('to', 'O'),\n",
              "  ('confirm', 'O'),\n",
              "  ('password', 'O'),\n",
              "  ('Admin@1234', 'B-value')],\n",
              " [('Click', 'O'), ('submit', 'B-value'), ('button', 'I-value')],\n",
              " [('On', 'O'),\n",
              "  ('the', 'O'),\n",
              "  ('Dashboard', 'O'),\n",
              "  ('page', 'O'),\n",
              "  (',', 'O'),\n",
              "  ('click', 'O'),\n",
              "  ('the', 'O'),\n",
              "  ('avatar', 'B-value'),\n",
              "  ('on', 'O'),\n",
              "  ('the', 'O'),\n",
              "  ('top', 'O'),\n",
              "  ('right', 'O'),\n",
              "  ('corner', 'O'),\n",
              "  ('to', 'O'),\n",
              "  ('open', 'O'),\n",
              "  ('menu', 'O')],\n",
              " [('Click', 'O'),\n",
              "  ('button', 'B-value'),\n",
              "  ('Change', 'I-value'),\n",
              "  ('password', 'I-value'),\n",
              "  ('to', 'O'),\n",
              "  ('go', 'O'),\n",
              "  ('to', 'O'),\n",
              "  ('change', 'O'),\n",
              "  ('password', 'O'),\n",
              "  ('page', 'O')],\n",
              " [('Wait', 'O'),\n",
              "  ('title', 'B-value'),\n",
              "  ('to', 'O'),\n",
              "  ('appear', 'O'),\n",
              "  ('for', 'O'),\n",
              "  ('10', 'B-time')],\n",
              " [('Enter', 'O'),\n",
              "  ('current', 'O'),\n",
              "  ('password', 'O'),\n",
              "  ('to', 'O'),\n",
              "  ('current', 'B-location'),\n",
              "  ('password', 'I-location'),\n",
              "  ('text', 'I-location'),\n",
              "  ('box', 'I-location'),\n",
              "  ('Admin@1234', 'B-value')],\n",
              " [('Enter', 'O'),\n",
              "  ('new', 'O'),\n",
              "  ('password', 'O'),\n",
              "  ('new', 'B-location'),\n",
              "  ('password', 'I-location'),\n",
              "  ('text', 'I-location'),\n",
              "  ('box', 'I-location'),\n",
              "  ('Admin@12345', 'B-value')],\n",
              " [('Enter', 'O'),\n",
              "  ('new', 'O'),\n",
              "  ('password', 'O'),\n",
              "  ('again', 'O'),\n",
              "  ('confirm', 'B-location'),\n",
              "  ('password', 'I-location'),\n",
              "  ('textbox', 'I-location'),\n",
              "  ('to', 'O'),\n",
              "  ('confirm', 'O'),\n",
              "  ('password', 'O'),\n",
              "  ('Admin@12345', 'B-value')],\n",
              " [('Click', 'O'), ('submit', 'B-value'), ('button', 'I-value')],\n",
              " [('Click', 'O'),\n",
              "  ('User’s', 'B-value'),\n",
              "  ('avatar', 'I-value'),\n",
              "  ('on', 'O'),\n",
              "  ('the', 'O'),\n",
              "  ('top', 'O'),\n",
              "  ('right', 'O')],\n",
              " [('Click', 'O'),\n",
              "  ('My', 'B-value'),\n",
              "  ('Profile', 'I-value'),\n",
              "  ('link', 'I-value')],\n",
              " [('Wait', 'O'),\n",
              "  ('email', 'B-value'),\n",
              "  ('to', 'O'),\n",
              "  ('appear', 'O'),\n",
              "  ('for', 'O'),\n",
              "  ('20s', 'B-time')],\n",
              " [('Enter', 'O'),\n",
              "  ('new', 'O'),\n",
              "  ('full', 'O'),\n",
              "  ('name', 'O'),\n",
              "  ('to', 'O'),\n",
              "  ('full', 'B-location'),\n",
              "  ('name', 'I-location'),\n",
              "  ('text', 'I-location'),\n",
              "  ('box', 'I-location'),\n",
              "  ('new', 'B-value'),\n",
              "  ('name', 'I-value')],\n",
              " [('Enter', 'O'),\n",
              "  ('new', 'O'),\n",
              "  ('phone', 'O'),\n",
              "  ('number', 'O'),\n",
              "  ('to', 'O'),\n",
              "  ('phone', 'B-location'),\n",
              "  ('number', 'I-location'),\n",
              "  ('text', 'I-location'),\n",
              "  ('box', 'I-location'),\n",
              "  ('1234567890', 'B-value')],\n",
              " [('Click', 'O'), ('submit', 'B-value'), ('button', 'I-value')],\n",
              " [('On', 'O'),\n",
              "  ('the', 'O'),\n",
              "  ('Dashboard', 'O'),\n",
              "  ('page', 'O'),\n",
              "  (',', 'O'),\n",
              "  ('click', 'O'),\n",
              "  ('the', 'O'),\n",
              "  ('avatar', 'B-value'),\n",
              "  ('on', 'O'),\n",
              "  ('the', 'O'),\n",
              "  ('top', 'O'),\n",
              "  ('right', 'O'),\n",
              "  ('corner', 'O'),\n",
              "  ('to', 'O'),\n",
              "  ('open', 'O'),\n",
              "  ('menu', 'O')],\n",
              " [('Click', 'O'),\n",
              "  ('button', 'B-value'),\n",
              "  ('My', 'I-value'),\n",
              "  ('Profile', 'I-value'),\n",
              "  ('to', 'O'),\n",
              "  ('go', 'O'),\n",
              "  ('to', 'O'),\n",
              "  ('Update', 'O'),\n",
              "  ('my', 'O'),\n",
              "  ('Profile', 'O'),\n",
              "  ('page', 'O')],\n",
              " [('Wait', 'O'),\n",
              "  ('for', 'O'),\n",
              "  ('email', 'B-value'),\n",
              "  ('to', 'O'),\n",
              "  ('appear', 'O'),\n",
              "  ('for', 'O'),\n",
              "  ('20', 'B-time')],\n",
              " [('Enter', 'O'),\n",
              "  ('new', 'O'),\n",
              "  ('full', 'O'),\n",
              "  ('name', 'O'),\n",
              "  ('to', 'O'),\n",
              "  ('full', 'B-location'),\n",
              "  ('name', 'B-location'),\n",
              "  ('text', 'I-location'),\n",
              "  ('box', 'I-location')],\n",
              " [('Enter', 'O'),\n",
              "  ('new', 'O'),\n",
              "  ('phone', 'O'),\n",
              "  ('number', 'O'),\n",
              "  ('to', 'O'),\n",
              "  ('phone', 'B-location'),\n",
              "  ('number', 'I-location'),\n",
              "  ('text', 'I-location'),\n",
              "  ('box', 'I-location'),\n",
              "  ('12345678', 'B-value')]]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuMZF3crH-i1",
        "outputId": "b2e0f24e-a1ea-4f48-dc0a-58c4dff56d4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done\n"
          ]
        }
      ],
      "source": [
        "with open(data_folder+ \"/train.txt\", \"w\") as file:\n",
        "  for sent in sents:\n",
        "    file.write(\"\\n\")\n",
        "    for item in sent:\n",
        "      file.write(\"\\n\" + \" \".join(item))\n",
        "  print(\"Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZ02FhusEhp0",
        "outputId": "58134c70-1e7c-418e-8c4a-c71fcf5d949d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-06-12 22:11:55,668 Reading data from /content/drive/MyDrive/Colab Notebooks/data\n",
            "2022-06-12 22:11:55,671 Train: /content/drive/MyDrive/Colab Notebooks/data/train.txt\n",
            "2022-06-12 22:11:55,672 Dev: None\n",
            "2022-06-12 22:11:55,674 Test: None\n"
          ]
        }
      ],
      "source": [
        "corpus: Corpus = ColumnCorpus(data_folder, columns, train_file = 'train.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B67QcaIPFSAN",
        "outputId": "756c7b86-81cc-41ab-cd34-cabc8c990e94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34\n"
          ]
        }
      ],
      "source": [
        "print(len(corpus.train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zwuxPKmKFVyq",
        "outputId": "edc883b5-e23c-4dc1-88d4-ea2301ebe43d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Sentence: \"Enter email address to Email textbox admin1@mail.com\" → [\"Email textbox\"/location, \"admin1@mail.com\"/value]'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus.train[0].to_tagged_string('ner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5xX7AALKItc",
        "outputId": "e4d04681-63e9-4c37-d3ce-bb9b00a3cb76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: \"Enter new phone number to phone number text box 12345678\" → [\"phone number text box\"/location, \"12345678\"/value]\n"
          ]
        }
      ],
      "source": [
        "print(corpus.train[-1].to_tagged_string('ner'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nZnvf-uJD7F"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "rI1Jwj4wJFCn"
      },
      "outputs": [],
      "source": [
        "label_type = \"ner\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKTcgiRHJI7Y",
        "outputId": "a6b15fe0-5cf9-4c45-fe5d-caba8d946f03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-06-12 22:11:55,745 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "34it [00:00, 16090.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-06-12 22:11:55,757 Dictionary created for label 'ner' with 4 values: value (seen 32 times), location (seen 12 times), time (seen 8 times)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "tag_dictionary = corpus.make_label_dictionary(label_type=label_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThYT_Dr9TIz5",
        "outputId": "9b38a789-7e91-40b6-b709-ac901d701006"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dictionary with 4 tags: <unk>, value, location, time\n"
          ]
        }
      ],
      "source": [
        "print(tag_dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Dwrzhj9ISvVa"
      },
      "outputs": [],
      "source": [
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, StackedEmbeddings\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrGCsSu_TQfx",
        "outputId": "ca183aae-468c-4a0a-9fb3-ed234851dacc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-06-12 22:11:56,311 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim.vectors.npy not found in cache, downloading to /tmp/tmpwjh0_flv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 160000128/160000128 [00:06<00:00, 25888964.33B/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-06-12 22:12:02,847 copying /tmp/tmpwjh0_flv to cache at /root/.flair/embeddings/glove.gensim.vectors.npy\n",
            "2022-06-12 22:12:03,084 removing temp file /tmp/tmpwjh0_flv\n",
            "2022-06-12 22:12:03,456 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim not found in cache, downloading to /tmp/tmpq9vzmwvx\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21494764/21494764 [00:01<00:00, 15693930.81B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-06-12 22:12:05,177 copying /tmp/tmpq9vzmwvx to cache at /root/.flair/embeddings/glove.gensim\n",
            "2022-06-12 22:12:05,200 removing temp file /tmp/tmpq9vzmwvx\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-06-12 22:12:06,881 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/news-forward-0.4.1.pt not found in cache, downloading to /tmp/tmp13_1axn_\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 73034624/73034624 [00:04<00:00, 17839704.28B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-06-12 22:12:11,327 copying /tmp/tmp13_1axn_ to cache at /root/.flair/embeddings/news-forward-0.4.1.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-06-12 22:12:11,433 removing temp file /tmp/tmp13_1axn_\n",
            "2022-06-12 22:12:12,001 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/news-backward-0.4.1.pt not found in cache, downloading to /tmp/tmpzv6y3i5t\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 73034575/73034575 [00:03<00:00, 23014928.91B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-06-12 22:12:15,499 copying /tmp/tmpzv6y3i5t to cache at /root/.flair/embeddings/news-backward-0.4.1.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-06-12 22:12:15,605 removing temp file /tmp/tmpzv6y3i5t\n"
          ]
        }
      ],
      "source": [
        "embedding_types = [\n",
        "    WordEmbeddings('glove'),\n",
        "    FlairEmbeddings('news-forward'),\n",
        "    FlairEmbeddings('news-backward'),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "KUvGwyZkTFrV"
      },
      "outputs": [],
      "source": [
        "embeddings = StackedEmbeddings(embeddings=embedding_types)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGmxaT9qTWDz",
        "outputId": "3f0eb77d-cfe5-4cfd-c70a-cb96a422b3bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-06-12 22:12:15,820 SequenceTagger predicts: Dictionary with 13 tags: O, S-value, B-value, E-value, I-value, S-location, B-location, E-location, I-location, S-time, B-time, E-time, I-time\n"
          ]
        }
      ],
      "source": [
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                        embeddings=embeddings,\n",
        "                        tag_dictionary=tag_dictionary,\n",
        "                        tag_type=label_type,\n",
        "                        use_crf=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "GpikiU2yTYDk"
      },
      "outputs": [],
      "source": [
        "trainer = ModelTrainer(tagger, corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35B5on1BTfoB",
        "outputId": "e76bc07c-668e-412b-886f-4b23536da48a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-06-12 22:21:29,885 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:29,887 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings(\n",
            "      'glove'\n",
            "      (embedding): Embedding(400001, 100)\n",
            "    )\n",
            "    (list_embedding_1): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.05, inplace=False)\n",
            "        (encoder): Embedding(300, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_2): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.05, inplace=False)\n",
            "        (encoder): Embedding(300, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=4196, out_features=4196, bias=True)\n",
            "  (rnn): LSTM(4196, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=15, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\"\n",
            "2022-06-12 22:21:29,888 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:29,890 Corpus: \"Corpus: 34 train + 4 dev + 4 test sentences\"\n",
            "2022-06-12 22:21:29,892 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:29,893 Parameters:\n",
            "2022-06-12 22:21:29,895  - learning_rate: \"0.100000\"\n",
            "2022-06-12 22:21:29,896  - mini_batch_size: \"1\"\n",
            "2022-06-12 22:21:29,898  - patience: \"3\"\n",
            "2022-06-12 22:21:29,900  - anneal_factor: \"0.5\"\n",
            "2022-06-12 22:21:29,902  - max_epochs: \"150\"\n",
            "2022-06-12 22:21:29,903  - shuffle: \"True\"\n",
            "2022-06-12 22:21:29,905  - train_with_dev: \"True\"\n",
            "2022-06-12 22:21:29,907  - batch_growth_annealing: \"False\"\n",
            "2022-06-12 22:21:29,909 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:29,910 Model training base path: \"resources/taggers/sota-ner-flair\"\n",
            "2022-06-12 22:21:29,911 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:29,913 Device: cuda:0\n",
            "2022-06-12 22:21:29,914 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:29,915 Embeddings storage mode: cpu\n",
            "2022-06-12 22:21:29,916 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:29,984 epoch 1 - iter 3/38 - loss 0.00791096 - samples/sec: 45.96 - lr: 0.100000\n",
            "2022-06-12 22:21:30,026 epoch 1 - iter 6/38 - loss 0.00545316 - samples/sec: 74.10 - lr: 0.100000\n",
            "2022-06-12 22:21:30,069 epoch 1 - iter 9/38 - loss 0.12949035 - samples/sec: 71.84 - lr: 0.100000\n",
            "2022-06-12 22:21:30,115 epoch 1 - iter 12/38 - loss 0.12112121 - samples/sec: 67.49 - lr: 0.100000\n",
            "2022-06-12 22:21:30,153 epoch 1 - iter 15/38 - loss 0.10058605 - samples/sec: 80.14 - lr: 0.100000\n",
            "2022-06-12 22:21:30,192 epoch 1 - iter 18/38 - loss 0.09741544 - samples/sec: 87.32 - lr: 0.100000\n",
            "2022-06-12 22:21:30,240 epoch 1 - iter 21/38 - loss 0.08343428 - samples/sec: 64.40 - lr: 0.100000\n",
            "2022-06-12 22:21:30,282 epoch 1 - iter 24/38 - loss 0.07234348 - samples/sec: 75.19 - lr: 0.100000\n",
            "2022-06-12 22:21:30,320 epoch 1 - iter 27/38 - loss 0.07206152 - samples/sec: 80.66 - lr: 0.100000\n",
            "2022-06-12 22:21:30,367 epoch 1 - iter 30/38 - loss 0.06193088 - samples/sec: 65.94 - lr: 0.100000\n",
            "2022-06-12 22:21:30,416 epoch 1 - iter 33/38 - loss 0.06580991 - samples/sec: 63.14 - lr: 0.100000\n",
            "2022-06-12 22:21:30,459 epoch 1 - iter 36/38 - loss 0.06748238 - samples/sec: 74.73 - lr: 0.100000\n",
            "2022-06-12 22:21:30,495 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:30,499 EPOCH 1 done: loss 0.0799 - lr 0.100000\n",
            "2022-06-12 22:21:30,500 BAD EPOCHS (no improvement): 0\n",
            "2022-06-12 22:21:30,506 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:30,545 epoch 2 - iter 3/38 - loss 0.00350380 - samples/sec: 84.47 - lr: 0.100000\n",
            "2022-06-12 22:21:30,586 epoch 2 - iter 6/38 - loss 0.04890664 - samples/sec: 78.64 - lr: 0.100000\n",
            "2022-06-12 22:21:30,624 epoch 2 - iter 9/38 - loss 0.03373243 - samples/sec: 88.72 - lr: 0.100000\n",
            "2022-06-12 22:21:30,660 epoch 2 - iter 12/38 - loss 0.02746935 - samples/sec: 86.82 - lr: 0.100000\n",
            "2022-06-12 22:21:30,705 epoch 2 - iter 15/38 - loss 0.02767458 - samples/sec: 68.44 - lr: 0.100000\n",
            "2022-06-12 22:21:30,743 epoch 2 - iter 18/38 - loss 0.02328140 - samples/sec: 81.18 - lr: 0.100000\n",
            "2022-06-12 22:21:30,790 epoch 2 - iter 21/38 - loss 0.01852670 - samples/sec: 66.00 - lr: 0.100000\n",
            "2022-06-12 22:21:30,839 epoch 2 - iter 24/38 - loss 0.01689582 - samples/sec: 66.72 - lr: 0.100000\n",
            "2022-06-12 22:21:30,879 epoch 2 - iter 27/38 - loss 0.04087317 - samples/sec: 76.05 - lr: 0.100000\n",
            "2022-06-12 22:21:30,920 epoch 2 - iter 30/38 - loss 0.05735054 - samples/sec: 80.64 - lr: 0.100000\n",
            "2022-06-12 22:21:30,955 epoch 2 - iter 33/38 - loss 0.05452469 - samples/sec: 96.18 - lr: 0.100000\n",
            "2022-06-12 22:21:30,992 epoch 2 - iter 36/38 - loss 0.06363195 - samples/sec: 83.84 - lr: 0.100000\n",
            "2022-06-12 22:21:31,021 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:31,022 EPOCH 2 done: loss 0.0593 - lr 0.100000\n",
            "2022-06-12 22:21:31,024 BAD EPOCHS (no improvement): 0\n",
            "2022-06-12 22:21:31,027 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:31,069 epoch 3 - iter 3/38 - loss 0.10879135 - samples/sec: 89.73 - lr: 0.100000\n",
            "2022-06-12 22:21:31,111 epoch 3 - iter 6/38 - loss 0.17466531 - samples/sec: 76.61 - lr: 0.100000\n",
            "2022-06-12 22:21:31,149 epoch 3 - iter 9/38 - loss 0.13123548 - samples/sec: 82.16 - lr: 0.100000\n",
            "2022-06-12 22:21:31,186 epoch 3 - iter 12/38 - loss 0.10456682 - samples/sec: 82.62 - lr: 0.100000\n",
            "2022-06-12 22:21:31,232 epoch 3 - iter 15/38 - loss 0.07618819 - samples/sec: 67.46 - lr: 0.100000\n",
            "2022-06-12 22:21:31,268 epoch 3 - iter 18/38 - loss 0.07425476 - samples/sec: 91.20 - lr: 0.100000\n",
            "2022-06-12 22:21:31,306 epoch 3 - iter 21/38 - loss 0.06660884 - samples/sec: 82.47 - lr: 0.100000\n",
            "2022-06-12 22:21:31,345 epoch 3 - iter 24/38 - loss 0.11012968 - samples/sec: 78.59 - lr: 0.100000\n",
            "2022-06-12 22:21:31,394 epoch 3 - iter 27/38 - loss 0.09227223 - samples/sec: 63.00 - lr: 0.100000\n",
            "2022-06-12 22:21:31,462 epoch 3 - iter 30/38 - loss 0.08797675 - samples/sec: 45.18 - lr: 0.100000\n",
            "2022-06-12 22:21:31,518 epoch 3 - iter 33/38 - loss 0.08781705 - samples/sec: 55.35 - lr: 0.100000\n",
            "2022-06-12 22:21:31,565 epoch 3 - iter 36/38 - loss 0.08320556 - samples/sec: 74.27 - lr: 0.100000\n",
            "2022-06-12 22:21:31,616 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:31,619 EPOCH 3 done: loss 0.0814 - lr 0.100000\n",
            "2022-06-12 22:21:31,626 BAD EPOCHS (no improvement): 1\n",
            "2022-06-12 22:21:31,632 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:31,714 epoch 4 - iter 3/38 - loss 0.14184443 - samples/sec: 40.86 - lr: 0.100000\n",
            "2022-06-12 22:21:31,795 epoch 4 - iter 6/38 - loss 0.24663044 - samples/sec: 43.95 - lr: 0.100000\n",
            "2022-06-12 22:21:31,886 epoch 4 - iter 9/38 - loss 0.18310146 - samples/sec: 35.17 - lr: 0.100000\n",
            "2022-06-12 22:21:31,952 epoch 4 - iter 12/38 - loss 0.15177739 - samples/sec: 50.19 - lr: 0.100000\n",
            "2022-06-12 22:21:31,999 epoch 4 - iter 15/38 - loss 0.11903371 - samples/sec: 66.22 - lr: 0.100000\n",
            "2022-06-12 22:21:32,040 epoch 4 - iter 18/38 - loss 0.15628212 - samples/sec: 75.02 - lr: 0.100000\n",
            "2022-06-12 22:21:32,085 epoch 4 - iter 21/38 - loss 0.15192155 - samples/sec: 69.56 - lr: 0.100000\n",
            "2022-06-12 22:21:32,127 epoch 4 - iter 24/38 - loss 0.13033193 - samples/sec: 74.18 - lr: 0.100000\n",
            "2022-06-12 22:21:32,168 epoch 4 - iter 27/38 - loss 0.11856050 - samples/sec: 74.33 - lr: 0.100000\n",
            "2022-06-12 22:21:32,202 epoch 4 - iter 30/38 - loss 0.11350758 - samples/sec: 93.58 - lr: 0.100000\n",
            "2022-06-12 22:21:32,238 epoch 4 - iter 33/38 - loss 0.10724809 - samples/sec: 85.01 - lr: 0.100000\n",
            "2022-06-12 22:21:32,278 epoch 4 - iter 36/38 - loss 0.09876886 - samples/sec: 80.85 - lr: 0.100000\n",
            "2022-06-12 22:21:32,304 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:32,306 EPOCH 4 done: loss 0.0956 - lr 0.100000\n",
            "2022-06-12 22:21:32,308 BAD EPOCHS (no improvement): 2\n",
            "2022-06-12 22:21:32,310 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:32,352 epoch 5 - iter 3/38 - loss 0.13276109 - samples/sec: 78.15 - lr: 0.100000\n",
            "2022-06-12 22:21:32,393 epoch 5 - iter 6/38 - loss 0.27181337 - samples/sec: 76.70 - lr: 0.100000\n",
            "2022-06-12 22:21:32,432 epoch 5 - iter 9/38 - loss 0.18165174 - samples/sec: 78.29 - lr: 0.100000\n",
            "2022-06-12 22:21:32,468 epoch 5 - iter 12/38 - loss 0.15911901 - samples/sec: 85.93 - lr: 0.100000\n",
            "2022-06-12 22:21:32,508 epoch 5 - iter 15/38 - loss 0.12538984 - samples/sec: 77.71 - lr: 0.100000\n",
            "2022-06-12 22:21:32,546 epoch 5 - iter 18/38 - loss 0.11644869 - samples/sec: 82.96 - lr: 0.100000\n",
            "2022-06-12 22:21:32,584 epoch 5 - iter 21/38 - loss 0.11361515 - samples/sec: 84.74 - lr: 0.100000\n",
            "2022-06-12 22:21:32,622 epoch 5 - iter 24/38 - loss 0.10472734 - samples/sec: 81.50 - lr: 0.100000\n",
            "2022-06-12 22:21:32,667 epoch 5 - iter 27/38 - loss 0.13056506 - samples/sec: 67.74 - lr: 0.100000\n",
            "2022-06-12 22:21:32,709 epoch 5 - iter 30/38 - loss 0.14112398 - samples/sec: 77.30 - lr: 0.100000\n",
            "2022-06-12 22:21:32,745 epoch 5 - iter 33/38 - loss 0.13463413 - samples/sec: 87.54 - lr: 0.100000\n",
            "2022-06-12 22:21:32,785 epoch 5 - iter 36/38 - loss 0.13715483 - samples/sec: 79.68 - lr: 0.100000\n",
            "2022-06-12 22:21:32,819 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:32,820 EPOCH 5 done: loss 0.1289 - lr 0.100000\n",
            "2022-06-12 22:21:32,825 BAD EPOCHS (no improvement): 3\n",
            "2022-06-12 22:21:32,831 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:32,872 epoch 6 - iter 3/38 - loss 0.01868221 - samples/sec: 76.72 - lr: 0.100000\n",
            "2022-06-12 22:21:32,910 epoch 6 - iter 6/38 - loss 0.01093432 - samples/sec: 82.78 - lr: 0.100000\n",
            "2022-06-12 22:21:32,954 epoch 6 - iter 9/38 - loss 0.00917292 - samples/sec: 70.96 - lr: 0.100000\n",
            "2022-06-12 22:21:32,995 epoch 6 - iter 12/38 - loss 0.00694904 - samples/sec: 75.43 - lr: 0.100000\n",
            "2022-06-12 22:21:33,033 epoch 6 - iter 15/38 - loss 0.01551099 - samples/sec: 80.52 - lr: 0.100000\n",
            "2022-06-12 22:21:33,072 epoch 6 - iter 18/38 - loss 0.01366807 - samples/sec: 85.22 - lr: 0.100000\n",
            "2022-06-12 22:21:33,115 epoch 6 - iter 21/38 - loss 0.01828928 - samples/sec: 77.67 - lr: 0.100000\n",
            "2022-06-12 22:21:33,153 epoch 6 - iter 24/38 - loss 0.06318386 - samples/sec: 83.90 - lr: 0.100000\n",
            "2022-06-12 22:21:33,192 epoch 6 - iter 27/38 - loss 0.07211964 - samples/sec: 80.39 - lr: 0.100000\n",
            "2022-06-12 22:21:33,232 epoch 6 - iter 30/38 - loss 0.06767927 - samples/sec: 76.76 - lr: 0.100000\n",
            "2022-06-12 22:21:33,280 epoch 6 - iter 33/38 - loss 0.07749387 - samples/sec: 64.16 - lr: 0.100000\n",
            "2022-06-12 22:21:33,324 epoch 6 - iter 36/38 - loss 0.07370677 - samples/sec: 71.57 - lr: 0.100000\n",
            "2022-06-12 22:21:33,348 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:33,351 EPOCH 6 done: loss 0.0731 - lr 0.100000\n",
            "2022-06-12 22:21:33,352 Epoch     6: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2022-06-12 22:21:33,355 BAD EPOCHS (no improvement): 4\n",
            "2022-06-12 22:21:33,362 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:33,404 epoch 7 - iter 3/38 - loss 0.37994512 - samples/sec: 80.14 - lr: 0.050000\n",
            "2022-06-12 22:21:33,444 epoch 7 - iter 6/38 - loss 0.21836126 - samples/sec: 83.43 - lr: 0.050000\n",
            "2022-06-12 22:21:33,483 epoch 7 - iter 9/38 - loss 0.15525615 - samples/sec: 84.17 - lr: 0.050000\n",
            "2022-06-12 22:21:33,526 epoch 7 - iter 12/38 - loss 0.10654612 - samples/sec: 70.67 - lr: 0.050000\n",
            "2022-06-12 22:21:33,574 epoch 7 - iter 15/38 - loss 0.10780165 - samples/sec: 64.87 - lr: 0.050000\n",
            "2022-06-12 22:21:33,614 epoch 7 - iter 18/38 - loss 0.09341345 - samples/sec: 80.83 - lr: 0.050000\n",
            "2022-06-12 22:21:33,656 epoch 7 - iter 21/38 - loss 0.11153086 - samples/sec: 76.62 - lr: 0.050000\n",
            "2022-06-12 22:21:33,698 epoch 7 - iter 24/38 - loss 0.14819375 - samples/sec: 75.01 - lr: 0.050000\n",
            "2022-06-12 22:21:33,742 epoch 7 - iter 27/38 - loss 0.12540886 - samples/sec: 69.67 - lr: 0.050000\n",
            "2022-06-12 22:21:33,778 epoch 7 - iter 30/38 - loss 0.11836769 - samples/sec: 87.02 - lr: 0.050000\n",
            "2022-06-12 22:21:33,816 epoch 7 - iter 33/38 - loss 0.11518310 - samples/sec: 81.23 - lr: 0.050000\n",
            "2022-06-12 22:21:33,854 epoch 7 - iter 36/38 - loss 0.10878006 - samples/sec: 81.97 - lr: 0.050000\n",
            "2022-06-12 22:21:33,881 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:33,882 EPOCH 7 done: loss 0.1064 - lr 0.050000\n",
            "2022-06-12 22:21:33,884 BAD EPOCHS (no improvement): 1\n",
            "2022-06-12 22:21:33,887 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:33,928 epoch 8 - iter 3/38 - loss 0.00267762 - samples/sec: 92.35 - lr: 0.050000\n",
            "2022-06-12 22:21:33,967 epoch 8 - iter 6/38 - loss 0.03059039 - samples/sec: 80.05 - lr: 0.050000\n",
            "2022-06-12 22:21:34,008 epoch 8 - iter 9/38 - loss 0.09228664 - samples/sec: 75.51 - lr: 0.050000\n",
            "2022-06-12 22:21:34,052 epoch 8 - iter 12/38 - loss 0.06639594 - samples/sec: 70.52 - lr: 0.050000\n",
            "2022-06-12 22:21:34,096 epoch 8 - iter 15/38 - loss 0.04969808 - samples/sec: 72.97 - lr: 0.050000\n",
            "2022-06-12 22:21:34,131 epoch 8 - iter 18/38 - loss 0.04510956 - samples/sec: 92.19 - lr: 0.050000\n",
            "2022-06-12 22:21:34,170 epoch 8 - iter 21/38 - loss 0.03989183 - samples/sec: 81.19 - lr: 0.050000\n",
            "2022-06-12 22:21:34,207 epoch 8 - iter 24/38 - loss 0.03607120 - samples/sec: 82.76 - lr: 0.050000\n",
            "2022-06-12 22:21:34,245 epoch 8 - iter 27/38 - loss 0.03261758 - samples/sec: 82.81 - lr: 0.050000\n",
            "2022-06-12 22:21:34,287 epoch 8 - iter 30/38 - loss 0.02987518 - samples/sec: 73.23 - lr: 0.050000\n",
            "2022-06-12 22:21:34,323 epoch 8 - iter 33/38 - loss 0.02804156 - samples/sec: 87.74 - lr: 0.050000\n",
            "2022-06-12 22:21:34,367 epoch 8 - iter 36/38 - loss 0.02880903 - samples/sec: 69.59 - lr: 0.050000\n",
            "2022-06-12 22:21:34,398 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:34,400 EPOCH 8 done: loss 0.0282 - lr 0.050000\n",
            "2022-06-12 22:21:34,402 BAD EPOCHS (no improvement): 0\n",
            "2022-06-12 22:21:34,405 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:34,457 epoch 9 - iter 3/38 - loss 0.20033959 - samples/sec: 69.59 - lr: 0.050000\n",
            "2022-06-12 22:21:34,497 epoch 9 - iter 6/38 - loss 0.18983121 - samples/sec: 80.30 - lr: 0.050000\n",
            "2022-06-12 22:21:34,539 epoch 9 - iter 9/38 - loss 0.21373242 - samples/sec: 73.93 - lr: 0.050000\n",
            "2022-06-12 22:21:34,579 epoch 9 - iter 12/38 - loss 0.16338655 - samples/sec: 77.68 - lr: 0.050000\n",
            "2022-06-12 22:21:34,617 epoch 9 - iter 15/38 - loss 0.13886869 - samples/sec: 81.64 - lr: 0.050000\n",
            "2022-06-12 22:21:34,654 epoch 9 - iter 18/38 - loss 0.12152564 - samples/sec: 85.37 - lr: 0.050000\n",
            "2022-06-12 22:21:34,693 epoch 9 - iter 21/38 - loss 0.11889317 - samples/sec: 79.17 - lr: 0.050000\n",
            "2022-06-12 22:21:34,734 epoch 9 - iter 24/38 - loss 0.10355354 - samples/sec: 80.41 - lr: 0.050000\n",
            "2022-06-12 22:21:34,773 epoch 9 - iter 27/38 - loss 0.09325504 - samples/sec: 84.72 - lr: 0.050000\n",
            "2022-06-12 22:21:34,810 epoch 9 - iter 30/38 - loss 0.08555273 - samples/sec: 83.61 - lr: 0.050000\n",
            "2022-06-12 22:21:34,851 epoch 9 - iter 33/38 - loss 0.07875269 - samples/sec: 75.95 - lr: 0.050000\n",
            "2022-06-12 22:21:34,901 epoch 9 - iter 36/38 - loss 0.06980215 - samples/sec: 65.32 - lr: 0.050000\n",
            "2022-06-12 22:21:34,928 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:34,929 EPOCH 9 done: loss 0.0687 - lr 0.050000\n",
            "2022-06-12 22:21:34,931 BAD EPOCHS (no improvement): 1\n",
            "2022-06-12 22:21:34,934 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:34,976 epoch 10 - iter 3/38 - loss 0.00598056 - samples/sec: 89.80 - lr: 0.050000\n",
            "2022-06-12 22:21:35,014 epoch 10 - iter 6/38 - loss 0.00323937 - samples/sec: 81.05 - lr: 0.050000\n",
            "2022-06-12 22:21:35,053 epoch 10 - iter 9/38 - loss 0.00306759 - samples/sec: 80.67 - lr: 0.050000\n",
            "2022-06-12 22:21:35,089 epoch 10 - iter 12/38 - loss 0.04277517 - samples/sec: 88.71 - lr: 0.050000\n",
            "2022-06-12 22:21:35,134 epoch 10 - iter 15/38 - loss 0.08746982 - samples/sec: 67.68 - lr: 0.050000\n",
            "2022-06-12 22:21:35,171 epoch 10 - iter 18/38 - loss 0.07631747 - samples/sec: 83.54 - lr: 0.050000\n",
            "2022-06-12 22:21:35,212 epoch 10 - iter 21/38 - loss 0.06951540 - samples/sec: 76.77 - lr: 0.050000\n",
            "2022-06-12 22:21:35,253 epoch 10 - iter 24/38 - loss 0.08126517 - samples/sec: 75.86 - lr: 0.050000\n",
            "2022-06-12 22:21:35,291 epoch 10 - iter 27/38 - loss 0.07429736 - samples/sec: 83.90 - lr: 0.050000\n",
            "2022-06-12 22:21:35,331 epoch 10 - iter 30/38 - loss 0.06877475 - samples/sec: 78.51 - lr: 0.050000\n",
            "2022-06-12 22:21:35,372 epoch 10 - iter 33/38 - loss 0.06702607 - samples/sec: 74.65 - lr: 0.050000\n",
            "2022-06-12 22:21:35,416 epoch 10 - iter 36/38 - loss 0.05931711 - samples/sec: 70.22 - lr: 0.050000\n",
            "2022-06-12 22:21:35,442 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:35,443 EPOCH 10 done: loss 0.0587 - lr 0.050000\n",
            "2022-06-12 22:21:35,446 BAD EPOCHS (no improvement): 2\n",
            "2022-06-12 22:21:35,448 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:35,494 epoch 11 - iter 3/38 - loss 0.10251060 - samples/sec: 72.40 - lr: 0.050000\n",
            "2022-06-12 22:21:35,538 epoch 11 - iter 6/38 - loss 0.05356909 - samples/sec: 71.71 - lr: 0.050000\n",
            "2022-06-12 22:21:35,577 epoch 11 - iter 9/38 - loss 0.03987534 - samples/sec: 86.00 - lr: 0.050000\n",
            "2022-06-12 22:21:35,619 epoch 11 - iter 12/38 - loss 0.09926055 - samples/sec: 78.93 - lr: 0.050000\n",
            "2022-06-12 22:21:35,657 epoch 11 - iter 15/38 - loss 0.08489233 - samples/sec: 82.98 - lr: 0.050000\n",
            "2022-06-12 22:21:35,700 epoch 11 - iter 18/38 - loss 0.07406404 - samples/sec: 70.80 - lr: 0.050000\n",
            "2022-06-12 22:21:35,739 epoch 11 - iter 21/38 - loss 0.06681307 - samples/sec: 86.35 - lr: 0.050000\n",
            "2022-06-12 22:21:35,774 epoch 11 - iter 24/38 - loss 0.06186115 - samples/sec: 89.66 - lr: 0.050000\n",
            "2022-06-12 22:21:35,811 epoch 11 - iter 27/38 - loss 0.05622651 - samples/sec: 83.14 - lr: 0.050000\n",
            "2022-06-12 22:21:35,851 epoch 11 - iter 30/38 - loss 0.05187855 - samples/sec: 77.07 - lr: 0.050000\n",
            "2022-06-12 22:21:35,891 epoch 11 - iter 33/38 - loss 0.05192932 - samples/sec: 78.87 - lr: 0.050000\n",
            "2022-06-12 22:21:35,937 epoch 11 - iter 36/38 - loss 0.05005937 - samples/sec: 69.09 - lr: 0.050000\n",
            "2022-06-12 22:21:35,963 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:35,964 EPOCH 11 done: loss 0.0654 - lr 0.050000\n",
            "2022-06-12 22:21:35,967 BAD EPOCHS (no improvement): 3\n",
            "2022-06-12 22:21:35,969 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:36,013 epoch 12 - iter 3/38 - loss 0.03731003 - samples/sec: 85.04 - lr: 0.050000\n",
            "2022-06-12 22:21:36,052 epoch 12 - iter 6/38 - loss 0.02340940 - samples/sec: 78.18 - lr: 0.050000\n",
            "2022-06-12 22:21:36,093 epoch 12 - iter 9/38 - loss 0.01704213 - samples/sec: 83.58 - lr: 0.050000\n",
            "2022-06-12 22:21:36,128 epoch 12 - iter 12/38 - loss 0.02380092 - samples/sec: 98.23 - lr: 0.050000\n",
            "2022-06-12 22:21:36,166 epoch 12 - iter 15/38 - loss 0.02012393 - samples/sec: 80.22 - lr: 0.050000\n",
            "2022-06-12 22:21:36,202 epoch 12 - iter 18/38 - loss 0.01768851 - samples/sec: 87.16 - lr: 0.050000\n",
            "2022-06-12 22:21:36,242 epoch 12 - iter 21/38 - loss 0.01523245 - samples/sec: 86.08 - lr: 0.050000\n",
            "2022-06-12 22:21:36,285 epoch 12 - iter 24/38 - loss 0.04763889 - samples/sec: 71.47 - lr: 0.050000\n",
            "2022-06-12 22:21:36,324 epoch 12 - iter 27/38 - loss 0.04521763 - samples/sec: 80.52 - lr: 0.050000\n",
            "2022-06-12 22:21:36,365 epoch 12 - iter 30/38 - loss 0.03953197 - samples/sec: 74.28 - lr: 0.050000\n",
            "2022-06-12 22:21:36,405 epoch 12 - iter 33/38 - loss 0.04262266 - samples/sec: 77.78 - lr: 0.050000\n",
            "2022-06-12 22:21:36,448 epoch 12 - iter 36/38 - loss 0.05526012 - samples/sec: 75.74 - lr: 0.050000\n",
            "2022-06-12 22:21:36,481 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:36,485 EPOCH 12 done: loss 0.0500 - lr 0.050000\n",
            "2022-06-12 22:21:36,486 Epoch    12: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2022-06-12 22:21:36,492 BAD EPOCHS (no improvement): 4\n",
            "2022-06-12 22:21:36,496 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:36,540 epoch 13 - iter 3/38 - loss 0.01458710 - samples/sec: 74.67 - lr: 0.025000\n",
            "2022-06-12 22:21:36,583 epoch 13 - iter 6/38 - loss 0.00964580 - samples/sec: 78.28 - lr: 0.025000\n",
            "2022-06-12 22:21:36,624 epoch 13 - iter 9/38 - loss 0.00752836 - samples/sec: 75.13 - lr: 0.025000\n",
            "2022-06-12 22:21:36,663 epoch 13 - iter 12/38 - loss 0.01303962 - samples/sec: 83.97 - lr: 0.025000\n",
            "2022-06-12 22:21:36,702 epoch 13 - iter 15/38 - loss 0.01131957 - samples/sec: 84.72 - lr: 0.025000\n",
            "2022-06-12 22:21:36,743 epoch 13 - iter 18/38 - loss 0.02361062 - samples/sec: 77.92 - lr: 0.025000\n",
            "2022-06-12 22:21:36,780 epoch 13 - iter 21/38 - loss 0.02243771 - samples/sec: 89.99 - lr: 0.025000\n",
            "2022-06-12 22:21:36,815 epoch 13 - iter 24/38 - loss 0.02118908 - samples/sec: 96.60 - lr: 0.025000\n",
            "2022-06-12 22:21:36,860 epoch 13 - iter 27/38 - loss 0.04661938 - samples/sec: 68.53 - lr: 0.025000\n",
            "2022-06-12 22:21:36,900 epoch 13 - iter 30/38 - loss 0.04202761 - samples/sec: 84.03 - lr: 0.025000\n",
            "2022-06-12 22:21:36,943 epoch 13 - iter 33/38 - loss 0.03837474 - samples/sec: 72.59 - lr: 0.025000\n",
            "2022-06-12 22:21:36,987 epoch 13 - iter 36/38 - loss 0.04979433 - samples/sec: 69.29 - lr: 0.025000\n",
            "2022-06-12 22:21:37,014 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:37,015 EPOCH 13 done: loss 0.0552 - lr 0.025000\n",
            "2022-06-12 22:21:37,017 BAD EPOCHS (no improvement): 1\n",
            "2022-06-12 22:21:37,020 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:37,064 epoch 14 - iter 3/38 - loss 0.03468704 - samples/sec: 82.63 - lr: 0.025000\n",
            "2022-06-12 22:21:37,100 epoch 14 - iter 6/38 - loss 0.02129605 - samples/sec: 86.60 - lr: 0.025000\n",
            "2022-06-12 22:21:37,139 epoch 14 - iter 9/38 - loss 0.02016117 - samples/sec: 86.67 - lr: 0.025000\n",
            "2022-06-12 22:21:37,182 epoch 14 - iter 12/38 - loss 0.01708751 - samples/sec: 76.01 - lr: 0.025000\n",
            "2022-06-12 22:21:37,224 epoch 14 - iter 15/38 - loss 0.01326669 - samples/sec: 74.06 - lr: 0.025000\n",
            "2022-06-12 22:21:37,263 epoch 14 - iter 18/38 - loss 0.05002587 - samples/sec: 85.63 - lr: 0.025000\n",
            "2022-06-12 22:21:37,305 epoch 14 - iter 21/38 - loss 0.04624686 - samples/sec: 76.51 - lr: 0.025000\n",
            "2022-06-12 22:21:37,340 epoch 14 - iter 24/38 - loss 0.04288680 - samples/sec: 89.10 - lr: 0.025000\n",
            "2022-06-12 22:21:37,379 epoch 14 - iter 27/38 - loss 0.04637228 - samples/sec: 81.79 - lr: 0.025000\n",
            "2022-06-12 22:21:37,425 epoch 14 - iter 30/38 - loss 0.04121051 - samples/sec: 66.22 - lr: 0.025000\n",
            "2022-06-12 22:21:37,473 epoch 14 - iter 33/38 - loss 0.03682930 - samples/sec: 68.02 - lr: 0.025000\n",
            "2022-06-12 22:21:37,513 epoch 14 - iter 36/38 - loss 0.04920566 - samples/sec: 84.03 - lr: 0.025000\n",
            "2022-06-12 22:21:37,541 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:37,545 EPOCH 14 done: loss 0.0475 - lr 0.025000\n",
            "2022-06-12 22:21:37,546 BAD EPOCHS (no improvement): 2\n",
            "2022-06-12 22:21:37,555 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:37,595 epoch 15 - iter 3/38 - loss 0.25323105 - samples/sec: 85.12 - lr: 0.025000\n",
            "2022-06-12 22:21:37,645 epoch 15 - iter 6/38 - loss 0.08168594 - samples/sec: 66.33 - lr: 0.025000\n",
            "2022-06-12 22:21:37,684 epoch 15 - iter 9/38 - loss 0.06146052 - samples/sec: 86.00 - lr: 0.025000\n",
            "2022-06-12 22:21:37,723 epoch 15 - iter 12/38 - loss 0.06143000 - samples/sec: 79.31 - lr: 0.025000\n",
            "2022-06-12 22:21:37,768 epoch 15 - iter 15/38 - loss 0.04789827 - samples/sec: 72.70 - lr: 0.025000\n",
            "2022-06-12 22:21:37,808 epoch 15 - iter 18/38 - loss 0.04039529 - samples/sec: 77.44 - lr: 0.025000\n",
            "2022-06-12 22:21:37,846 epoch 15 - iter 21/38 - loss 0.03572773 - samples/sec: 81.35 - lr: 0.025000\n",
            "2022-06-12 22:21:37,883 epoch 15 - iter 24/38 - loss 0.03272009 - samples/sec: 90.93 - lr: 0.025000\n",
            "2022-06-12 22:21:37,925 epoch 15 - iter 27/38 - loss 0.02873441 - samples/sec: 72.19 - lr: 0.025000\n",
            "2022-06-12 22:21:37,967 epoch 15 - iter 30/38 - loss 0.02668490 - samples/sec: 79.56 - lr: 0.025000\n",
            "2022-06-12 22:21:38,004 epoch 15 - iter 33/38 - loss 0.02485084 - samples/sec: 86.58 - lr: 0.025000\n",
            "2022-06-12 22:21:38,046 epoch 15 - iter 36/38 - loss 0.03040566 - samples/sec: 74.91 - lr: 0.025000\n",
            "2022-06-12 22:21:38,075 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:38,076 EPOCH 15 done: loss 0.0328 - lr 0.025000\n",
            "2022-06-12 22:21:38,078 BAD EPOCHS (no improvement): 3\n",
            "2022-06-12 22:21:38,082 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:38,127 epoch 16 - iter 3/38 - loss 0.03106580 - samples/sec: 75.39 - lr: 0.025000\n",
            "2022-06-12 22:21:38,169 epoch 16 - iter 6/38 - loss 0.02257265 - samples/sec: 76.05 - lr: 0.025000\n",
            "2022-06-12 22:21:38,212 epoch 16 - iter 9/38 - loss 0.01675593 - samples/sec: 77.80 - lr: 0.025000\n",
            "2022-06-12 22:21:38,255 epoch 16 - iter 12/38 - loss 0.01317211 - samples/sec: 71.39 - lr: 0.025000\n",
            "2022-06-12 22:21:38,293 epoch 16 - iter 15/38 - loss 0.03488979 - samples/sec: 90.04 - lr: 0.025000\n",
            "2022-06-12 22:21:38,331 epoch 16 - iter 18/38 - loss 0.03011130 - samples/sec: 81.25 - lr: 0.025000\n",
            "2022-06-12 22:21:38,372 epoch 16 - iter 21/38 - loss 0.02568145 - samples/sec: 75.97 - lr: 0.025000\n",
            "2022-06-12 22:21:38,409 epoch 16 - iter 24/38 - loss 0.03459543 - samples/sec: 87.20 - lr: 0.025000\n",
            "2022-06-12 22:21:38,448 epoch 16 - iter 27/38 - loss 0.03641752 - samples/sec: 84.94 - lr: 0.025000\n",
            "2022-06-12 22:21:38,488 epoch 16 - iter 30/38 - loss 0.03284622 - samples/sec: 76.56 - lr: 0.025000\n",
            "2022-06-12 22:21:38,530 epoch 16 - iter 33/38 - loss 0.03024073 - samples/sec: 73.30 - lr: 0.025000\n",
            "2022-06-12 22:21:38,568 epoch 16 - iter 36/38 - loss 0.02851582 - samples/sec: 83.73 - lr: 0.025000\n",
            "2022-06-12 22:21:38,596 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:38,597 EPOCH 16 done: loss 0.0277 - lr 0.025000\n",
            "2022-06-12 22:21:38,600 BAD EPOCHS (no improvement): 0\n",
            "2022-06-12 22:21:38,603 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:38,645 epoch 17 - iter 3/38 - loss 0.00160711 - samples/sec: 79.95 - lr: 0.025000\n",
            "2022-06-12 22:21:38,684 epoch 17 - iter 6/38 - loss 0.00504854 - samples/sec: 80.62 - lr: 0.025000\n",
            "2022-06-12 22:21:38,721 epoch 17 - iter 9/38 - loss 0.00359704 - samples/sec: 85.02 - lr: 0.025000\n",
            "2022-06-12 22:21:38,759 epoch 17 - iter 12/38 - loss 0.00800552 - samples/sec: 82.81 - lr: 0.025000\n",
            "2022-06-12 22:21:38,799 epoch 17 - iter 15/38 - loss 0.05183477 - samples/sec: 77.41 - lr: 0.025000\n",
            "2022-06-12 22:21:38,839 epoch 17 - iter 18/38 - loss 0.04419257 - samples/sec: 77.94 - lr: 0.025000\n",
            "2022-06-12 22:21:38,880 epoch 17 - iter 21/38 - loss 0.10537842 - samples/sec: 75.64 - lr: 0.025000\n",
            "2022-06-12 22:21:38,917 epoch 17 - iter 24/38 - loss 0.09426809 - samples/sec: 90.16 - lr: 0.025000\n",
            "2022-06-12 22:21:38,962 epoch 17 - iter 27/38 - loss 0.09896036 - samples/sec: 67.61 - lr: 0.025000\n",
            "2022-06-12 22:21:39,001 epoch 17 - iter 30/38 - loss 0.09000672 - samples/sec: 81.84 - lr: 0.025000\n",
            "2022-06-12 22:21:39,044 epoch 17 - iter 33/38 - loss 0.08023472 - samples/sec: 76.43 - lr: 0.025000\n",
            "2022-06-12 22:21:39,086 epoch 17 - iter 36/38 - loss 0.07291637 - samples/sec: 74.99 - lr: 0.025000\n",
            "2022-06-12 22:21:39,118 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:39,120 EPOCH 17 done: loss 0.0735 - lr 0.025000\n",
            "2022-06-12 22:21:39,123 BAD EPOCHS (no improvement): 1\n",
            "2022-06-12 22:21:39,125 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:39,169 epoch 18 - iter 3/38 - loss 0.30903625 - samples/sec: 85.76 - lr: 0.025000\n",
            "2022-06-12 22:21:39,208 epoch 18 - iter 6/38 - loss 0.14363508 - samples/sec: 79.41 - lr: 0.025000\n",
            "2022-06-12 22:21:39,249 epoch 18 - iter 9/38 - loss 0.17743079 - samples/sec: 75.51 - lr: 0.025000\n",
            "2022-06-12 22:21:39,294 epoch 18 - iter 12/38 - loss 0.16141373 - samples/sec: 68.43 - lr: 0.025000\n",
            "2022-06-12 22:21:39,337 epoch 18 - iter 15/38 - loss 0.12286677 - samples/sec: 74.68 - lr: 0.025000\n",
            "2022-06-12 22:21:39,380 epoch 18 - iter 18/38 - loss 0.10122278 - samples/sec: 71.97 - lr: 0.025000\n",
            "2022-06-12 22:21:39,416 epoch 18 - iter 21/38 - loss 0.09288095 - samples/sec: 90.87 - lr: 0.025000\n",
            "2022-06-12 22:21:39,454 epoch 18 - iter 24/38 - loss 0.08816564 - samples/sec: 81.78 - lr: 0.025000\n",
            "2022-06-12 22:21:39,490 epoch 18 - iter 27/38 - loss 0.08290019 - samples/sec: 86.41 - lr: 0.025000\n",
            "2022-06-12 22:21:39,526 epoch 18 - iter 30/38 - loss 0.11143146 - samples/sec: 84.55 - lr: 0.025000\n",
            "2022-06-12 22:21:39,567 epoch 18 - iter 33/38 - loss 0.09981758 - samples/sec: 75.28 - lr: 0.025000\n",
            "2022-06-12 22:21:39,610 epoch 18 - iter 36/38 - loss 0.09347943 - samples/sec: 72.50 - lr: 0.025000\n",
            "2022-06-12 22:21:39,638 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:39,639 EPOCH 18 done: loss 0.0912 - lr 0.025000\n",
            "2022-06-12 22:21:39,642 BAD EPOCHS (no improvement): 2\n",
            "2022-06-12 22:21:39,644 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:39,688 epoch 19 - iter 3/38 - loss 0.00143388 - samples/sec: 77.44 - lr: 0.025000\n",
            "2022-06-12 22:21:39,728 epoch 19 - iter 6/38 - loss 0.12235184 - samples/sec: 78.06 - lr: 0.025000\n",
            "2022-06-12 22:21:39,772 epoch 19 - iter 9/38 - loss 0.07673181 - samples/sec: 70.46 - lr: 0.025000\n",
            "2022-06-12 22:21:39,808 epoch 19 - iter 12/38 - loss 0.06314178 - samples/sec: 89.13 - lr: 0.025000\n",
            "2022-06-12 22:21:39,853 epoch 19 - iter 15/38 - loss 0.05176700 - samples/sec: 69.46 - lr: 0.025000\n",
            "2022-06-12 22:21:39,892 epoch 19 - iter 18/38 - loss 0.04443465 - samples/sec: 78.62 - lr: 0.025000\n",
            "2022-06-12 22:21:39,932 epoch 19 - iter 21/38 - loss 0.04891128 - samples/sec: 80.66 - lr: 0.025000\n",
            "2022-06-12 22:21:39,971 epoch 19 - iter 24/38 - loss 0.04415249 - samples/sec: 79.50 - lr: 0.025000\n",
            "2022-06-12 22:21:40,017 epoch 19 - iter 27/38 - loss 0.03752660 - samples/sec: 71.32 - lr: 0.025000\n",
            "2022-06-12 22:21:40,060 epoch 19 - iter 30/38 - loss 0.03576840 - samples/sec: 76.49 - lr: 0.025000\n",
            "2022-06-12 22:21:40,097 epoch 19 - iter 33/38 - loss 0.03314036 - samples/sec: 88.29 - lr: 0.025000\n",
            "2022-06-12 22:21:40,139 epoch 19 - iter 36/38 - loss 0.03719864 - samples/sec: 73.26 - lr: 0.025000\n",
            "2022-06-12 22:21:40,165 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:40,166 EPOCH 19 done: loss 0.0365 - lr 0.025000\n",
            "2022-06-12 22:21:40,168 BAD EPOCHS (no improvement): 3\n",
            "2022-06-12 22:21:40,171 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:40,215 epoch 20 - iter 3/38 - loss 0.00212521 - samples/sec: 83.27 - lr: 0.025000\n",
            "2022-06-12 22:21:40,252 epoch 20 - iter 6/38 - loss 0.00186620 - samples/sec: 89.75 - lr: 0.025000\n",
            "2022-06-12 22:21:40,290 epoch 20 - iter 9/38 - loss 0.00217019 - samples/sec: 87.89 - lr: 0.025000\n",
            "2022-06-12 22:21:40,330 epoch 20 - iter 12/38 - loss 0.00164470 - samples/sec: 77.39 - lr: 0.025000\n",
            "2022-06-12 22:21:40,366 epoch 20 - iter 15/38 - loss 0.00178585 - samples/sec: 86.25 - lr: 0.025000\n",
            "2022-06-12 22:21:40,407 epoch 20 - iter 18/38 - loss 0.01507152 - samples/sec: 80.41 - lr: 0.025000\n",
            "2022-06-12 22:21:40,446 epoch 20 - iter 21/38 - loss 0.01347401 - samples/sec: 80.28 - lr: 0.025000\n",
            "2022-06-12 22:21:40,489 epoch 20 - iter 24/38 - loss 0.01539574 - samples/sec: 71.70 - lr: 0.025000\n",
            "2022-06-12 22:21:40,530 epoch 20 - iter 27/38 - loss 0.01376015 - samples/sec: 76.86 - lr: 0.025000\n",
            "2022-06-12 22:21:40,569 epoch 20 - iter 30/38 - loss 0.01264409 - samples/sec: 80.18 - lr: 0.025000\n",
            "2022-06-12 22:21:40,614 epoch 20 - iter 33/38 - loss 0.01166473 - samples/sec: 69.19 - lr: 0.025000\n",
            "2022-06-12 22:21:40,658 epoch 20 - iter 36/38 - loss 0.01073422 - samples/sec: 70.77 - lr: 0.025000\n",
            "2022-06-12 22:21:40,692 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:40,694 EPOCH 20 done: loss 0.0540 - lr 0.025000\n",
            "2022-06-12 22:21:40,696 Epoch    20: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2022-06-12 22:21:40,698 BAD EPOCHS (no improvement): 4\n",
            "2022-06-12 22:21:40,706 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:40,746 epoch 21 - iter 3/38 - loss 0.06405986 - samples/sec: 78.64 - lr: 0.012500\n",
            "2022-06-12 22:21:40,783 epoch 21 - iter 6/38 - loss 0.05382538 - samples/sec: 83.27 - lr: 0.012500\n",
            "2022-06-12 22:21:40,823 epoch 21 - iter 9/38 - loss 0.07315639 - samples/sec: 79.02 - lr: 0.012500\n",
            "2022-06-12 22:21:40,863 epoch 21 - iter 12/38 - loss 0.05528789 - samples/sec: 76.99 - lr: 0.012500\n",
            "2022-06-12 22:21:40,902 epoch 21 - iter 15/38 - loss 0.04464397 - samples/sec: 79.16 - lr: 0.012500\n",
            "2022-06-12 22:21:40,944 epoch 21 - iter 18/38 - loss 0.03650057 - samples/sec: 74.62 - lr: 0.012500\n",
            "2022-06-12 22:21:40,987 epoch 21 - iter 21/38 - loss 0.03016729 - samples/sec: 74.37 - lr: 0.012500\n",
            "2022-06-12 22:21:41,033 epoch 21 - iter 24/38 - loss 0.04560787 - samples/sec: 69.20 - lr: 0.012500\n",
            "2022-06-12 22:21:41,071 epoch 21 - iter 27/38 - loss 0.04592239 - samples/sec: 81.33 - lr: 0.012500\n",
            "2022-06-12 22:21:41,114 epoch 21 - iter 30/38 - loss 0.04770263 - samples/sec: 74.83 - lr: 0.012500\n",
            "2022-06-12 22:21:41,154 epoch 21 - iter 33/38 - loss 0.04384219 - samples/sec: 77.40 - lr: 0.012500\n",
            "2022-06-12 22:21:41,189 epoch 21 - iter 36/38 - loss 0.04196374 - samples/sec: 88.83 - lr: 0.012500\n",
            "2022-06-12 22:21:41,216 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:41,217 EPOCH 21 done: loss 0.0396 - lr 0.012500\n",
            "2022-06-12 22:21:41,219 BAD EPOCHS (no improvement): 1\n",
            "2022-06-12 22:21:41,222 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:41,274 epoch 22 - iter 3/38 - loss 0.00068296 - samples/sec: 67.75 - lr: 0.012500\n",
            "2022-06-12 22:21:41,316 epoch 22 - iter 6/38 - loss 0.00053847 - samples/sec: 73.75 - lr: 0.012500\n",
            "2022-06-12 22:21:41,351 epoch 22 - iter 9/38 - loss 0.00167678 - samples/sec: 89.91 - lr: 0.012500\n",
            "2022-06-12 22:21:41,391 epoch 22 - iter 12/38 - loss 0.00411589 - samples/sec: 77.41 - lr: 0.012500\n",
            "2022-06-12 22:21:41,427 epoch 22 - iter 15/38 - loss 0.00421139 - samples/sec: 88.38 - lr: 0.012500\n",
            "2022-06-12 22:21:41,469 epoch 22 - iter 18/38 - loss 0.00419503 - samples/sec: 73.52 - lr: 0.012500\n",
            "2022-06-12 22:21:41,509 epoch 22 - iter 21/38 - loss 0.00460723 - samples/sec: 78.31 - lr: 0.012500\n",
            "2022-06-12 22:21:41,548 epoch 22 - iter 24/38 - loss 0.00483946 - samples/sec: 79.12 - lr: 0.012500\n",
            "2022-06-12 22:21:41,589 epoch 22 - iter 27/38 - loss 0.00678019 - samples/sec: 75.44 - lr: 0.012500\n",
            "2022-06-12 22:21:41,625 epoch 22 - iter 30/38 - loss 0.01502973 - samples/sec: 90.29 - lr: 0.012500\n",
            "2022-06-12 22:21:41,666 epoch 22 - iter 33/38 - loss 0.03246786 - samples/sec: 75.74 - lr: 0.012500\n",
            "2022-06-12 22:21:41,702 epoch 22 - iter 36/38 - loss 0.03113775 - samples/sec: 86.45 - lr: 0.012500\n",
            "2022-06-12 22:21:41,732 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:41,733 EPOCH 22 done: loss 0.0392 - lr 0.012500\n",
            "2022-06-12 22:21:41,735 BAD EPOCHS (no improvement): 2\n",
            "2022-06-12 22:21:41,738 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:41,784 epoch 23 - iter 3/38 - loss 0.08954407 - samples/sec: 80.00 - lr: 0.012500\n",
            "2022-06-12 22:21:41,821 epoch 23 - iter 6/38 - loss 0.09449205 - samples/sec: 86.98 - lr: 0.012500\n",
            "2022-06-12 22:21:41,859 epoch 23 - iter 9/38 - loss 0.06623671 - samples/sec: 82.15 - lr: 0.012500\n",
            "2022-06-12 22:21:41,900 epoch 23 - iter 12/38 - loss 0.04991903 - samples/sec: 74.93 - lr: 0.012500\n",
            "2022-06-12 22:21:41,939 epoch 23 - iter 15/38 - loss 0.04085110 - samples/sec: 83.74 - lr: 0.012500\n",
            "2022-06-12 22:21:41,979 epoch 23 - iter 18/38 - loss 0.03321704 - samples/sec: 76.33 - lr: 0.012500\n",
            "2022-06-12 22:21:42,023 epoch 23 - iter 21/38 - loss 0.02885638 - samples/sec: 71.80 - lr: 0.012500\n",
            "2022-06-12 22:21:42,067 epoch 23 - iter 24/38 - loss 0.03003130 - samples/sec: 69.40 - lr: 0.012500\n",
            "2022-06-12 22:21:42,110 epoch 23 - iter 27/38 - loss 0.02583721 - samples/sec: 75.47 - lr: 0.012500\n",
            "2022-06-12 22:21:42,146 epoch 23 - iter 30/38 - loss 0.02395436 - samples/sec: 84.91 - lr: 0.012500\n",
            "2022-06-12 22:21:42,186 epoch 23 - iter 33/38 - loss 0.03188749 - samples/sec: 77.91 - lr: 0.012500\n",
            "2022-06-12 22:21:42,229 epoch 23 - iter 36/38 - loss 0.03021778 - samples/sec: 71.59 - lr: 0.012500\n",
            "2022-06-12 22:21:42,254 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:42,255 EPOCH 23 done: loss 0.0292 - lr 0.012500\n",
            "2022-06-12 22:21:42,257 BAD EPOCHS (no improvement): 3\n",
            "2022-06-12 22:21:42,260 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:42,312 epoch 24 - iter 3/38 - loss 0.05991618 - samples/sec: 75.90 - lr: 0.012500\n",
            "2022-06-12 22:21:42,349 epoch 24 - iter 6/38 - loss 0.03916865 - samples/sec: 84.11 - lr: 0.012500\n",
            "2022-06-12 22:21:42,392 epoch 24 - iter 9/38 - loss 0.03650007 - samples/sec: 75.27 - lr: 0.012500\n",
            "2022-06-12 22:21:42,431 epoch 24 - iter 12/38 - loss 0.02992299 - samples/sec: 83.69 - lr: 0.012500\n",
            "2022-06-12 22:21:42,469 epoch 24 - iter 15/38 - loss 0.02520038 - samples/sec: 84.74 - lr: 0.012500\n",
            "2022-06-12 22:21:42,511 epoch 24 - iter 18/38 - loss 0.02225090 - samples/sec: 77.24 - lr: 0.012500\n",
            "2022-06-12 22:21:42,550 epoch 24 - iter 21/38 - loss 0.01980468 - samples/sec: 82.64 - lr: 0.012500\n",
            "2022-06-12 22:21:42,593 epoch 24 - iter 24/38 - loss 0.01958957 - samples/sec: 72.61 - lr: 0.012500\n",
            "2022-06-12 22:21:42,636 epoch 24 - iter 27/38 - loss 0.04930139 - samples/sec: 71.91 - lr: 0.012500\n",
            "2022-06-12 22:21:42,673 epoch 24 - iter 30/38 - loss 0.04610471 - samples/sec: 83.33 - lr: 0.012500\n",
            "2022-06-12 22:21:42,715 epoch 24 - iter 33/38 - loss 0.04331788 - samples/sec: 77.82 - lr: 0.012500\n",
            "2022-06-12 22:21:42,752 epoch 24 - iter 36/38 - loss 0.04153946 - samples/sec: 88.96 - lr: 0.012500\n",
            "2022-06-12 22:21:42,777 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:42,778 EPOCH 24 done: loss 0.0488 - lr 0.012500\n",
            "2022-06-12 22:21:42,781 Epoch    24: reducing learning rate of group 0 to 6.2500e-03.\n",
            "2022-06-12 22:21:42,783 BAD EPOCHS (no improvement): 4\n",
            "2022-06-12 22:21:42,789 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:42,835 epoch 25 - iter 3/38 - loss 0.03951974 - samples/sec: 68.05 - lr: 0.006250\n",
            "2022-06-12 22:21:42,872 epoch 25 - iter 6/38 - loss 0.02629006 - samples/sec: 83.56 - lr: 0.006250\n",
            "2022-06-12 22:21:42,906 epoch 25 - iter 9/38 - loss 0.02176162 - samples/sec: 96.59 - lr: 0.006250\n",
            "2022-06-12 22:21:42,947 epoch 25 - iter 12/38 - loss 0.05703540 - samples/sec: 74.79 - lr: 0.006250\n",
            "2022-06-12 22:21:42,994 epoch 25 - iter 15/38 - loss 0.04772014 - samples/sec: 65.38 - lr: 0.006250\n",
            "2022-06-12 22:21:43,033 epoch 25 - iter 18/38 - loss 0.04219259 - samples/sec: 85.12 - lr: 0.006250\n",
            "2022-06-12 22:21:43,074 epoch 25 - iter 21/38 - loss 0.04904420 - samples/sec: 83.14 - lr: 0.006250\n",
            "2022-06-12 22:21:43,116 epoch 25 - iter 24/38 - loss 0.04298922 - samples/sec: 78.11 - lr: 0.006250\n",
            "2022-06-12 22:21:43,156 epoch 25 - iter 27/38 - loss 0.03804418 - samples/sec: 79.62 - lr: 0.006250\n",
            "2022-06-12 22:21:43,196 epoch 25 - iter 30/38 - loss 0.03481326 - samples/sec: 77.25 - lr: 0.006250\n",
            "2022-06-12 22:21:43,242 epoch 25 - iter 33/38 - loss 0.03816707 - samples/sec: 71.60 - lr: 0.006250\n",
            "2022-06-12 22:21:43,284 epoch 25 - iter 36/38 - loss 0.03498490 - samples/sec: 74.51 - lr: 0.006250\n",
            "2022-06-12 22:21:43,309 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:43,310 EPOCH 25 done: loss 0.0335 - lr 0.006250\n",
            "2022-06-12 22:21:43,313 BAD EPOCHS (no improvement): 1\n",
            "2022-06-12 22:21:43,315 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:43,360 epoch 26 - iter 3/38 - loss 0.00249844 - samples/sec: 77.04 - lr: 0.006250\n",
            "2022-06-12 22:21:43,404 epoch 26 - iter 6/38 - loss 0.00364304 - samples/sec: 72.25 - lr: 0.006250\n",
            "2022-06-12 22:21:43,441 epoch 26 - iter 9/38 - loss 0.00457601 - samples/sec: 84.26 - lr: 0.006250\n",
            "2022-06-12 22:21:43,484 epoch 26 - iter 12/38 - loss 0.02539635 - samples/sec: 71.41 - lr: 0.006250\n",
            "2022-06-12 22:21:43,524 epoch 26 - iter 15/38 - loss 0.02079579 - samples/sec: 77.21 - lr: 0.006250\n",
            "2022-06-12 22:21:43,561 epoch 26 - iter 18/38 - loss 0.01915493 - samples/sec: 88.69 - lr: 0.006250\n",
            "2022-06-12 22:21:43,610 epoch 26 - iter 21/38 - loss 0.02990503 - samples/sec: 65.23 - lr: 0.006250\n",
            "2022-06-12 22:21:43,651 epoch 26 - iter 24/38 - loss 0.02861608 - samples/sec: 77.37 - lr: 0.006250\n",
            "2022-06-12 22:21:43,693 epoch 26 - iter 27/38 - loss 0.02608351 - samples/sec: 72.62 - lr: 0.006250\n",
            "2022-06-12 22:21:43,730 epoch 26 - iter 30/38 - loss 0.02431651 - samples/sec: 89.72 - lr: 0.006250\n",
            "2022-06-12 22:21:43,783 epoch 26 - iter 33/38 - loss 0.02163674 - samples/sec: 58.32 - lr: 0.006250\n",
            "2022-06-12 22:21:43,818 epoch 26 - iter 36/38 - loss 0.02226257 - samples/sec: 88.56 - lr: 0.006250\n",
            "2022-06-12 22:21:43,845 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:43,847 EPOCH 26 done: loss 0.0234 - lr 0.006250\n",
            "2022-06-12 22:21:43,849 BAD EPOCHS (no improvement): 0\n",
            "2022-06-12 22:21:43,852 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:43,899 epoch 27 - iter 3/38 - loss 0.00028851 - samples/sec: 86.27 - lr: 0.006250\n",
            "2022-06-12 22:21:43,935 epoch 27 - iter 6/38 - loss 0.00028689 - samples/sec: 90.08 - lr: 0.006250\n",
            "2022-06-12 22:21:43,973 epoch 27 - iter 9/38 - loss 0.00071140 - samples/sec: 85.15 - lr: 0.006250\n",
            "2022-06-12 22:21:44,009 epoch 27 - iter 12/38 - loss 0.00149744 - samples/sec: 86.20 - lr: 0.006250\n",
            "2022-06-12 22:21:44,055 epoch 27 - iter 15/38 - loss 0.01141673 - samples/sec: 68.39 - lr: 0.006250\n",
            "2022-06-12 22:21:44,097 epoch 27 - iter 18/38 - loss 0.01410527 - samples/sec: 76.59 - lr: 0.006250\n",
            "2022-06-12 22:21:44,131 epoch 27 - iter 21/38 - loss 0.01329187 - samples/sec: 96.65 - lr: 0.006250\n",
            "2022-06-12 22:21:44,171 epoch 27 - iter 24/38 - loss 0.01124986 - samples/sec: 81.04 - lr: 0.006250\n",
            "2022-06-12 22:21:44,216 epoch 27 - iter 27/38 - loss 0.04053093 - samples/sec: 67.26 - lr: 0.006250\n",
            "2022-06-12 22:21:44,260 epoch 27 - iter 30/38 - loss 0.04008371 - samples/sec: 74.58 - lr: 0.006250\n",
            "2022-06-12 22:21:44,301 epoch 27 - iter 33/38 - loss 0.04994489 - samples/sec: 77.32 - lr: 0.006250\n",
            "2022-06-12 22:21:44,344 epoch 27 - iter 36/38 - loss 0.04545049 - samples/sec: 71.25 - lr: 0.006250\n",
            "2022-06-12 22:21:44,368 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:44,372 EPOCH 27 done: loss 0.0444 - lr 0.006250\n",
            "2022-06-12 22:21:44,375 BAD EPOCHS (no improvement): 1\n",
            "2022-06-12 22:21:44,378 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:44,423 epoch 28 - iter 3/38 - loss 0.00951949 - samples/sec: 75.34 - lr: 0.006250\n",
            "2022-06-12 22:21:44,462 epoch 28 - iter 6/38 - loss 0.03687428 - samples/sec: 82.31 - lr: 0.006250\n",
            "2022-06-12 22:21:44,505 epoch 28 - iter 9/38 - loss 0.07384535 - samples/sec: 73.34 - lr: 0.006250\n",
            "2022-06-12 22:21:44,555 epoch 28 - iter 12/38 - loss 0.05154472 - samples/sec: 65.62 - lr: 0.006250\n",
            "2022-06-12 22:21:44,596 epoch 28 - iter 15/38 - loss 0.08428518 - samples/sec: 75.76 - lr: 0.006250\n",
            "2022-06-12 22:21:44,633 epoch 28 - iter 18/38 - loss 0.07858821 - samples/sec: 84.00 - lr: 0.006250\n",
            "2022-06-12 22:21:44,670 epoch 28 - iter 21/38 - loss 0.07089233 - samples/sec: 90.03 - lr: 0.006250\n",
            "2022-06-12 22:21:44,714 epoch 28 - iter 24/38 - loss 0.06055603 - samples/sec: 69.11 - lr: 0.006250\n",
            "2022-06-12 22:21:44,750 epoch 28 - iter 27/38 - loss 0.05589786 - samples/sec: 92.30 - lr: 0.006250\n",
            "2022-06-12 22:21:44,794 epoch 28 - iter 30/38 - loss 0.06420307 - samples/sec: 71.79 - lr: 0.006250\n",
            "2022-06-12 22:21:44,833 epoch 28 - iter 33/38 - loss 0.05856836 - samples/sec: 79.71 - lr: 0.006250\n",
            "2022-06-12 22:21:44,870 epoch 28 - iter 36/38 - loss 0.05568283 - samples/sec: 83.33 - lr: 0.006250\n",
            "2022-06-12 22:21:44,895 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:44,896 EPOCH 28 done: loss 0.0536 - lr 0.006250\n",
            "2022-06-12 22:21:44,898 BAD EPOCHS (no improvement): 2\n",
            "2022-06-12 22:21:44,901 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:44,940 epoch 29 - iter 3/38 - loss 0.00088692 - samples/sec: 99.43 - lr: 0.006250\n",
            "2022-06-12 22:21:44,980 epoch 29 - iter 6/38 - loss 0.00130035 - samples/sec: 77.40 - lr: 0.006250\n",
            "2022-06-12 22:21:45,027 epoch 29 - iter 9/38 - loss 0.00079070 - samples/sec: 65.91 - lr: 0.006250\n",
            "2022-06-12 22:21:45,070 epoch 29 - iter 12/38 - loss 0.02639885 - samples/sec: 70.92 - lr: 0.006250\n",
            "2022-06-12 22:21:45,110 epoch 29 - iter 15/38 - loss 0.03631070 - samples/sec: 81.09 - lr: 0.006250\n",
            "2022-06-12 22:21:45,146 epoch 29 - iter 18/38 - loss 0.03517893 - samples/sec: 85.53 - lr: 0.006250\n",
            "2022-06-12 22:21:45,190 epoch 29 - iter 21/38 - loss 0.03176783 - samples/sec: 70.66 - lr: 0.006250\n",
            "2022-06-12 22:21:45,227 epoch 29 - iter 24/38 - loss 0.02843827 - samples/sec: 83.36 - lr: 0.006250\n",
            "2022-06-12 22:21:45,266 epoch 29 - iter 27/38 - loss 0.02555850 - samples/sec: 86.66 - lr: 0.006250\n",
            "2022-06-12 22:21:45,304 epoch 29 - iter 30/38 - loss 0.02350205 - samples/sec: 80.92 - lr: 0.006250\n",
            "2022-06-12 22:21:45,347 epoch 29 - iter 33/38 - loss 0.02954098 - samples/sec: 72.49 - lr: 0.006250\n",
            "2022-06-12 22:21:45,386 epoch 29 - iter 36/38 - loss 0.02725890 - samples/sec: 79.21 - lr: 0.006250\n",
            "2022-06-12 22:21:45,412 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:45,414 EPOCH 29 done: loss 0.0411 - lr 0.006250\n",
            "2022-06-12 22:21:45,416 BAD EPOCHS (no improvement): 3\n",
            "2022-06-12 22:21:45,418 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:45,464 epoch 30 - iter 3/38 - loss 0.00453880 - samples/sec: 80.72 - lr: 0.006250\n",
            "2022-06-12 22:21:45,507 epoch 30 - iter 6/38 - loss 0.03163683 - samples/sec: 74.72 - lr: 0.006250\n",
            "2022-06-12 22:21:45,550 epoch 30 - iter 9/38 - loss 0.02210788 - samples/sec: 71.11 - lr: 0.006250\n",
            "2022-06-12 22:21:45,592 epoch 30 - iter 12/38 - loss 0.02568570 - samples/sec: 74.58 - lr: 0.006250\n",
            "2022-06-12 22:21:45,633 epoch 30 - iter 15/38 - loss 0.02242523 - samples/sec: 75.95 - lr: 0.006250\n",
            "2022-06-12 22:21:45,668 epoch 30 - iter 18/38 - loss 0.02047388 - samples/sec: 87.56 - lr: 0.006250\n",
            "2022-06-12 22:21:45,709 epoch 30 - iter 21/38 - loss 0.02420486 - samples/sec: 77.21 - lr: 0.006250\n",
            "2022-06-12 22:21:45,743 epoch 30 - iter 24/38 - loss 0.02246051 - samples/sec: 90.06 - lr: 0.006250\n",
            "2022-06-12 22:21:45,783 epoch 30 - iter 27/38 - loss 0.01991132 - samples/sec: 78.82 - lr: 0.006250\n",
            "2022-06-12 22:21:45,821 epoch 30 - iter 30/38 - loss 0.01866112 - samples/sec: 81.51 - lr: 0.006250\n",
            "2022-06-12 22:21:45,856 epoch 30 - iter 33/38 - loss 0.01896433 - samples/sec: 89.28 - lr: 0.006250\n",
            "2022-06-12 22:21:45,894 epoch 30 - iter 36/38 - loss 0.01774702 - samples/sec: 86.32 - lr: 0.006250\n",
            "2022-06-12 22:21:45,922 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:45,924 EPOCH 30 done: loss 0.0189 - lr 0.006250\n",
            "2022-06-12 22:21:45,927 BAD EPOCHS (no improvement): 0\n",
            "2022-06-12 22:21:45,935 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:45,980 epoch 31 - iter 3/38 - loss 0.02027008 - samples/sec: 69.35 - lr: 0.006250\n",
            "2022-06-12 22:21:46,020 epoch 31 - iter 6/38 - loss 0.03614791 - samples/sec: 77.73 - lr: 0.006250\n",
            "2022-06-12 22:21:46,063 epoch 31 - iter 9/38 - loss 0.10252501 - samples/sec: 71.85 - lr: 0.006250\n",
            "2022-06-12 22:21:46,104 epoch 31 - iter 12/38 - loss 0.08491002 - samples/sec: 79.03 - lr: 0.006250\n",
            "2022-06-12 22:21:46,147 epoch 31 - iter 15/38 - loss 0.06436658 - samples/sec: 74.76 - lr: 0.006250\n",
            "2022-06-12 22:21:46,188 epoch 31 - iter 18/38 - loss 0.05324554 - samples/sec: 74.95 - lr: 0.006250\n",
            "2022-06-12 22:21:46,228 epoch 31 - iter 21/38 - loss 0.04835392 - samples/sec: 86.86 - lr: 0.006250\n",
            "2022-06-12 22:21:46,267 epoch 31 - iter 24/38 - loss 0.04371766 - samples/sec: 81.02 - lr: 0.006250\n",
            "2022-06-12 22:21:46,302 epoch 31 - iter 27/38 - loss 0.04086979 - samples/sec: 88.96 - lr: 0.006250\n",
            "2022-06-12 22:21:46,339 epoch 31 - iter 30/38 - loss 0.03818179 - samples/sec: 82.72 - lr: 0.006250\n",
            "2022-06-12 22:21:46,381 epoch 31 - iter 33/38 - loss 0.03405202 - samples/sec: 73.98 - lr: 0.006250\n",
            "2022-06-12 22:21:46,420 epoch 31 - iter 36/38 - loss 0.03222016 - samples/sec: 79.19 - lr: 0.006250\n",
            "2022-06-12 22:21:46,448 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:46,449 EPOCH 31 done: loss 0.0310 - lr 0.006250\n",
            "2022-06-12 22:21:46,451 BAD EPOCHS (no improvement): 1\n",
            "2022-06-12 22:21:46,454 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:46,494 epoch 32 - iter 3/38 - loss 0.01408087 - samples/sec: 93.83 - lr: 0.006250\n",
            "2022-06-12 22:21:46,533 epoch 32 - iter 6/38 - loss 0.07171345 - samples/sec: 79.76 - lr: 0.006250\n",
            "2022-06-12 22:21:46,571 epoch 32 - iter 9/38 - loss 0.04929949 - samples/sec: 82.96 - lr: 0.006250\n",
            "2022-06-12 22:21:46,608 epoch 32 - iter 12/38 - loss 0.03848100 - samples/sec: 83.48 - lr: 0.006250\n",
            "2022-06-12 22:21:46,648 epoch 32 - iter 15/38 - loss 0.05326228 - samples/sec: 78.36 - lr: 0.006250\n",
            "2022-06-12 22:21:46,684 epoch 32 - iter 18/38 - loss 0.04642957 - samples/sec: 86.36 - lr: 0.006250\n",
            "2022-06-12 22:21:46,727 epoch 32 - iter 21/38 - loss 0.03923471 - samples/sec: 70.84 - lr: 0.006250\n",
            "2022-06-12 22:21:46,765 epoch 32 - iter 24/38 - loss 0.05109797 - samples/sec: 83.12 - lr: 0.006250\n",
            "2022-06-12 22:21:46,801 epoch 32 - iter 27/38 - loss 0.04744286 - samples/sec: 88.63 - lr: 0.006250\n",
            "2022-06-12 22:21:46,844 epoch 32 - iter 30/38 - loss 0.04437352 - samples/sec: 71.75 - lr: 0.006250\n",
            "2022-06-12 22:21:46,892 epoch 32 - iter 33/38 - loss 0.03957735 - samples/sec: 65.07 - lr: 0.006250\n",
            "2022-06-12 22:21:46,933 epoch 32 - iter 36/38 - loss 0.03559615 - samples/sec: 75.52 - lr: 0.006250\n",
            "2022-06-12 22:21:46,962 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:46,964 EPOCH 32 done: loss 0.0335 - lr 0.006250\n",
            "2022-06-12 22:21:46,966 BAD EPOCHS (no improvement): 2\n",
            "2022-06-12 22:21:46,969 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:47,018 epoch 33 - iter 3/38 - loss 0.00225581 - samples/sec: 69.82 - lr: 0.006250\n",
            "2022-06-12 22:21:47,065 epoch 33 - iter 6/38 - loss 0.01567496 - samples/sec: 67.26 - lr: 0.006250\n",
            "2022-06-12 22:21:47,110 epoch 33 - iter 9/38 - loss 0.01240574 - samples/sec: 70.32 - lr: 0.006250\n",
            "2022-06-12 22:21:47,148 epoch 33 - iter 12/38 - loss 0.03500826 - samples/sec: 83.18 - lr: 0.006250\n",
            "2022-06-12 22:21:47,190 epoch 33 - iter 15/38 - loss 0.02839630 - samples/sec: 77.12 - lr: 0.006250\n",
            "2022-06-12 22:21:47,231 epoch 33 - iter 18/38 - loss 0.02489537 - samples/sec: 83.42 - lr: 0.006250\n",
            "2022-06-12 22:21:47,271 epoch 33 - iter 21/38 - loss 0.09582518 - samples/sec: 76.98 - lr: 0.006250\n",
            "2022-06-12 22:21:47,313 epoch 33 - iter 24/38 - loss 0.09085082 - samples/sec: 74.03 - lr: 0.006250\n",
            "2022-06-12 22:21:47,353 epoch 33 - iter 27/38 - loss 0.08437605 - samples/sec: 78.79 - lr: 0.006250\n",
            "2022-06-12 22:21:47,390 epoch 33 - iter 30/38 - loss 0.07807354 - samples/sec: 83.89 - lr: 0.006250\n",
            "2022-06-12 22:21:47,430 epoch 33 - iter 33/38 - loss 0.07287224 - samples/sec: 77.25 - lr: 0.006250\n",
            "2022-06-12 22:21:47,473 epoch 33 - iter 36/38 - loss 0.07033176 - samples/sec: 77.57 - lr: 0.006250\n",
            "2022-06-12 22:21:47,500 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:47,501 EPOCH 33 done: loss 0.0664 - lr 0.006250\n",
            "2022-06-12 22:21:47,505 BAD EPOCHS (no improvement): 3\n",
            "2022-06-12 22:21:47,507 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:47,552 epoch 34 - iter 3/38 - loss 0.07770983 - samples/sec: 78.39 - lr: 0.006250\n",
            "2022-06-12 22:21:47,590 epoch 34 - iter 6/38 - loss 0.04069138 - samples/sec: 82.51 - lr: 0.006250\n",
            "2022-06-12 22:21:47,629 epoch 34 - iter 9/38 - loss 0.03023779 - samples/sec: 83.12 - lr: 0.006250\n",
            "2022-06-12 22:21:47,673 epoch 34 - iter 12/38 - loss 0.03454484 - samples/sec: 70.16 - lr: 0.006250\n",
            "2022-06-12 22:21:47,711 epoch 34 - iter 15/38 - loss 0.02986784 - samples/sec: 88.60 - lr: 0.006250\n",
            "2022-06-12 22:21:47,753 epoch 34 - iter 18/38 - loss 0.02333337 - samples/sec: 73.63 - lr: 0.006250\n",
            "2022-06-12 22:21:47,792 epoch 34 - iter 21/38 - loss 0.02427567 - samples/sec: 82.73 - lr: 0.006250\n",
            "2022-06-12 22:21:47,834 epoch 34 - iter 24/38 - loss 0.02037352 - samples/sec: 73.05 - lr: 0.006250\n",
            "2022-06-12 22:21:47,870 epoch 34 - iter 27/38 - loss 0.01894851 - samples/sec: 90.64 - lr: 0.006250\n",
            "2022-06-12 22:21:47,912 epoch 34 - iter 30/38 - loss 0.02807660 - samples/sec: 78.50 - lr: 0.006250\n",
            "2022-06-12 22:21:47,949 epoch 34 - iter 33/38 - loss 0.02585971 - samples/sec: 83.52 - lr: 0.006250\n",
            "2022-06-12 22:21:47,995 epoch 34 - iter 36/38 - loss 0.02442670 - samples/sec: 68.03 - lr: 0.006250\n",
            "2022-06-12 22:21:48,026 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:48,030 EPOCH 34 done: loss 0.0230 - lr 0.006250\n",
            "2022-06-12 22:21:48,031 Epoch    34: reducing learning rate of group 0 to 3.1250e-03.\n",
            "2022-06-12 22:21:48,033 BAD EPOCHS (no improvement): 4\n",
            "2022-06-12 22:21:48,042 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:48,088 epoch 35 - iter 3/38 - loss 0.03519116 - samples/sec: 71.00 - lr: 0.003125\n",
            "2022-06-12 22:21:48,131 epoch 35 - iter 6/38 - loss 0.02217591 - samples/sec: 75.37 - lr: 0.003125\n",
            "2022-06-12 22:21:48,175 epoch 35 - iter 9/38 - loss 0.01743426 - samples/sec: 74.79 - lr: 0.003125\n",
            "2022-06-12 22:21:48,213 epoch 35 - iter 12/38 - loss 0.01449398 - samples/sec: 84.60 - lr: 0.003125\n",
            "2022-06-12 22:21:48,252 epoch 35 - iter 15/38 - loss 0.01415530 - samples/sec: 78.83 - lr: 0.003125\n",
            "2022-06-12 22:21:48,300 epoch 35 - iter 18/38 - loss 0.03018177 - samples/sec: 68.49 - lr: 0.003125\n",
            "2022-06-12 22:21:48,339 epoch 35 - iter 21/38 - loss 0.02768102 - samples/sec: 79.98 - lr: 0.003125\n",
            "2022-06-12 22:21:48,380 epoch 35 - iter 24/38 - loss 0.03158561 - samples/sec: 76.61 - lr: 0.003125\n",
            "2022-06-12 22:21:48,421 epoch 35 - iter 27/38 - loss 0.02820173 - samples/sec: 75.19 - lr: 0.003125\n",
            "2022-06-12 22:21:48,459 epoch 35 - iter 30/38 - loss 0.02590255 - samples/sec: 80.95 - lr: 0.003125\n",
            "2022-06-12 22:21:48,499 epoch 35 - iter 33/38 - loss 0.03606275 - samples/sec: 77.85 - lr: 0.003125\n",
            "2022-06-12 22:21:48,539 epoch 35 - iter 36/38 - loss 0.03369632 - samples/sec: 78.91 - lr: 0.003125\n",
            "2022-06-12 22:21:48,564 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:48,565 EPOCH 35 done: loss 0.0323 - lr 0.003125\n",
            "2022-06-12 22:21:48,568 BAD EPOCHS (no improvement): 1\n",
            "2022-06-12 22:21:48,570 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:48,615 epoch 36 - iter 3/38 - loss 0.00040359 - samples/sec: 75.48 - lr: 0.003125\n",
            "2022-06-12 22:21:48,657 epoch 36 - iter 6/38 - loss 0.01015249 - samples/sec: 76.30 - lr: 0.003125\n",
            "2022-06-12 22:21:48,694 epoch 36 - iter 9/38 - loss 0.01968559 - samples/sec: 83.22 - lr: 0.003125\n",
            "2022-06-12 22:21:48,738 epoch 36 - iter 12/38 - loss 0.01371070 - samples/sec: 70.55 - lr: 0.003125\n",
            "2022-06-12 22:21:48,778 epoch 36 - iter 15/38 - loss 0.01662466 - samples/sec: 78.00 - lr: 0.003125\n",
            "2022-06-12 22:21:48,818 epoch 36 - iter 18/38 - loss 0.04365475 - samples/sec: 80.50 - lr: 0.003125\n",
            "2022-06-12 22:21:48,863 epoch 36 - iter 21/38 - loss 0.03715099 - samples/sec: 68.33 - lr: 0.003125\n",
            "2022-06-12 22:21:48,902 epoch 36 - iter 24/38 - loss 0.03718185 - samples/sec: 80.88 - lr: 0.003125\n",
            "2022-06-12 22:21:48,938 epoch 36 - iter 27/38 - loss 0.03978843 - samples/sec: 87.41 - lr: 0.003125\n",
            "2022-06-12 22:21:48,979 epoch 36 - iter 30/38 - loss 0.03628776 - samples/sec: 74.24 - lr: 0.003125\n",
            "2022-06-12 22:21:49,017 epoch 36 - iter 33/38 - loss 0.03367794 - samples/sec: 85.51 - lr: 0.003125\n",
            "2022-06-12 22:21:49,055 epoch 36 - iter 36/38 - loss 0.03162087 - samples/sec: 82.48 - lr: 0.003125\n",
            "2022-06-12 22:21:49,084 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:49,087 EPOCH 36 done: loss 0.0302 - lr 0.003125\n",
            "2022-06-12 22:21:49,088 BAD EPOCHS (no improvement): 2\n",
            "2022-06-12 22:21:49,091 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:49,144 epoch 37 - iter 3/38 - loss 0.06138405 - samples/sec: 66.53 - lr: 0.003125\n",
            "2022-06-12 22:21:49,182 epoch 37 - iter 6/38 - loss 0.03729124 - samples/sec: 83.92 - lr: 0.003125\n",
            "2022-06-12 22:21:49,228 epoch 37 - iter 9/38 - loss 0.07096917 - samples/sec: 66.77 - lr: 0.003125\n",
            "2022-06-12 22:21:49,270 epoch 37 - iter 12/38 - loss 0.05331116 - samples/sec: 73.67 - lr: 0.003125\n",
            "2022-06-12 22:21:49,312 epoch 37 - iter 15/38 - loss 0.06294085 - samples/sec: 73.97 - lr: 0.003125\n",
            "2022-06-12 22:21:49,353 epoch 37 - iter 18/38 - loss 0.05599533 - samples/sec: 75.25 - lr: 0.003125\n",
            "2022-06-12 22:21:49,388 epoch 37 - iter 21/38 - loss 0.05207347 - samples/sec: 94.50 - lr: 0.003125\n",
            "2022-06-12 22:21:49,430 epoch 37 - iter 24/38 - loss 0.04800129 - samples/sec: 76.24 - lr: 0.003125\n",
            "2022-06-12 22:21:49,465 epoch 37 - iter 27/38 - loss 0.04478265 - samples/sec: 87.42 - lr: 0.003125\n",
            "2022-06-12 22:21:49,498 epoch 37 - iter 30/38 - loss 0.04261566 - samples/sec: 98.84 - lr: 0.003125\n",
            "2022-06-12 22:21:49,541 epoch 37 - iter 33/38 - loss 0.03755649 - samples/sec: 73.38 - lr: 0.003125\n",
            "2022-06-12 22:21:49,581 epoch 37 - iter 36/38 - loss 0.03585587 - samples/sec: 79.57 - lr: 0.003125\n",
            "2022-06-12 22:21:49,610 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:49,611 EPOCH 37 done: loss 0.0350 - lr 0.003125\n",
            "2022-06-12 22:21:49,613 BAD EPOCHS (no improvement): 3\n",
            "2022-06-12 22:21:49,616 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:49,663 epoch 38 - iter 3/38 - loss 0.04496702 - samples/sec: 73.78 - lr: 0.003125\n",
            "2022-06-12 22:21:49,702 epoch 38 - iter 6/38 - loss 0.02732395 - samples/sec: 82.09 - lr: 0.003125\n",
            "2022-06-12 22:21:49,740 epoch 38 - iter 9/38 - loss 0.02038272 - samples/sec: 82.28 - lr: 0.003125\n",
            "2022-06-12 22:21:49,780 epoch 38 - iter 12/38 - loss 0.01682633 - samples/sec: 76.93 - lr: 0.003125\n",
            "2022-06-12 22:21:49,822 epoch 38 - iter 15/38 - loss 0.05993332 - samples/sec: 74.04 - lr: 0.003125\n",
            "2022-06-12 22:21:49,863 epoch 38 - iter 18/38 - loss 0.04883225 - samples/sec: 75.45 - lr: 0.003125\n",
            "2022-06-12 22:21:49,905 epoch 38 - iter 21/38 - loss 0.06516170 - samples/sec: 73.11 - lr: 0.003125\n",
            "2022-06-12 22:21:49,948 epoch 38 - iter 24/38 - loss 0.05743285 - samples/sec: 75.02 - lr: 0.003125\n",
            "2022-06-12 22:21:49,986 epoch 38 - iter 27/38 - loss 0.05187724 - samples/sec: 84.30 - lr: 0.003125\n",
            "2022-06-12 22:21:50,025 epoch 38 - iter 30/38 - loss 0.04729581 - samples/sec: 80.51 - lr: 0.003125\n",
            "2022-06-12 22:21:50,065 epoch 38 - iter 33/38 - loss 0.04354480 - samples/sec: 82.58 - lr: 0.003125\n",
            "2022-06-12 22:21:50,103 epoch 38 - iter 36/38 - loss 0.04027158 - samples/sec: 82.38 - lr: 0.003125\n",
            "2022-06-12 22:21:50,130 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:50,131 EPOCH 38 done: loss 0.0471 - lr 0.003125\n",
            "2022-06-12 22:21:50,134 Epoch    38: reducing learning rate of group 0 to 1.5625e-03.\n",
            "2022-06-12 22:21:50,136 BAD EPOCHS (no improvement): 4\n",
            "2022-06-12 22:21:50,147 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:50,192 epoch 39 - iter 3/38 - loss 0.00080805 - samples/sec: 69.14 - lr: 0.001563\n",
            "2022-06-12 22:21:50,231 epoch 39 - iter 6/38 - loss 0.00171424 - samples/sec: 78.64 - lr: 0.001563\n",
            "2022-06-12 22:21:50,275 epoch 39 - iter 9/38 - loss 0.05933189 - samples/sec: 71.23 - lr: 0.001563\n",
            "2022-06-12 22:21:50,316 epoch 39 - iter 12/38 - loss 0.24608290 - samples/sec: 74.98 - lr: 0.001563\n",
            "2022-06-12 22:21:50,356 epoch 39 - iter 15/38 - loss 0.20757700 - samples/sec: 77.37 - lr: 0.001563\n",
            "2022-06-12 22:21:50,394 epoch 39 - iter 18/38 - loss 0.18115402 - samples/sec: 82.59 - lr: 0.001563\n",
            "2022-06-12 22:21:50,438 epoch 39 - iter 21/38 - loss 0.16366184 - samples/sec: 71.36 - lr: 0.001563\n",
            "2022-06-12 22:21:50,483 epoch 39 - iter 24/38 - loss 0.13503570 - samples/sec: 70.54 - lr: 0.001563\n",
            "2022-06-12 22:21:50,525 epoch 39 - iter 27/38 - loss 0.11992421 - samples/sec: 73.76 - lr: 0.001563\n",
            "2022-06-12 22:21:50,564 epoch 39 - iter 30/38 - loss 0.11095184 - samples/sec: 78.37 - lr: 0.001563\n",
            "2022-06-12 22:21:50,600 epoch 39 - iter 33/38 - loss 0.10488806 - samples/sec: 86.61 - lr: 0.001563\n",
            "2022-06-12 22:21:50,633 epoch 39 - iter 36/38 - loss 0.10166451 - samples/sec: 96.62 - lr: 0.001563\n",
            "2022-06-12 22:21:50,658 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:50,663 EPOCH 39 done: loss 0.0979 - lr 0.001563\n",
            "2022-06-12 22:21:50,665 BAD EPOCHS (no improvement): 1\n",
            "2022-06-12 22:21:50,667 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:50,715 epoch 40 - iter 3/38 - loss 0.14843689 - samples/sec: 69.76 - lr: 0.001563\n",
            "2022-06-12 22:21:50,752 epoch 40 - iter 6/38 - loss 0.09075062 - samples/sec: 84.24 - lr: 0.001563\n",
            "2022-06-12 22:21:50,791 epoch 40 - iter 9/38 - loss 0.05930068 - samples/sec: 79.29 - lr: 0.001563\n",
            "2022-06-12 22:21:50,837 epoch 40 - iter 12/38 - loss 0.04769311 - samples/sec: 68.08 - lr: 0.001563\n",
            "2022-06-12 22:21:50,872 epoch 40 - iter 15/38 - loss 0.04248991 - samples/sec: 91.37 - lr: 0.001563\n",
            "2022-06-12 22:21:50,914 epoch 40 - iter 18/38 - loss 0.04697260 - samples/sec: 73.98 - lr: 0.001563\n",
            "2022-06-12 22:21:50,952 epoch 40 - iter 21/38 - loss 0.04147546 - samples/sec: 80.95 - lr: 0.001563\n",
            "2022-06-12 22:21:50,988 epoch 40 - iter 24/38 - loss 0.04007262 - samples/sec: 90.61 - lr: 0.001563\n",
            "2022-06-12 22:21:51,028 epoch 40 - iter 27/38 - loss 0.03730711 - samples/sec: 82.61 - lr: 0.001563\n",
            "2022-06-12 22:21:51,073 epoch 40 - iter 30/38 - loss 0.03140331 - samples/sec: 70.02 - lr: 0.001563\n",
            "2022-06-12 22:21:51,115 epoch 40 - iter 33/38 - loss 0.02914182 - samples/sec: 76.99 - lr: 0.001563\n",
            "2022-06-12 22:21:51,157 epoch 40 - iter 36/38 - loss 0.03250175 - samples/sec: 79.85 - lr: 0.001563\n",
            "2022-06-12 22:21:51,189 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:51,192 EPOCH 40 done: loss 0.0309 - lr 0.001563\n",
            "2022-06-12 22:21:51,193 BAD EPOCHS (no improvement): 2\n",
            "2022-06-12 22:21:51,196 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:51,244 epoch 41 - iter 3/38 - loss 0.00187454 - samples/sec: 65.22 - lr: 0.001563\n",
            "2022-06-12 22:21:51,286 epoch 41 - iter 6/38 - loss 0.05535831 - samples/sec: 78.54 - lr: 0.001563\n",
            "2022-06-12 22:21:51,323 epoch 41 - iter 9/38 - loss 0.08573689 - samples/sec: 82.94 - lr: 0.001563\n",
            "2022-06-12 22:21:51,361 epoch 41 - iter 12/38 - loss 0.06984057 - samples/sec: 83.50 - lr: 0.001563\n",
            "2022-06-12 22:21:51,402 epoch 41 - iter 15/38 - loss 0.05520938 - samples/sec: 75.02 - lr: 0.001563\n",
            "2022-06-12 22:21:51,444 epoch 41 - iter 18/38 - loss 0.04484095 - samples/sec: 74.02 - lr: 0.001563\n",
            "2022-06-12 22:21:51,479 epoch 41 - iter 21/38 - loss 0.04147519 - samples/sec: 89.43 - lr: 0.001563\n",
            "2022-06-12 22:21:51,521 epoch 41 - iter 24/38 - loss 0.03572217 - samples/sec: 73.79 - lr: 0.001563\n",
            "2022-06-12 22:21:51,557 epoch 41 - iter 27/38 - loss 0.03345255 - samples/sec: 85.91 - lr: 0.001563\n",
            "2022-06-12 22:21:51,596 epoch 41 - iter 30/38 - loss 0.03079472 - samples/sec: 79.26 - lr: 0.001563\n",
            "2022-06-12 22:21:51,633 epoch 41 - iter 33/38 - loss 0.02885905 - samples/sec: 84.70 - lr: 0.001563\n",
            "2022-06-12 22:21:51,677 epoch 41 - iter 36/38 - loss 0.02612784 - samples/sec: 69.39 - lr: 0.001563\n",
            "2022-06-12 22:21:51,709 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:51,711 EPOCH 41 done: loss 0.0283 - lr 0.001563\n",
            "2022-06-12 22:21:51,713 BAD EPOCHS (no improvement): 3\n",
            "2022-06-12 22:21:51,716 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:51,759 epoch 42 - iter 3/38 - loss 0.05513483 - samples/sec: 89.86 - lr: 0.001563\n",
            "2022-06-12 22:21:51,802 epoch 42 - iter 6/38 - loss 0.02345009 - samples/sec: 71.95 - lr: 0.001563\n",
            "2022-06-12 22:21:51,844 epoch 42 - iter 9/38 - loss 0.01661416 - samples/sec: 74.49 - lr: 0.001563\n",
            "2022-06-12 22:21:51,887 epoch 42 - iter 12/38 - loss 0.01652913 - samples/sec: 76.40 - lr: 0.001563\n",
            "2022-06-12 22:21:51,926 epoch 42 - iter 15/38 - loss 0.01445018 - samples/sec: 79.37 - lr: 0.001563\n",
            "2022-06-12 22:21:51,968 epoch 42 - iter 18/38 - loss 0.03203721 - samples/sec: 78.55 - lr: 0.001563\n",
            "2022-06-12 22:21:52,002 epoch 42 - iter 21/38 - loss 0.03006262 - samples/sec: 96.36 - lr: 0.001563\n",
            "2022-06-12 22:21:52,041 epoch 42 - iter 24/38 - loss 0.02675582 - samples/sec: 78.12 - lr: 0.001563\n",
            "2022-06-12 22:21:52,080 epoch 42 - iter 27/38 - loss 0.02438669 - samples/sec: 84.34 - lr: 0.001563\n",
            "2022-06-12 22:21:52,116 epoch 42 - iter 30/38 - loss 0.02248239 - samples/sec: 88.34 - lr: 0.001563\n",
            "2022-06-12 22:21:52,154 epoch 42 - iter 33/38 - loss 0.02197875 - samples/sec: 83.05 - lr: 0.001563\n",
            "2022-06-12 22:21:52,204 epoch 42 - iter 36/38 - loss 0.01920591 - samples/sec: 60.66 - lr: 0.001563\n",
            "2022-06-12 22:21:52,233 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:52,236 EPOCH 42 done: loss 0.0186 - lr 0.001563\n",
            "2022-06-12 22:21:52,238 BAD EPOCHS (no improvement): 0\n",
            "2022-06-12 22:21:52,240 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:52,282 epoch 43 - iter 3/38 - loss 0.00033896 - samples/sec: 82.16 - lr: 0.001563\n",
            "2022-06-12 22:21:52,323 epoch 43 - iter 6/38 - loss 0.01981807 - samples/sec: 75.69 - lr: 0.001563\n",
            "2022-06-12 22:21:52,360 epoch 43 - iter 9/38 - loss 0.01389075 - samples/sec: 84.21 - lr: 0.001563\n",
            "2022-06-12 22:21:52,405 epoch 43 - iter 12/38 - loss 0.01267461 - samples/sec: 67.66 - lr: 0.001563\n",
            "2022-06-12 22:21:52,448 epoch 43 - iter 15/38 - loss 0.03946822 - samples/sec: 77.44 - lr: 0.001563\n",
            "2022-06-12 22:21:52,494 epoch 43 - iter 18/38 - loss 0.04166000 - samples/sec: 68.42 - lr: 0.001563\n",
            "2022-06-12 22:21:52,528 epoch 43 - iter 21/38 - loss 0.03896340 - samples/sec: 90.48 - lr: 0.001563\n",
            "2022-06-12 22:21:52,563 epoch 43 - iter 24/38 - loss 0.03587645 - samples/sec: 89.01 - lr: 0.001563\n",
            "2022-06-12 22:21:52,607 epoch 43 - iter 27/38 - loss 0.04348925 - samples/sec: 69.99 - lr: 0.001563\n",
            "2022-06-12 22:21:52,650 epoch 43 - iter 30/38 - loss 0.03953410 - samples/sec: 72.73 - lr: 0.001563\n",
            "2022-06-12 22:21:52,691 epoch 43 - iter 33/38 - loss 0.03594819 - samples/sec: 75.86 - lr: 0.001563\n",
            "2022-06-12 22:21:52,730 epoch 43 - iter 36/38 - loss 0.03280838 - samples/sec: 78.38 - lr: 0.001563\n",
            "2022-06-12 22:21:52,757 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:52,758 EPOCH 43 done: loss 0.0310 - lr 0.001563\n",
            "2022-06-12 22:21:52,760 BAD EPOCHS (no improvement): 1\n",
            "2022-06-12 22:21:52,763 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:52,812 epoch 44 - iter 3/38 - loss 0.00038881 - samples/sec: 75.85 - lr: 0.001563\n",
            "2022-06-12 22:21:52,850 epoch 44 - iter 6/38 - loss 0.00368464 - samples/sec: 89.81 - lr: 0.001563\n",
            "2022-06-12 22:21:52,890 epoch 44 - iter 9/38 - loss 0.00675501 - samples/sec: 76.58 - lr: 0.001563\n",
            "2022-06-12 22:21:52,926 epoch 44 - iter 12/38 - loss 0.00744097 - samples/sec: 86.40 - lr: 0.001563\n",
            "2022-06-12 22:21:52,966 epoch 44 - iter 15/38 - loss 0.00882422 - samples/sec: 81.30 - lr: 0.001563\n",
            "2022-06-12 22:21:53,003 epoch 44 - iter 18/38 - loss 0.00774119 - samples/sec: 86.02 - lr: 0.001563\n",
            "2022-06-12 22:21:53,042 epoch 44 - iter 21/38 - loss 0.00672586 - samples/sec: 81.00 - lr: 0.001563\n",
            "2022-06-12 22:21:53,085 epoch 44 - iter 24/38 - loss 0.00611808 - samples/sec: 71.74 - lr: 0.001563\n",
            "2022-06-12 22:21:53,121 epoch 44 - iter 27/38 - loss 0.01731693 - samples/sec: 87.52 - lr: 0.001563\n",
            "2022-06-12 22:21:53,159 epoch 44 - iter 30/38 - loss 0.01713012 - samples/sec: 80.25 - lr: 0.001563\n",
            "2022-06-12 22:21:53,199 epoch 44 - iter 33/38 - loss 0.02489866 - samples/sec: 82.30 - lr: 0.001563\n",
            "2022-06-12 22:21:53,253 epoch 44 - iter 36/38 - loss 0.02296842 - samples/sec: 57.51 - lr: 0.001563\n",
            "2022-06-12 22:21:53,289 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:53,294 EPOCH 44 done: loss 0.0208 - lr 0.001563\n",
            "2022-06-12 22:21:53,298 BAD EPOCHS (no improvement): 2\n",
            "2022-06-12 22:21:53,300 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:53,348 epoch 45 - iter 3/38 - loss 0.09536404 - samples/sec: 77.88 - lr: 0.001563\n",
            "2022-06-12 22:21:53,392 epoch 45 - iter 6/38 - loss 0.04605770 - samples/sec: 70.90 - lr: 0.001563\n",
            "2022-06-12 22:21:53,441 epoch 45 - iter 9/38 - loss 0.02805149 - samples/sec: 71.13 - lr: 0.001563\n",
            "2022-06-12 22:21:53,484 epoch 45 - iter 12/38 - loss 0.02123516 - samples/sec: 72.72 - lr: 0.001563\n",
            "2022-06-12 22:21:53,523 epoch 45 - iter 15/38 - loss 0.01899399 - samples/sec: 80.02 - lr: 0.001563\n",
            "2022-06-12 22:21:53,561 epoch 45 - iter 18/38 - loss 0.01664364 - samples/sec: 82.92 - lr: 0.001563\n",
            "2022-06-12 22:21:53,604 epoch 45 - iter 21/38 - loss 0.01337378 - samples/sec: 71.18 - lr: 0.001563\n",
            "2022-06-12 22:21:53,644 epoch 45 - iter 24/38 - loss 0.01198160 - samples/sec: 77.20 - lr: 0.001563\n",
            "2022-06-12 22:21:53,683 epoch 45 - iter 27/38 - loss 0.01090784 - samples/sec: 80.49 - lr: 0.001563\n",
            "2022-06-12 22:21:53,727 epoch 45 - iter 30/38 - loss 0.02386789 - samples/sec: 69.52 - lr: 0.001563\n",
            "2022-06-12 22:21:53,767 epoch 45 - iter 33/38 - loss 0.02247161 - samples/sec: 79.02 - lr: 0.001563\n",
            "2022-06-12 22:21:53,808 epoch 45 - iter 36/38 - loss 0.02094612 - samples/sec: 75.59 - lr: 0.001563\n",
            "2022-06-12 22:21:53,839 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:53,842 EPOCH 45 done: loss 0.0309 - lr 0.001563\n",
            "2022-06-12 22:21:53,846 BAD EPOCHS (no improvement): 3\n",
            "2022-06-12 22:21:53,848 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:53,896 epoch 46 - iter 3/38 - loss 0.00125027 - samples/sec: 70.17 - lr: 0.001563\n",
            "2022-06-12 22:21:53,940 epoch 46 - iter 6/38 - loss 0.00810222 - samples/sec: 73.32 - lr: 0.001563\n",
            "2022-06-12 22:21:53,995 epoch 46 - iter 9/38 - loss 0.09797549 - samples/sec: 57.54 - lr: 0.001563\n",
            "2022-06-12 22:21:54,038 epoch 46 - iter 12/38 - loss 0.07487323 - samples/sec: 73.09 - lr: 0.001563\n",
            "2022-06-12 22:21:54,083 epoch 46 - iter 15/38 - loss 0.08041620 - samples/sec: 70.27 - lr: 0.001563\n",
            "2022-06-12 22:21:54,130 epoch 46 - iter 18/38 - loss 0.06366404 - samples/sec: 68.18 - lr: 0.001563\n",
            "2022-06-12 22:21:54,173 epoch 46 - iter 21/38 - loss 0.05809458 - samples/sec: 72.32 - lr: 0.001563\n",
            "2022-06-12 22:21:54,211 epoch 46 - iter 24/38 - loss 0.05261741 - samples/sec: 84.44 - lr: 0.001563\n",
            "2022-06-12 22:21:54,259 epoch 46 - iter 27/38 - loss 0.04894599 - samples/sec: 65.32 - lr: 0.001563\n",
            "2022-06-12 22:21:54,300 epoch 46 - iter 30/38 - loss 0.05100710 - samples/sec: 76.01 - lr: 0.001563\n",
            "2022-06-12 22:21:54,338 epoch 46 - iter 33/38 - loss 0.04815469 - samples/sec: 82.29 - lr: 0.001563\n",
            "2022-06-12 22:21:54,380 epoch 46 - iter 36/38 - loss 0.04555769 - samples/sec: 74.23 - lr: 0.001563\n",
            "2022-06-12 22:21:54,408 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:54,409 EPOCH 46 done: loss 0.0433 - lr 0.001563\n",
            "2022-06-12 22:21:54,414 Epoch    46: reducing learning rate of group 0 to 7.8125e-04.\n",
            "2022-06-12 22:21:54,417 BAD EPOCHS (no improvement): 4\n",
            "2022-06-12 22:21:54,419 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:54,461 epoch 47 - iter 3/38 - loss 0.03724888 - samples/sec: 79.88 - lr: 0.000781\n",
            "2022-06-12 22:21:54,501 epoch 47 - iter 6/38 - loss 0.02503167 - samples/sec: 77.45 - lr: 0.000781\n",
            "2022-06-12 22:21:54,542 epoch 47 - iter 9/38 - loss 0.01653184 - samples/sec: 81.00 - lr: 0.000781\n",
            "2022-06-12 22:21:54,578 epoch 47 - iter 12/38 - loss 0.01404724 - samples/sec: 85.34 - lr: 0.000781\n",
            "2022-06-12 22:21:54,618 epoch 47 - iter 15/38 - loss 0.02035477 - samples/sec: 77.69 - lr: 0.000781\n",
            "2022-06-12 22:21:54,651 epoch 47 - iter 18/38 - loss 0.01901871 - samples/sec: 97.12 - lr: 0.000781\n",
            "2022-06-12 22:21:54,694 epoch 47 - iter 21/38 - loss 0.01558806 - samples/sec: 76.76 - lr: 0.000781\n",
            "2022-06-12 22:21:54,732 epoch 47 - iter 24/38 - loss 0.01364182 - samples/sec: 80.89 - lr: 0.000781\n",
            "2022-06-12 22:21:54,773 epoch 47 - iter 27/38 - loss 0.01208030 - samples/sec: 80.01 - lr: 0.000781\n",
            "2022-06-12 22:21:54,820 epoch 47 - iter 30/38 - loss 0.01102786 - samples/sec: 67.02 - lr: 0.000781\n",
            "2022-06-12 22:21:54,864 epoch 47 - iter 33/38 - loss 0.00968600 - samples/sec: 71.06 - lr: 0.000781\n",
            "2022-06-12 22:21:54,901 epoch 47 - iter 36/38 - loss 0.02865540 - samples/sec: 89.02 - lr: 0.000781\n",
            "2022-06-12 22:21:54,929 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:54,930 EPOCH 47 done: loss 0.0270 - lr 0.000781\n",
            "2022-06-12 22:21:54,932 BAD EPOCHS (no improvement): 1\n",
            "2022-06-12 22:21:54,935 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:54,982 epoch 48 - iter 3/38 - loss 0.10196806 - samples/sec: 82.08 - lr: 0.000781\n",
            "2022-06-12 22:21:55,018 epoch 48 - iter 6/38 - loss 0.05717970 - samples/sec: 85.37 - lr: 0.000781\n",
            "2022-06-12 22:21:55,061 epoch 48 - iter 9/38 - loss 0.03334673 - samples/sec: 72.21 - lr: 0.000781\n",
            "2022-06-12 22:21:55,109 epoch 48 - iter 12/38 - loss 0.05096109 - samples/sec: 64.06 - lr: 0.000781\n",
            "2022-06-12 22:21:55,149 epoch 48 - iter 15/38 - loss 0.04223915 - samples/sec: 80.51 - lr: 0.000781\n",
            "2022-06-12 22:21:55,190 epoch 48 - iter 18/38 - loss 0.03672449 - samples/sec: 75.78 - lr: 0.000781\n",
            "2022-06-12 22:21:55,232 epoch 48 - iter 21/38 - loss 0.03251648 - samples/sec: 73.33 - lr: 0.000781\n",
            "2022-06-12 22:21:55,280 epoch 48 - iter 24/38 - loss 0.02859651 - samples/sec: 65.14 - lr: 0.000781\n",
            "2022-06-12 22:21:55,317 epoch 48 - iter 27/38 - loss 0.02632634 - samples/sec: 83.20 - lr: 0.000781\n",
            "2022-06-12 22:21:55,353 epoch 48 - iter 30/38 - loss 0.02503761 - samples/sec: 85.98 - lr: 0.000781\n",
            "2022-06-12 22:21:55,393 epoch 48 - iter 33/38 - loss 0.04276487 - samples/sec: 77.72 - lr: 0.000781\n",
            "2022-06-12 22:21:55,427 epoch 48 - iter 36/38 - loss 0.04103563 - samples/sec: 92.20 - lr: 0.000781\n",
            "2022-06-12 22:21:55,455 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:55,458 EPOCH 48 done: loss 0.0406 - lr 0.000781\n",
            "2022-06-12 22:21:55,460 BAD EPOCHS (no improvement): 2\n",
            "2022-06-12 22:21:55,463 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:55,508 epoch 49 - iter 3/38 - loss 0.05157547 - samples/sec: 74.57 - lr: 0.000781\n",
            "2022-06-12 22:21:55,544 epoch 49 - iter 6/38 - loss 0.02890841 - samples/sec: 89.84 - lr: 0.000781\n",
            "2022-06-12 22:21:55,581 epoch 49 - iter 9/38 - loss 0.01982297 - samples/sec: 84.13 - lr: 0.000781\n",
            "2022-06-12 22:21:55,621 epoch 49 - iter 12/38 - loss 0.04047044 - samples/sec: 78.54 - lr: 0.000781\n",
            "2022-06-12 22:21:55,658 epoch 49 - iter 15/38 - loss 0.03352034 - samples/sec: 83.25 - lr: 0.000781\n",
            "2022-06-12 22:21:55,697 epoch 49 - iter 18/38 - loss 0.04967162 - samples/sec: 79.61 - lr: 0.000781\n",
            "2022-06-12 22:21:55,739 epoch 49 - iter 21/38 - loss 0.05292564 - samples/sec: 73.69 - lr: 0.000781\n",
            "2022-06-12 22:21:55,785 epoch 49 - iter 24/38 - loss 0.04345363 - samples/sec: 67.19 - lr: 0.000781\n",
            "2022-06-12 22:21:55,830 epoch 49 - iter 27/38 - loss 0.03629301 - samples/sec: 68.71 - lr: 0.000781\n",
            "2022-06-12 22:21:55,868 epoch 49 - iter 30/38 - loss 0.03363486 - samples/sec: 83.04 - lr: 0.000781\n",
            "2022-06-12 22:21:55,910 epoch 49 - iter 33/38 - loss 0.03016748 - samples/sec: 73.80 - lr: 0.000781\n",
            "2022-06-12 22:21:55,948 epoch 49 - iter 36/38 - loss 0.02844584 - samples/sec: 82.16 - lr: 0.000781\n",
            "2022-06-12 22:21:55,973 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:55,976 EPOCH 49 done: loss 0.0275 - lr 0.000781\n",
            "2022-06-12 22:21:55,977 BAD EPOCHS (no improvement): 3\n",
            "2022-06-12 22:21:55,980 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:56,030 epoch 50 - iter 3/38 - loss 0.00109258 - samples/sec: 75.92 - lr: 0.000781\n",
            "2022-06-12 22:21:56,070 epoch 50 - iter 6/38 - loss 0.00723748 - samples/sec: 86.24 - lr: 0.000781\n",
            "2022-06-12 22:21:56,114 epoch 50 - iter 9/38 - loss 0.00517446 - samples/sec: 78.30 - lr: 0.000781\n",
            "2022-06-12 22:21:56,155 epoch 50 - iter 12/38 - loss 0.00586482 - samples/sec: 76.37 - lr: 0.000781\n",
            "2022-06-12 22:21:56,192 epoch 50 - iter 15/38 - loss 0.00531826 - samples/sec: 84.00 - lr: 0.000781\n",
            "2022-06-12 22:21:56,232 epoch 50 - iter 18/38 - loss 0.01102678 - samples/sec: 81.39 - lr: 0.000781\n",
            "2022-06-12 22:21:56,283 epoch 50 - iter 21/38 - loss 0.02854355 - samples/sec: 64.33 - lr: 0.000781\n",
            "2022-06-12 22:21:56,322 epoch 50 - iter 24/38 - loss 0.02767885 - samples/sec: 79.36 - lr: 0.000781\n",
            "2022-06-12 22:21:56,366 epoch 50 - iter 27/38 - loss 0.02575889 - samples/sec: 72.34 - lr: 0.000781\n",
            "2022-06-12 22:21:56,406 epoch 50 - iter 30/38 - loss 0.03150461 - samples/sec: 79.37 - lr: 0.000781\n",
            "2022-06-12 22:21:56,449 epoch 50 - iter 33/38 - loss 0.02953927 - samples/sec: 72.70 - lr: 0.000781\n",
            "2022-06-12 22:21:56,487 epoch 50 - iter 36/38 - loss 0.02780652 - samples/sec: 86.30 - lr: 0.000781\n",
            "2022-06-12 22:21:56,516 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:56,517 EPOCH 50 done: loss 0.0258 - lr 0.000781\n",
            "2022-06-12 22:21:56,520 Epoch    50: reducing learning rate of group 0 to 3.9063e-04.\n",
            "2022-06-12 22:21:56,522 BAD EPOCHS (no improvement): 4\n",
            "2022-06-12 22:21:56,528 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:56,569 epoch 51 - iter 3/38 - loss 0.06439523 - samples/sec: 84.90 - lr: 0.000391\n",
            "2022-06-12 22:21:56,614 epoch 51 - iter 6/38 - loss 0.16780529 - samples/sec: 73.90 - lr: 0.000391\n",
            "2022-06-12 22:21:56,652 epoch 51 - iter 9/38 - loss 0.11601996 - samples/sec: 82.53 - lr: 0.000391\n",
            "2022-06-12 22:21:56,697 epoch 51 - iter 12/38 - loss 0.10852111 - samples/sec: 67.53 - lr: 0.000391\n",
            "2022-06-12 22:21:56,741 epoch 51 - iter 15/38 - loss 0.08236657 - samples/sec: 71.20 - lr: 0.000391\n",
            "2022-06-12 22:21:56,784 epoch 51 - iter 18/38 - loss 0.06879778 - samples/sec: 72.40 - lr: 0.000391\n",
            "2022-06-12 22:21:56,821 epoch 51 - iter 21/38 - loss 0.06346672 - samples/sec: 83.38 - lr: 0.000391\n",
            "2022-06-12 22:21:56,867 epoch 51 - iter 24/38 - loss 0.05698154 - samples/sec: 66.80 - lr: 0.000391\n",
            "2022-06-12 22:21:56,904 epoch 51 - iter 27/38 - loss 0.05303081 - samples/sec: 85.18 - lr: 0.000391\n",
            "2022-06-12 22:21:56,944 epoch 51 - iter 30/38 - loss 0.04784698 - samples/sec: 77.66 - lr: 0.000391\n",
            "2022-06-12 22:21:56,983 epoch 51 - iter 33/38 - loss 0.04415774 - samples/sec: 78.77 - lr: 0.000391\n",
            "2022-06-12 22:21:57,023 epoch 51 - iter 36/38 - loss 0.04103521 - samples/sec: 78.15 - lr: 0.000391\n",
            "2022-06-12 22:21:57,046 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:57,049 EPOCH 51 done: loss 0.0401 - lr 0.000391\n",
            "2022-06-12 22:21:57,052 BAD EPOCHS (no improvement): 1\n",
            "2022-06-12 22:21:57,054 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:57,097 epoch 52 - iter 3/38 - loss 0.05524284 - samples/sec: 81.19 - lr: 0.000391\n",
            "2022-06-12 22:21:57,134 epoch 52 - iter 6/38 - loss 0.02957215 - samples/sec: 87.11 - lr: 0.000391\n",
            "2022-06-12 22:21:57,175 epoch 52 - iter 9/38 - loss 0.01980410 - samples/sec: 83.47 - lr: 0.000391\n",
            "2022-06-12 22:21:57,220 epoch 52 - iter 12/38 - loss 0.02420824 - samples/sec: 74.21 - lr: 0.000391\n",
            "2022-06-12 22:21:57,263 epoch 52 - iter 15/38 - loss 0.02420473 - samples/sec: 79.13 - lr: 0.000391\n",
            "2022-06-12 22:21:57,307 epoch 52 - iter 18/38 - loss 0.02073371 - samples/sec: 76.46 - lr: 0.000391\n",
            "2022-06-12 22:21:57,349 epoch 52 - iter 21/38 - loss 0.01828687 - samples/sec: 76.76 - lr: 0.000391\n",
            "2022-06-12 22:21:57,392 epoch 52 - iter 24/38 - loss 0.01625245 - samples/sec: 71.86 - lr: 0.000391\n",
            "2022-06-12 22:21:57,437 epoch 52 - iter 27/38 - loss 0.01857598 - samples/sec: 68.98 - lr: 0.000391\n",
            "2022-06-12 22:21:57,475 epoch 52 - iter 30/38 - loss 0.03762391 - samples/sec: 83.33 - lr: 0.000391\n",
            "2022-06-12 22:21:57,514 epoch 52 - iter 33/38 - loss 0.03501667 - samples/sec: 78.66 - lr: 0.000391\n",
            "2022-06-12 22:21:57,552 epoch 52 - iter 36/38 - loss 0.03323647 - samples/sec: 87.14 - lr: 0.000391\n",
            "2022-06-12 22:21:57,579 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:57,580 EPOCH 52 done: loss 0.0312 - lr 0.000391\n",
            "2022-06-12 22:21:57,583 BAD EPOCHS (no improvement): 2\n",
            "2022-06-12 22:21:57,586 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:57,630 epoch 53 - iter 3/38 - loss 0.02593193 - samples/sec: 86.63 - lr: 0.000391\n",
            "2022-06-12 22:21:57,667 epoch 53 - iter 6/38 - loss 0.01543572 - samples/sec: 83.63 - lr: 0.000391\n",
            "2022-06-12 22:21:57,708 epoch 53 - iter 9/38 - loss 0.02296688 - samples/sec: 76.98 - lr: 0.000391\n",
            "2022-06-12 22:21:57,748 epoch 53 - iter 12/38 - loss 0.01862919 - samples/sec: 77.43 - lr: 0.000391\n",
            "2022-06-12 22:21:57,790 epoch 53 - iter 15/38 - loss 0.01457432 - samples/sec: 73.58 - lr: 0.000391\n",
            "2022-06-12 22:21:57,830 epoch 53 - iter 18/38 - loss 0.02893275 - samples/sec: 77.06 - lr: 0.000391\n",
            "2022-06-12 22:21:57,873 epoch 53 - iter 21/38 - loss 0.02437380 - samples/sec: 72.96 - lr: 0.000391\n",
            "2022-06-12 22:21:57,916 epoch 53 - iter 24/38 - loss 0.02660278 - samples/sec: 72.36 - lr: 0.000391\n",
            "2022-06-12 22:21:57,951 epoch 53 - iter 27/38 - loss 0.02901684 - samples/sec: 89.28 - lr: 0.000391\n",
            "2022-06-12 22:21:57,990 epoch 53 - iter 30/38 - loss 0.07485020 - samples/sec: 79.26 - lr: 0.000391\n",
            "2022-06-12 22:21:58,031 epoch 53 - iter 33/38 - loss 0.07306931 - samples/sec: 74.83 - lr: 0.000391\n",
            "2022-06-12 22:21:58,071 epoch 53 - iter 36/38 - loss 0.06714900 - samples/sec: 78.78 - lr: 0.000391\n",
            "2022-06-12 22:21:58,097 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:58,099 EPOCH 53 done: loss 0.0651 - lr 0.000391\n",
            "2022-06-12 22:21:58,101 BAD EPOCHS (no improvement): 3\n",
            "2022-06-12 22:21:58,104 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:58,150 epoch 54 - iter 3/38 - loss 0.00253002 - samples/sec: 78.20 - lr: 0.000391\n",
            "2022-06-12 22:21:58,190 epoch 54 - iter 6/38 - loss 0.00214386 - samples/sec: 76.86 - lr: 0.000391\n",
            "2022-06-12 22:21:58,227 epoch 54 - iter 9/38 - loss 0.00218830 - samples/sec: 84.27 - lr: 0.000391\n",
            "2022-06-12 22:21:58,268 epoch 54 - iter 12/38 - loss 0.00537674 - samples/sec: 79.20 - lr: 0.000391\n",
            "2022-06-12 22:21:58,312 epoch 54 - iter 15/38 - loss 0.01931797 - samples/sec: 70.20 - lr: 0.000391\n",
            "2022-06-12 22:21:58,352 epoch 54 - iter 18/38 - loss 0.01685467 - samples/sec: 80.89 - lr: 0.000391\n",
            "2022-06-12 22:21:58,387 epoch 54 - iter 21/38 - loss 0.01781783 - samples/sec: 87.13 - lr: 0.000391\n",
            "2022-06-12 22:21:58,430 epoch 54 - iter 24/38 - loss 0.01951182 - samples/sec: 79.04 - lr: 0.000391\n",
            "2022-06-12 22:21:58,467 epoch 54 - iter 27/38 - loss 0.01776305 - samples/sec: 90.13 - lr: 0.000391\n",
            "2022-06-12 22:21:58,502 epoch 54 - iter 30/38 - loss 0.01661196 - samples/sec: 88.46 - lr: 0.000391\n",
            "2022-06-12 22:21:58,545 epoch 54 - iter 33/38 - loss 0.01494546 - samples/sec: 72.93 - lr: 0.000391\n",
            "2022-06-12 22:21:58,591 epoch 54 - iter 36/38 - loss 0.01856178 - samples/sec: 67.49 - lr: 0.000391\n",
            "2022-06-12 22:21:58,621 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:58,622 EPOCH 54 done: loss 0.0203 - lr 0.000391\n",
            "2022-06-12 22:21:58,625 Epoch    54: reducing learning rate of group 0 to 1.9531e-04.\n",
            "2022-06-12 22:21:58,627 BAD EPOCHS (no improvement): 4\n",
            "2022-06-12 22:21:58,637 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:58,681 epoch 55 - iter 3/38 - loss 0.01706664 - samples/sec: 77.75 - lr: 0.000195\n",
            "2022-06-12 22:21:58,722 epoch 55 - iter 6/38 - loss 0.01096007 - samples/sec: 79.34 - lr: 0.000195\n",
            "2022-06-12 22:21:58,761 epoch 55 - iter 9/38 - loss 0.00828683 - samples/sec: 79.06 - lr: 0.000195\n",
            "2022-06-12 22:21:58,800 epoch 55 - iter 12/38 - loss 0.02258673 - samples/sec: 80.09 - lr: 0.000195\n",
            "2022-06-12 22:21:58,841 epoch 55 - iter 15/38 - loss 0.01808787 - samples/sec: 76.25 - lr: 0.000195\n",
            "2022-06-12 22:21:58,884 epoch 55 - iter 18/38 - loss 0.03563949 - samples/sec: 75.35 - lr: 0.000195\n",
            "2022-06-12 22:21:58,927 epoch 55 - iter 21/38 - loss 0.03570403 - samples/sec: 72.55 - lr: 0.000195\n",
            "2022-06-12 22:21:58,960 epoch 55 - iter 24/38 - loss 0.03497526 - samples/sec: 92.74 - lr: 0.000195\n",
            "2022-06-12 22:21:59,003 epoch 55 - iter 27/38 - loss 0.03628142 - samples/sec: 71.92 - lr: 0.000195\n",
            "2022-06-12 22:21:59,046 epoch 55 - iter 30/38 - loss 0.06440231 - samples/sec: 72.10 - lr: 0.000195\n",
            "2022-06-12 22:21:59,089 epoch 55 - iter 33/38 - loss 0.05831696 - samples/sec: 76.38 - lr: 0.000195\n",
            "2022-06-12 22:21:59,127 epoch 55 - iter 36/38 - loss 0.05472243 - samples/sec: 86.49 - lr: 0.000195\n",
            "2022-06-12 22:21:59,153 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:59,154 EPOCH 55 done: loss 0.0527 - lr 0.000195\n",
            "2022-06-12 22:21:59,157 BAD EPOCHS (no improvement): 1\n",
            "2022-06-12 22:21:59,159 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:59,207 epoch 56 - iter 3/38 - loss 0.00287326 - samples/sec: 77.14 - lr: 0.000195\n",
            "2022-06-12 22:21:59,242 epoch 56 - iter 6/38 - loss 0.00973282 - samples/sec: 90.47 - lr: 0.000195\n",
            "2022-06-12 22:21:59,289 epoch 56 - iter 9/38 - loss 0.03555562 - samples/sec: 65.51 - lr: 0.000195\n",
            "2022-06-12 22:21:59,334 epoch 56 - iter 12/38 - loss 0.03012613 - samples/sec: 69.01 - lr: 0.000195\n",
            "2022-06-12 22:21:59,374 epoch 56 - iter 15/38 - loss 0.05253173 - samples/sec: 77.52 - lr: 0.000195\n",
            "2022-06-12 22:21:59,413 epoch 56 - iter 18/38 - loss 0.04485611 - samples/sec: 80.28 - lr: 0.000195\n",
            "2022-06-12 22:21:59,456 epoch 56 - iter 21/38 - loss 0.04052784 - samples/sec: 71.27 - lr: 0.000195\n",
            "2022-06-12 22:21:59,492 epoch 56 - iter 24/38 - loss 0.04032680 - samples/sec: 86.26 - lr: 0.000195\n",
            "2022-06-12 22:21:59,529 epoch 56 - iter 27/38 - loss 0.03687288 - samples/sec: 84.21 - lr: 0.000195\n",
            "2022-06-12 22:21:59,571 epoch 56 - iter 30/38 - loss 0.04625756 - samples/sec: 74.52 - lr: 0.000195\n",
            "2022-06-12 22:21:59,616 epoch 56 - iter 33/38 - loss 0.04415905 - samples/sec: 68.58 - lr: 0.000195\n",
            "2022-06-12 22:21:59,653 epoch 56 - iter 36/38 - loss 0.04128576 - samples/sec: 86.08 - lr: 0.000195\n",
            "2022-06-12 22:21:59,683 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:59,684 EPOCH 56 done: loss 0.0391 - lr 0.000195\n",
            "2022-06-12 22:21:59,687 BAD EPOCHS (no improvement): 2\n",
            "2022-06-12 22:21:59,689 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:21:59,736 epoch 57 - iter 3/38 - loss 0.00130595 - samples/sec: 78.15 - lr: 0.000195\n",
            "2022-06-12 22:21:59,778 epoch 57 - iter 6/38 - loss 0.00093521 - samples/sec: 74.00 - lr: 0.000195\n",
            "2022-06-12 22:21:59,822 epoch 57 - iter 9/38 - loss 0.00216100 - samples/sec: 70.28 - lr: 0.000195\n",
            "2022-06-12 22:21:59,866 epoch 57 - iter 12/38 - loss 0.02948337 - samples/sec: 69.84 - lr: 0.000195\n",
            "2022-06-12 22:21:59,904 epoch 57 - iter 15/38 - loss 0.03242767 - samples/sec: 82.03 - lr: 0.000195\n",
            "2022-06-12 22:21:59,940 epoch 57 - iter 18/38 - loss 0.02998795 - samples/sec: 86.17 - lr: 0.000195\n",
            "2022-06-12 22:21:59,976 epoch 57 - iter 21/38 - loss 0.02733629 - samples/sec: 91.89 - lr: 0.000195\n",
            "2022-06-12 22:22:00,018 epoch 57 - iter 24/38 - loss 0.03067361 - samples/sec: 73.80 - lr: 0.000195\n",
            "2022-06-12 22:22:00,056 epoch 57 - iter 27/38 - loss 0.02781458 - samples/sec: 81.27 - lr: 0.000195\n",
            "2022-06-12 22:22:00,099 epoch 57 - iter 30/38 - loss 0.02507571 - samples/sec: 71.69 - lr: 0.000195\n",
            "2022-06-12 22:22:00,134 epoch 57 - iter 33/38 - loss 0.02360315 - samples/sec: 90.45 - lr: 0.000195\n",
            "2022-06-12 22:22:00,172 epoch 57 - iter 36/38 - loss 0.02206639 - samples/sec: 83.02 - lr: 0.000195\n",
            "2022-06-12 22:22:00,200 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:22:00,202 EPOCH 57 done: loss 0.0226 - lr 0.000195\n",
            "2022-06-12 22:22:00,204 BAD EPOCHS (no improvement): 3\n",
            "2022-06-12 22:22:00,207 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:22:00,253 epoch 58 - iter 3/38 - loss 0.00581082 - samples/sec: 78.41 - lr: 0.000195\n",
            "2022-06-12 22:22:00,291 epoch 58 - iter 6/38 - loss 0.01160694 - samples/sec: 81.56 - lr: 0.000195\n",
            "2022-06-12 22:22:00,329 epoch 58 - iter 9/38 - loss 0.08480236 - samples/sec: 91.82 - lr: 0.000195\n",
            "2022-06-12 22:22:00,376 epoch 58 - iter 12/38 - loss 0.14117981 - samples/sec: 68.42 - lr: 0.000195\n",
            "2022-06-12 22:22:00,419 epoch 58 - iter 15/38 - loss 0.11943324 - samples/sec: 72.34 - lr: 0.000195\n",
            "2022-06-12 22:22:00,460 epoch 58 - iter 18/38 - loss 0.10890090 - samples/sec: 75.39 - lr: 0.000195\n",
            "2022-06-12 22:22:00,500 epoch 58 - iter 21/38 - loss 0.09429453 - samples/sec: 78.69 - lr: 0.000195\n",
            "2022-06-12 22:22:00,535 epoch 58 - iter 24/38 - loss 0.08669859 - samples/sec: 89.76 - lr: 0.000195\n",
            "2022-06-12 22:22:00,576 epoch 58 - iter 27/38 - loss 0.08335542 - samples/sec: 76.79 - lr: 0.000195\n",
            "2022-06-12 22:22:00,619 epoch 58 - iter 30/38 - loss 0.08166578 - samples/sec: 71.10 - lr: 0.000195\n",
            "2022-06-12 22:22:00,667 epoch 58 - iter 33/38 - loss 0.08414103 - samples/sec: 65.35 - lr: 0.000195\n",
            "2022-06-12 22:22:00,708 epoch 58 - iter 36/38 - loss 0.07604181 - samples/sec: 73.93 - lr: 0.000195\n",
            "2022-06-12 22:22:00,738 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:22:00,739 EPOCH 58 done: loss 0.0705 - lr 0.000195\n",
            "2022-06-12 22:22:00,741 Epoch    58: reducing learning rate of group 0 to 9.7656e-05.\n",
            "2022-06-12 22:22:00,744 BAD EPOCHS (no improvement): 4\n",
            "2022-06-12 22:22:00,752 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:22:00,754 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:22:00,759 learning rate too small - quitting training!\n",
            "2022-06-12 22:22:00,760 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:22:02,820 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-12 22:22:02,824 Testing using last state of model ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 23.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-06-12 22:22:03,021 Evaluating as a multi-label problem: False\n",
            "2022-06-12 22:22:03,031 0.8\t0.5714\t0.6667\t0.5\n",
            "2022-06-12 22:22:03,032 \n",
            "Results:\n",
            "- F-score (micro) 0.6667\n",
            "- F-score (macro) 0.8\n",
            "- Accuracy 0.5\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       value     0.7500    0.5000    0.6000         6\n",
            "        time     1.0000    1.0000    1.0000         1\n",
            "\n",
            "   micro avg     0.8000    0.5714    0.6667         7\n",
            "   macro avg     0.8750    0.7500    0.8000         7\n",
            "weighted avg     0.7857    0.5714    0.6571         7\n",
            "\n",
            "2022-06-12 22:22:03,039 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'dev_loss_history': [],\n",
              " 'dev_score_history': [],\n",
              " 'test_score': 0.6666666666666666,\n",
              " 'train_loss_history': [0.07990737120901342,\n",
              "  0.05931226382911427,\n",
              "  0.08140684858130699,\n",
              "  0.09559431395122996,\n",
              "  0.12887827791689055,\n",
              "  0.07306244648079004,\n",
              "  0.10643832479710916,\n",
              "  0.028233687673802712,\n",
              "  0.06872195204837615,\n",
              "  0.058675510732657844,\n",
              "  0.06544429041639137,\n",
              "  0.049977075654777894,\n",
              "  0.055217778372498694,\n",
              "  0.04750386135285672,\n",
              "  0.03276113772480904,\n",
              "  0.02773266831295198,\n",
              "  0.07347876254510702,\n",
              "  0.09119680468477724,\n",
              "  0.03646449971819456,\n",
              "  0.05400232931938313,\n",
              "  0.03960466207624811,\n",
              "  0.03917331057410258,\n",
              "  0.02922255930847395,\n",
              "  0.048842394662169275,\n",
              "  0.03349969289559857,\n",
              "  0.023432983341713377,\n",
              "  0.04444575043859092,\n",
              "  0.05364010325151748,\n",
              "  0.04112821529345884,\n",
              "  0.018879557187672442,\n",
              "  0.031014222637871385,\n",
              "  0.03349580729317931,\n",
              "  0.06642650760239385,\n",
              "  0.022980487922753545,\n",
              "  0.03232858792556706,\n",
              "  0.030170305954036216,\n",
              "  0.03500580344501481,\n",
              "  0.047110419291102754,\n",
              "  0.09791245513689119,\n",
              "  0.030946345134295495,\n",
              "  0.028345115122741925,\n",
              "  0.01864932106330049,\n",
              "  0.03099080266562536,\n",
              "  0.020842148025682867,\n",
              "  0.030864981470498012,\n",
              "  0.04330165324157942,\n",
              "  0.027022007229602914,\n",
              "  0.04055741817091477,\n",
              "  0.027518502841651662,\n",
              "  0.02584633242241955,\n",
              "  0.040137766019119205,\n",
              "  0.03119366585543608,\n",
              "  0.06506441960104337,\n",
              "  0.020340972673494134,\n",
              "  0.052692863577803714,\n",
              "  0.03909246451792664,\n",
              "  0.022580962198817597,\n",
              "  0.07047487634708446]}"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train('resources/taggers/sota-ner-flair',\n",
        "              learning_rate=0.1,\n",
        "              train_with_dev=True,\n",
        "              mini_batch_size=1,\n",
        "              max_epochs=150)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hLksstNUTl4"
      },
      "source": [
        "# Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "tQjZ0ylxVCgi"
      },
      "outputs": [],
      "source": [
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BStzRtYTvt8",
        "outputId": "297021ac-c5b1-4292-aa60-0a284ccd4cd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-06-12 22:20:41,906 loading file resources/taggers/sota-ner-flair/final-model.pt\n",
            "2022-06-12 22:20:42,658 SequenceTagger predicts: Dictionary with 15 tags: O, S-value, B-value, E-value, I-value, S-location, B-location, E-location, I-location, S-time, B-time, E-time, I-time, <START>, <STOP>\n"
          ]
        }
      ],
      "source": [
        "model = SequenceTagger.load('resources/taggers/sota-ner-flair/final-model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Qm1ciRhWb57",
        "outputId": "cdd929ab-a617-40cf-a91e-3366461e9be3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: \"Enter email address to Email textbox admin @ gmail.com\" → [\"Email textbox\"/location, \"admin\"/value, \"@\"/value, \"gmail.com\"/value]\n"
          ]
        }
      ],
      "source": [
        "sentence = Sentence(\"Enter email address to Email textbox admin@gmail.com\")\n",
        "model.predict(sentence)\n",
        "print(sentence.to_tagged_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_lTMTGAXkUx",
        "outputId": "bf606b09-48a2-4338-9781-684204bee5cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: \"Wait for email to appear for 20s\" → [\"20s\"/time]\n"
          ]
        }
      ],
      "source": [
        "sentence = Sentence(\"Wait for email to appear for 20s\")\n",
        "model.predict(sentence)\n",
        "print(sentence.to_tagged_string())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "flair_sequence_tagger.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0e44730a994049ee89e31a0d3b27cbe6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0eadd28db21443ff8fdd928267904d02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "54233e83ac964e32bc14fabe6cd3a2d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e44730a994049ee89e31a0d3b27cbe6",
            "placeholder": "​",
            "style": "IPY_MODEL_81b7ea20f30748d88a353c1ef18aa1b8",
            "value": " 432M/432M [00:12&lt;00:00, 58.2MB/s]"
          }
        },
        "58563cd15871480491cdde3d369a0044": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81b7ea20f30748d88a353c1ef18aa1b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "964fd675176148d4bf5163e7bfe695a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9da5e83bd300484c90c1ce1358860155",
            "placeholder": "​",
            "style": "IPY_MODEL_58563cd15871480491cdde3d369a0044",
            "value": "Downloading: 100%"
          }
        },
        "9da5e83bd300484c90c1ce1358860155": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb99e1d726bb45d4949eff4ad9d251d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee3c2b13b1f746e3b85ff8eba7762842",
            "max": 432176557,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0eadd28db21443ff8fdd928267904d02",
            "value": 432176557
          }
        },
        "e5970413cbef4286b561549f8e5c0908": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_964fd675176148d4bf5163e7bfe695a5",
              "IPY_MODEL_bb99e1d726bb45d4949eff4ad9d251d6",
              "IPY_MODEL_54233e83ac964e32bc14fabe6cd3a2d2"
            ],
            "layout": "IPY_MODEL_f266e33f613946ceac5faae3a9f8b865"
          }
        },
        "ee3c2b13b1f746e3b85ff8eba7762842": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f266e33f613946ceac5faae3a9f8b865": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
