{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yDN347uHXsV"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7ElOSYKRECP0"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import io\n",
        "import os\n",
        "#you may need to install the packages by\n",
        "#!pip install csv\n",
        "#!pip install io\n",
        "#!pip install os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FW2Avk_nECSa",
        "outputId": "25b66bd4-2f4a-4910-ce61-a110e63c0074"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#The file is trained on Google Colab and this is to connect to Google Drive\n",
        "#If you have GPU on you local computer, you may train locally\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XMPcUYUxECVU"
      },
      "outputs": [],
      "source": [
        "#Change the path to the training file\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/data/anno_14_tc.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfPryO18JyqR"
      },
      "source": [
        "# Load in data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "X2-T7mchECYe"
      },
      "outputs": [],
      "source": [
        "#Read the csv and save it as a file\n",
        "with open(file_path) as f:\n",
        "    f.readline()\n",
        "    reader = csv.reader(f)\n",
        "    data = list(reader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3BYT77xECbX",
        "outputId": "a8fa5a01-c76d-42a5-d384-4a2bb7dbba91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['S1', '*'], ['Enter', 'O'], ['email', 'O'], ['address', 'O'], ['to', 'O']]\n"
          ]
        }
      ],
      "source": [
        "#To inspect the file format\n",
        "print(data[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSu6u20lKNa5",
        "outputId": "beca8f35-c8a9-4222-ae8b-8fa9735e3a80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['S1', '*'], ['Enter', 'O'], ['email', 'O'], ['address', 'O'], ['to', 'O'], ['Email', 'B-location'], ['textbox', 'I-location'], ['admin1@mail.com', 'B-value'], ['S2', '*'], ['Enter', 'O'], ['password', 'O'], ['to', 'O'], ['Password', 'B-location'], ['textbox', 'I-location'], ['Admin@123', 'B-value'], ['S3', '*'], ['Click', 'O'], ['button', 'B-value'], ['Login', 'I-value'], ['S4', '*']]\n"
          ]
        }
      ],
      "source": [
        "print(data[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_irvfVY9PMH"
      },
      "source": [
        "# Clean the sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "c1LzlGwtKNTQ"
      },
      "outputs": [],
      "source": [
        "#The ['S1', '*'] is to indicate the beginning of the steps/sentences \n",
        "#We need to remove it and use it to indicate the segmentation of sentences\n",
        "sents = []\n",
        "sent = []\n",
        "for word, tag in data:\n",
        "  if tag == '*':\n",
        "    if len(sent) > 0:\n",
        "        sents.append(sent)\n",
        "        sent = []\n",
        "    else:\n",
        "        continue\n",
        "  else:\n",
        "    sent.append((word, tag))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xWx7duyP6usw"
      },
      "outputs": [],
      "source": [
        "#Make the sentences into text format\n",
        "texts_sents = []\n",
        "for sent in sents:\n",
        "  words = []\n",
        "  for word, tag in sent:\n",
        "    words.append(word)\n",
        "  texts_sents.append(\" \".join(words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BYUiCnmW8hra",
        "outputId": "ee2005f4-85d5-4229-dcd3-f3c9c6fba89d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Enter email address to Email textbox admin1@mail.com'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#inspect the format\n",
        "texts_sents[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfwtoOM79B-v"
      },
      "source": [
        "# Trying out Flair BERT models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH8ojK5LEChE",
        "outputId": "ccb117a1-0113-45d2-ca80-722e585e7277"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flair\n",
            "  Downloading flair-0.11.3-py3-none-any.whl (401 kB)\n",
            "\u001b[K     |████████████████████████████████| 401 kB 7.7 MB/s \n",
            "\u001b[?25hCollecting mpld3==0.3\n",
            "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
            "\u001b[K     |████████████████████████████████| 788 kB 53.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair) (2.8.2)\n",
            "Collecting sqlitedict>=1.6.0\n",
            "  Downloading sqlitedict-2.0.0.tar.gz (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair) (1.0.2)\n",
            "Collecting janome\n",
            "  Downloading Janome-0.4.2-py2.py3-none-any.whl (19.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.7 MB 210 kB/s \n",
            "\u001b[?25hCollecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 14.4 MB/s \n",
            "\u001b[?25hCollecting konoha<5.0.0,>=4.0.0\n",
            "  Downloading konoha-4.6.5-py3-none-any.whl (20 kB)\n",
            "Collecting transformers>=4.0.0\n",
            "  Downloading transformers-4.20.0-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 50.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (3.6.0)\n",
            "Collecting pptree\n",
            "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair) (4.2.6)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair) (2022.6.2)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.64.0)\n",
            "Collecting conllu>=4.0\n",
            "  Downloading conllu-4.4.2-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from flair) (8.13.0)\n",
            "Collecting wikipedia-api\n",
            "  Downloading Wikipedia-API-0.5.4.tar.gz (18 kB)\n",
            "Collecting hyperopt>=0.2.7\n",
            "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 24.9 MB/s \n",
            "\u001b[?25hCollecting bpemb>=0.3.2\n",
            "  Downloading bpemb-0.3.3-py3-none-any.whl (19 kB)\n",
            "Collecting sentencepiece==0.1.95\n",
            "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 52.6 MB/s \n",
            "\u001b[?25hCollecting segtok>=1.5.7\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: torch!=1.8,>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.11.0+cu113)\n",
            "Collecting deprecated>=1.2.4\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: gdown==4.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.4.0)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from flair) (3.2.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair) (0.8.9)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown==4.4.0->flair) (4.6.3)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown==4.4.0->flair) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown==4.4.0->flair) (3.7.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown==4.4.0->flair) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bpemb>=0.3.2->flair) (1.21.6)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair) (1.14.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->flair) (6.0.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->flair) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.7->flair) (0.16.0)\n",
            "Collecting py4j\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 76.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.7->flair) (2.6.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.7->flair) (1.3.0)\n",
            "Collecting importlib-metadata<4.0.0,>=3.7.0\n",
            "  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n",
            "Collecting requests\n",
            "  Downloading requests-2.28.0-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.8 MB/s \n",
            "\u001b[?25hCollecting overrides<4.0.0,>=3.0.0\n",
            "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (4.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (1.4.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2022.5.18.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (3.1.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 58.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (21.3)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 68.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->flair) (0.2.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.7.1)\n",
            "Building wheels for collected packages: mpld3, overrides, sqlitedict, langdetect, pptree, wikipedia-api\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116702 sha256=184f20e11650b2a5df74beb265eb11346d0ab81d1ff269311b67776824627383\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/70/6a/1c79e59951a41b4045497da187b2724f5659ca64033cf4548e\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10187 sha256=5c7066e0650a89dedd81564782b68474e472d7ab2a3571d786f6198c0befa4ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/0d/38/01a9bc6e20dcfaf0a6a7b552d03137558ba1c38aea47644682\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.0.0-py3-none-any.whl size=15736 sha256=2270bf41088cc8c21febd76135f45aa5f0afa212bad3a400fd304029c822ab03\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/dd/2e/0ed4a25cb73fc30c7ea8d10b50acb7226175736067e40a7ea3\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=8437136186c8f310a7ba5cda7b94dde8032e684248b4cce66f210444a012abb9\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
            "  Building wheel for pptree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4629 sha256=003431b605007e99910006d62aada928f6b02124f040bf5145cf4bc1eb96adec\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/e8/7d/a9c3c19b4722608a0d8b05a38c36bc3f230c43becd2a46794b\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.5.4-py3-none-any.whl size=13477 sha256=2ba2aa6866c03355fcd1d64765adf21ab024c19b899c5066cbf4ca7a078cab4c\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/24/56/58ba93cf78be162451144e7a9889603f437976ef1ae7013d04\n",
            "Successfully built mpld3 overrides sqlitedict langdetect pptree wikipedia-api\n",
            "Installing collected packages: requests, pyyaml, importlib-metadata, tokenizers, sentencepiece, py4j, overrides, huggingface-hub, wikipedia-api, transformers, sqlitedict, segtok, pptree, mpld3, langdetect, konoha, janome, hyperopt, ftfy, deprecated, conllu, bpemb, flair\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.11.4\n",
            "    Uninstalling importlib-metadata-4.11.4:\n",
            "      Successfully uninstalled importlib-metadata-4.11.4\n",
            "  Attempting uninstall: hyperopt\n",
            "    Found existing installation: hyperopt 0.1.2\n",
            "    Uninstalling hyperopt-0.1.2:\n",
            "      Successfully uninstalled hyperopt-0.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "markdown 3.3.7 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 3.10.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed bpemb-0.3.3 conllu-4.4.2 deprecated-1.2.13 flair-0.11.3 ftfy-6.1.1 huggingface-hub-0.7.0 hyperopt-0.2.7 importlib-metadata-3.10.1 janome-0.4.2 konoha-4.6.5 langdetect-1.0.9 mpld3-0.3 overrides-3.1.0 pptree-3.1 py4j-0.10.9.5 pyyaml-6.0 requests-2.28.0 segtok-1.5.11 sentencepiece-0.1.95 sqlitedict-2.0.0 tokenizers-0.12.1 transformers-4.20.0 wikipedia-api-0.5.4\n"
          ]
        }
      ],
      "source": [
        "!pip install flair\n",
        "#You may need to install flair libary \n",
        "#The documentation https://github.com/flairNLP/flair\n",
        "#Flair is a framework for state-of-art NLP for:\n",
        "#named entity recognition, part-of-speech tagging, classification and etc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CnRzl7HAECj2"
      },
      "outputs": [],
      "source": [
        "from flair.models import SequenceTagger\n",
        "#This is to import the sequence tagger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "3daab240581343be96014ea9b69b64e1",
            "8e9486701051494aa3e07272092c01ff",
            "a40f442c26b6484790eac008afab50ca",
            "90bcb8820adc41cc9ca6e3ff35a6c7f0",
            "0b2bedf9e2f84d8eafd850054d70c764",
            "bcd6b3f5666446da93b1ee4290c7cfa2",
            "582d072d25464fd4a9903d16d03a12e4",
            "86883fdbe0b44daea0dfc362d65e1970",
            "897f670f9ce640869c71b5659849adbe",
            "ba08420a176e4c3c8dffe5025475b9bd",
            "60c0e6a92c5143e9bd63729dc56df4f4"
          ]
        },
        "id": "U08yXATIECmr",
        "outputId": "4727501a-2606-44fc-ad2b-cd70e9ff34db"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3daab240581343be96014ea9b69b64e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/432M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-06-17 00:13:29,327 loading file /root/.flair/models/ner-english/4f4cdab26f24cb98b732b389e6cebc646c36f54cfd6e0b7d3b90b25656e4262f.8baa8ae8795f4df80b28e7f7b61d788ecbb057d1dc85aacb316f1bd02837a4a4\n",
            "2022-06-17 00:13:31,468 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n"
          ]
        }
      ],
      "source": [
        "tagger = SequenceTagger.load('ner')\n",
        "#To load the named entity recognition function by 'ner'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QvgEOmFi-maH"
      },
      "outputs": [],
      "source": [
        "from flair.data import Sentence\n",
        "#To precess data by sentence level, import Sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GBtRrrH293ok"
      },
      "outputs": [],
      "source": [
        "#A demo of using NER(named entity recognition) tagger for sentence\n",
        "sentence = Sentence(\"George Washington went to Washington.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "t2WnOizV-qq0"
      },
      "outputs": [],
      "source": [
        "tagger.predict(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26leOD8z_DhM",
        "outputId": "608e40fe-5f25-452f-a8b7-c53f201e0e75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: \"George Washington went to Washington .\" → [\"George Washington\"/PER, \"Washington\"/LOC]\n"
          ]
        }
      ],
      "source": [
        "#It can predicts Person: PER, and location: LOC by context because though the two Washingtongs are the same word\n",
        "#This is the power of Flair, tag the words by context rather than form only\n",
        "print(sentence.to_tagged_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjoWJRt3_Iay",
        "outputId": "339b73b8-fe28-4188-b801-4585e2834ba5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Span[0:2]: \"George Washington\" → PER (0.9989)\n",
            "Span[4:5]: \"Washington\" → LOC (0.9942)\n"
          ]
        }
      ],
      "source": [
        "#To print the entity and its probability \n",
        "for entity in sentence.get_spans('ner'):\n",
        "  print(entity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzQsZ4vwBDkZ",
        "outputId": "b82b866d-4aab-4245-ba67-9c22894ed7e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'text': 'George Washington went to Washington.', 'ner': [{'value': 'PER', 'confidence': 0.998886227607727}, {'value': 'LOC', 'confidence': 0.9942097663879395}]}\n"
          ]
        }
      ],
      "source": [
        "print(sentence.to_dict(tag_type='ner'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "nCdK3GLLCtCu"
      },
      "outputs": [],
      "source": [
        "#For our task, we have different entities to extract\n",
        "#To extract entities of our interest, we need to build our own corpus to train\n",
        "from flair.data import Corpus \n",
        "from flair.datasets import ColumnCorpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "P2-wN39ZCzhZ"
      },
      "outputs": [],
      "source": [
        "#The columns should correspond to the format of the file\n",
        "#The first column is text, the second is NER,\n",
        "#You may have other columns to assist flair such as part-of-speech tagging, dependency parsing and etc\n",
        "columns = {0: 'text', 1:'ner'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Oe3ysLKEE9Yn"
      },
      "outputs": [],
      "source": [
        "data_folder = '/content/drive/MyDrive/Colab Notebooks/data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNMjk_1wFo4s",
        "outputId": "f0cf1f1e-8c09-4a49-b7f8-5c8870549480"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[('Enter', 'O'),\n",
              "  ('email', 'O'),\n",
              "  ('address', 'O'),\n",
              "  ('to', 'O'),\n",
              "  ('Email', 'B-location'),\n",
              "  ('textbox', 'I-location'),\n",
              "  ('admin1@mail.com', 'B-value')],\n",
              " [('Enter', 'O'),\n",
              "  ('password', 'O'),\n",
              "  ('to', 'O'),\n",
              "  ('Password', 'B-location'),\n",
              "  ('textbox', 'I-location'),\n",
              "  ('Admin@123', 'B-value')],\n",
              " [('Click', 'O'), ('button', 'B-value'), ('Login', 'I-value')],\n",
              " [('Wait', 'O'),\n",
              "  ('title', 'B-value'),\n",
              "  ('to', 'O'),\n",
              "  ('be', 'O'),\n",
              "  ('present', 'O'),\n",
              "  ('for', 'O'),\n",
              "  ('30', 'B-time'),\n",
              "  ('seconds', 'I-time')],\n",
              " [('Enter', 'O'),\n",
              "  ('email', 'O'),\n",
              "  ('address', 'O'),\n",
              "  ('to', 'O'),\n",
              "  ('Email', 'B-location'),\n",
              "  ('textbox', 'I-location'),\n",
              "  ('invalid@wrong', 'B-value')],\n",
              " [('Enter', 'O'),\n",
              "  ('password', 'O'),\n",
              "  ('to', 'O'),\n",
              "  ('Password', 'B-location'),\n",
              "  ('textbox', 'I-location'),\n",
              "  ('invalidpassword', 'B-value')],\n",
              " [('Click', 'O'), ('Login', 'B-value'), ('button', 'I-value')],\n",
              " [('Wait', 'O'),\n",
              "  ('email', 'B-value'),\n",
              "  ('error', 'I-value'),\n",
              "  ('message', 'I-value'),\n",
              "  ('to', 'O'),\n",
              "  ('appear', 'O'),\n",
              "  ('for', 'O'),\n",
              "  ('3', 'B-time'),\n",
              "  ('seconds', 'I-time')],\n",
              " [('Get', 'O'),\n",
              "  ('email', 'B-value'),\n",
              "  ('error', 'I-value'),\n",
              "  ('message', 'I-value')],\n",
              " [('Check', 'O'),\n",
              "  ('if', 'O'),\n",
              "  ('actual', 'B-value'),\n",
              "  ('error', 'I-value'),\n",
              "  ('message', 'I-value'),\n",
              "  ('is', 'O'),\n",
              "  ('correct', 'O')],\n",
              " [('Wait', 'O'),\n",
              "  ('password', 'B-value'),\n",
              "  ('error', 'I-value'),\n",
              "  ('message', 'I-value'),\n",
              "  ('to', 'O'),\n",
              "  ('appear', 'O'),\n",
              "  ('for', 'O'),\n",
              "  ('3', 'B-time'),\n",
              "  ('seconds', 'I-time')],\n",
              " [('Get', 'O'),\n",
              "  ('password', 'B-value'),\n",
              "  ('error', 'I-value'),\n",
              "  ('message', 'I-value')],\n",
              " [('Check', 'O'),\n",
              "  ('if', 'O'),\n",
              "  ('actual', 'B-value'),\n",
              "  ('password', 'I-value'),\n",
              "  ('message', 'I-value'),\n",
              "  ('is', 'O'),\n",
              "  ('correct', 'O')],\n",
              " [('On', 'O'),\n",
              "  ('the', 'O'),\n",
              "  ('Dashboard', 'O'),\n",
              "  ('page', 'O'),\n",
              "  (',', 'O'),\n",
              "  ('click', 'O'),\n",
              "  ('the', 'O'),\n",
              "  ('avatar', 'B-value'),\n",
              "  ('on', 'O'),\n",
              "  ('the', 'O'),\n",
              "  ('top', 'O'),\n",
              "  ('right', 'O'),\n",
              "  ('corner', 'O'),\n",
              "  ('to', 'O'),\n",
              "  ('open', 'O'),\n",
              "  ('menu', 'O')],\n",
              " [('Click', 'O'),\n",
              "  ('button', 'B-value'),\n",
              "  ('Sign', 'I-value'),\n",
              "  ('out', 'I-value')],\n",
              " [('Wait', 'O'),\n",
              "  ('Login', 'B-value'),\n",
              "  ('button', 'I-value'),\n",
              "  ('to', 'O'),\n",
              "  ('appear', 'O'),\n",
              "  ('for', 'O'),\n",
              "  ('10s', 'B-time')],\n",
              " [('Click', 'O'),\n",
              "  (\"User's\", 'B-value'),\n",
              "  ('avatar', 'I-value'),\n",
              "  ('on', 'O'),\n",
              "  ('the', 'O'),\n",
              "  ('top', 'O'),\n",
              "  ('right', 'O')],\n",
              " [('Click', 'O'),\n",
              "  ('Change', 'B-value'),\n",
              "  ('Password', 'I-value'),\n",
              "  ('link', 'I-value')],\n",
              " [('Wait', 'O'),\n",
              "  ('title', 'B-value'),\n",
              "  ('to', 'O'),\n",
              "  ('appear', 'O'),\n",
              "  ('for', 'O'),\n",
              "  ('10', 'B-time')],\n",
              " [('Enter', 'O')],\n",
              " [('to', 'O'),\n",
              "  ('current', 'B-location'),\n",
              "  ('password', 'I-location'),\n",
              "  ('text', 'I-location'),\n",
              "  ('box', 'I-location'),\n",
              "  ('Admin@123', 'B-value')],\n",
              " [('Enter', 'O'),\n",
              "  ('new', 'O'),\n",
              "  ('password', 'O'),\n",
              "  ('to', 'O'),\n",
              "  ('new', 'B-location'),\n",
              "  ('password', 'I-location'),\n",
              "  ('text', 'I-location'),\n",
              "  ('box', 'I-location'),\n",
              "  ('Admin@1234', 'B-value')],\n",
              " [('Enter', 'O'),\n",
              "  ('new', 'O'),\n",
              "  ('password', 'O'),\n",
              "  ('again', 'O'),\n",
              "  ('to', 'O'),\n",
              "  ('confirm', 'O'),\n",
              "  ('password', 'O'),\n",
              "  ('Admin@1234', 'B-value')],\n",
              " [('Click', 'O'), ('submit', 'B-value'), ('button', 'I-value')],\n",
              " [('On', 'O'),\n",
              "  ('the', 'O'),\n",
              "  ('Dashboard', 'O'),\n",
              "  ('page', 'O'),\n",
              "  (',', 'O'),\n",
              "  ('click', 'O'),\n",
              "  ('the', 'O'),\n",
              "  ('avatar', 'B-value'),\n",
              "  ('on', 'O'),\n",
              "  ('the', 'O'),\n",
              "  ('top', 'O'),\n",
              "  ('right', 'O'),\n",
              "  ('corner', 'O'),\n",
              "  ('to', 'O'),\n",
              "  ('open', 'O'),\n",
              "  ('menu', 'O')],\n",
              " [('Click', 'O'),\n",
              "  ('button', 'B-value'),\n",
              "  ('Change', 'I-value'),\n",
              "  ('password', 'I-value'),\n",
              "  ('to', 'O'),\n",
              "  ('go', 'O'),\n",
              "  ('to', 'O'),\n",
              "  ('change', 'O'),\n",
              "  ('password', 'O'),\n",
              "  ('page', 'O')],\n",
              " [('Wait', 'O'),\n",
              "  ('title', 'B-value'),\n",
              "  ('to', 'O'),\n",
              "  ('appear', 'O'),\n",
              "  ('for', 'O'),\n",
              "  ('10', 'B-time')],\n",
              " [('Enter', 'O'),\n",
              "  ('current', 'O'),\n",
              "  ('password', 'O'),\n",
              "  ('to', 'O'),\n",
              "  ('current', 'B-location'),\n",
              "  ('password', 'I-location'),\n",
              "  ('text', 'I-location'),\n",
              "  ('box', 'I-location'),\n",
              "  ('Admin@1234', 'B-value')],\n",
              " [('Enter', 'O'),\n",
              "  ('new', 'O'),\n",
              "  ('password', 'O'),\n",
              "  ('new', 'B-location'),\n",
              "  ('password', 'I-location'),\n",
              "  ('text', 'I-location'),\n",
              "  ('box', 'I-location'),\n",
              "  ('Admin@12345', 'B-value')],\n",
              " [('Enter', 'O'),\n",
              "  ('new', 'O'),\n",
              "  ('password', 'O'),\n",
              "  ('again', 'O'),\n",
              "  ('confirm', 'B-location'),\n",
              "  ('password', 'I-location'),\n",
              "  ('textbox', 'I-location'),\n",
              "  ('to', 'O'),\n",
              "  ('confirm', 'O'),\n",
              "  ('password', 'O'),\n",
              "  ('Admin@12345', 'B-value')],\n",
              " [('Click', 'O'), ('submit', 'B-value'), ('button', 'I-value')],\n",
              " [('Click', 'O'),\n",
              "  ('User’s', 'B-value'),\n",
              "  ('avatar', 'I-value'),\n",
              "  ('on', 'O'),\n",
              "  ('the', 'O'),\n",
              "  ('top', 'O'),\n",
              "  ('right', 'O')],\n",
              " [('Click', 'O'),\n",
              "  ('My', 'B-value'),\n",
              "  ('Profile', 'I-value'),\n",
              "  ('link', 'I-value')],\n",
              " [('Wait', 'O'),\n",
              "  ('email', 'B-value'),\n",
              "  ('to', 'O'),\n",
              "  ('appear', 'O'),\n",
              "  ('for', 'O'),\n",
              "  ('20s', 'B-time')],\n",
              " [('Enter', 'O'),\n",
              "  ('new', 'O'),\n",
              "  ('full', 'O'),\n",
              "  ('name', 'O'),\n",
              "  ('to', 'O'),\n",
              "  ('full', 'B-location'),\n",
              "  ('name', 'I-location'),\n",
              "  ('text', 'I-location'),\n",
              "  ('box', 'I-location'),\n",
              "  ('new', 'B-value'),\n",
              "  ('name', 'I-value')],\n",
              " [('Enter', 'O'),\n",
              "  ('new', 'O'),\n",
              "  ('phone', 'O'),\n",
              "  ('number', 'O'),\n",
              "  ('to', 'O'),\n",
              "  ('phone', 'B-location'),\n",
              "  ('number', 'I-location'),\n",
              "  ('text', 'I-location'),\n",
              "  ('box', 'I-location'),\n",
              "  ('1234567890', 'B-value')],\n",
              " [('Click', 'O'), ('submit', 'B-value'), ('button', 'I-value')],\n",
              " [('On', 'O'),\n",
              "  ('the', 'O'),\n",
              "  ('Dashboard', 'O'),\n",
              "  ('page', 'O'),\n",
              "  (',', 'O'),\n",
              "  ('click', 'O'),\n",
              "  ('the', 'O'),\n",
              "  ('avatar', 'B-value'),\n",
              "  ('on', 'O'),\n",
              "  ('the', 'O'),\n",
              "  ('top', 'O'),\n",
              "  ('right', 'O'),\n",
              "  ('corner', 'O'),\n",
              "  ('to', 'O'),\n",
              "  ('open', 'O'),\n",
              "  ('menu', 'O')],\n",
              " [('Click', 'O'),\n",
              "  ('button', 'B-value'),\n",
              "  ('My', 'I-value'),\n",
              "  ('Profile', 'I-value'),\n",
              "  ('to', 'O'),\n",
              "  ('go', 'O'),\n",
              "  ('to', 'O'),\n",
              "  ('Update', 'O'),\n",
              "  ('my', 'O'),\n",
              "  ('Profile', 'O'),\n",
              "  ('page', 'O')],\n",
              " [('Wait', 'O'),\n",
              "  ('for', 'O'),\n",
              "  ('email', 'B-value'),\n",
              "  ('to', 'O'),\n",
              "  ('appear', 'O'),\n",
              "  ('for', 'O'),\n",
              "  ('20', 'B-time')],\n",
              " [('Enter', 'O'),\n",
              "  ('new', 'O'),\n",
              "  ('full', 'O'),\n",
              "  ('name', 'O'),\n",
              "  ('to', 'O'),\n",
              "  ('full', 'B-location'),\n",
              "  ('name', 'I-location'),\n",
              "  ('text', 'I-location'),\n",
              "  ('box', 'I-location')],\n",
              " [('Enter', 'O'),\n",
              "  ('new', 'O'),\n",
              "  ('phone', 'O'),\n",
              "  ('number', 'O'),\n",
              "  ('to', 'O'),\n",
              "  ('phone', 'B-location'),\n",
              "  ('number', 'I-location'),\n",
              "  ('text', 'I-location'),\n",
              "  ('box', 'I-location'),\n",
              "  ('12345678', 'B-value')],\n",
              " [('Click', 'O'), ('submit', 'B-value'), ('button', 'I-value')],\n",
              " [('Verify', 'O'),\n",
              "  ('message', 'O'),\n",
              "  ('You', 'B-value'),\n",
              "  ('have', 'I-value'),\n",
              "  ('no', 'I-value'),\n",
              "  ('libraries', 'I-value'),\n",
              "  ('yet', 'I-value'),\n",
              "  ('shows', 'O'),\n",
              "  ('up', 'O')],\n",
              " [('Verify', 'O'),\n",
              "  ('create', 'B-value'),\n",
              "  ('library', 'I-value'),\n",
              "  ('button', 'I-value'),\n",
              "  ('appears', 'O')],\n",
              " [('Click', 'O'),\n",
              "  ('create', 'B-value'),\n",
              "  ('library', 'I-value'),\n",
              "  ('button', 'I-value')],\n",
              " [('Verify', 'O'),\n",
              "  ('add', 'B-value'),\n",
              "  ('library', 'I-value'),\n",
              "  ('dialog', 'I-value'),\n",
              "  ('shows', 'O'),\n",
              "  ('up', 'O')],\n",
              " [('Input', 'O'),\n",
              "  ('valid', 'O'),\n",
              "  ('value', 'O'),\n",
              "  ('new', 'B-value'),\n",
              "  ('library', 'I-value'),\n",
              "  ('to', 'O'),\n",
              "  ('library', 'B-location'),\n",
              "  ('name', 'I-location'),\n",
              "  ('field', 'I-location'),\n",
              "  ('textbox', 'I-location')],\n",
              " [('Click', 'O'), ('submit', 'B-value'), ('button', 'I-value')],\n",
              " [('Verify', 'O'),\n",
              "  ('element', 'O'),\n",
              "  ('text', 'O'),\n",
              "  ('of', 'O'),\n",
              "  ('empty', 'B-value'),\n",
              "  ('library', 'I-value'),\n",
              "  ('message', 'I-value'),\n",
              "  ('is', 'O')],\n",
              " [('Verify', 'O'),\n",
              "  ('element', 'O'),\n",
              "  ('visible', 'O'),\n",
              "  ('for', 'O'),\n",
              "  ('button', 'B-value'),\n",
              "  ('Create', 'I-value'),\n",
              "  ('Library', 'I-value')],\n",
              " [('Click', 'O'),\n",
              "  ('button', 'O'),\n",
              "  ('Create', 'B-value'),\n",
              "  ('Library', 'I-value')],\n",
              " [('Verify', 'O'),\n",
              "  ('element', 'O'),\n",
              "  ('visible', 'O'),\n",
              "  ('for', 'O'),\n",
              "  ('Add', 'B-value'),\n",
              "  ('Library', 'I-value'),\n",
              "  ('dialog', 'I-value')],\n",
              " [('Set', 'O'),\n",
              "  ('random_placeholder', 'B-value'),\n",
              "  ('in', 'O'),\n",
              "  ('the', 'O'),\n",
              "  ('name', 'B-location'),\n",
              "  ('field', 'I-location'),\n",
              "  ('text', 'I-location')],\n",
              " [('Click', 'O'), ('button', 'O'), ('Submit', 'B-value')],\n",
              " [('Wait', 'O'),\n",
              "  ('for', 'O'),\n",
              "  ('invalid', 'B-value'),\n",
              "  ('message', 'I-value'),\n",
              "  ('text', 'I-value'),\n",
              "  ('to', 'O'),\n",
              "  ('be', 'O'),\n",
              "  ('present', 'O'),\n",
              "  ('for', 'O'),\n",
              "  ('20', 'B-time'),\n",
              "  ('s', 'I-time')],\n",
              " [('Get', 'O'),\n",
              "  ('invalid', 'B-value'),\n",
              "  ('message', 'I-value'),\n",
              "  ('text', 'I-value')],\n",
              " [('Verify', 'O'),\n",
              "  ('that', 'O'),\n",
              "  ('the', 'O'),\n",
              "  ('read', 'O'),\n",
              "  ('invalid', 'O'),\n",
              "  ('message', 'O'),\n",
              "  ('text', 'O'),\n",
              "  ('is', 'O'),\n",
              "  ('This', 'B-value'),\n",
              "  ('field', 'I-value'),\n",
              "  ('is', 'I-value'),\n",
              "  ('required.', 'I-value')],\n",
              " [('Wait', 'O'),\n",
              "  ('for', 'O'),\n",
              "  ('button', 'O'),\n",
              "  ('Add', 'B-value'),\n",
              "  ('Library', 'I-value'),\n",
              "  ('to', 'O'),\n",
              "  ('be', 'O'),\n",
              "  ('present', 'O'),\n",
              "  ('for', 'O'),\n",
              "  ('20', 'B-time'),\n",
              "  ('s', 'I-time')],\n",
              " [('Click', 'O'), ('button', 'O'), ('Add', 'B-value'), ('Library', 'I-value')],\n",
              " [('Verify', 'O'),\n",
              "  ('element', 'O'),\n",
              "  ('visible', 'O'),\n",
              "  ('for', 'O'),\n",
              "  ('Add', 'B-value'),\n",
              "  ('Library', 'I-value'),\n",
              "  ('Dialog', 'I-value')],\n",
              " [('Set', 'O'),\n",
              "  ('name', 'B-value'),\n",
              "  ('field', 'I-value'),\n",
              "  ('text', 'I-value'),\n",
              "  ('as', 'O'),\n",
              "  ('valid', 'O'),\n",
              "  ('name', 'O')],\n",
              " [('Click', 'O'), ('button', 'O'), ('Submit', 'B-value')],\n",
              " [('Wait', 'O'),\n",
              "  ('for', 'O'),\n",
              "  ('success', 'B-value'),\n",
              "  ('message', 'I-value'),\n",
              "  ('text', 'I-value'),\n",
              "  ('to', 'O'),\n",
              "  ('be', 'O'),\n",
              "  ('present', 'O'),\n",
              "  ('for', 'O'),\n",
              "  ('20', 'B-time'),\n",
              "  ('s', 'I-time')],\n",
              " [('Get', 'O'),\n",
              "  ('success', 'B-value'),\n",
              "  ('message', 'I-value'),\n",
              "  ('text', 'I-value')],\n",
              " [('Verify', 'O'),\n",
              "  ('that', 'O'),\n",
              "  ('the', 'O'),\n",
              "  ('success', 'O'),\n",
              "  ('message', 'O'),\n",
              "  ('text', 'O'),\n",
              "  ('is', 'O'),\n",
              "  ('Create', 'B-value'),\n",
              "  ('library', 'I-value'),\n",
              "  ('successfully.', 'I-value')],\n",
              " [('Verify', 'O'),\n",
              "  ('element', 'O'),\n",
              "  ('not', 'O'),\n",
              "  ('present', 'O'),\n",
              "  ('for', 'O'),\n",
              "  ('Add', 'B-value'),\n",
              "  ('Library', 'I-value'),\n",
              "  ('Dialog', 'I-value'),\n",
              "  ('for', 'O'),\n",
              "  ('1', 'O'),\n",
              "  ('s', 'O')],\n",
              " [('Verify', 'O'),\n",
              "  ('element', 'O'),\n",
              "  ('visible', 'O'),\n",
              "  ('for', 'O'),\n",
              "  ('button', 'O'),\n",
              "  ('Add', 'B-value'),\n",
              "  ('Question', 'I-value')],\n",
              " [('Click', 'O'), ('button', 'O'), ('Add', 'B-value'), ('Library', 'I-value')],\n",
              " [('Verify', 'O'),\n",
              "  ('element', 'O'),\n",
              "  ('visible', 'O'),\n",
              "  ('for', 'O'),\n",
              "  ('Add', 'B-value'),\n",
              "  ('Library', 'I-value'),\n",
              "  ('Dialog', 'I-value')],\n",
              " [('Input', 'O'),\n",
              "  ('name', 'B-location'),\n",
              "  ('field', 'I-location'),\n",
              "  ('as', 'O'),\n",
              "  ('invalid', 'O')],\n",
              " [('Click', 'O'), ('button', 'O'), ('Submit', 'B-value')],\n",
              " [('Wait', 'O'),\n",
              "  ('for', 'O'),\n",
              "  ('invalid', 'B-value'),\n",
              "  ('message', 'I-value'),\n",
              "  ('text', 'I-value'),\n",
              "  ('to', 'O'),\n",
              "  ('be', 'O'),\n",
              "  ('present', 'O'),\n",
              "  ('for', 'O'),\n",
              "  ('20', 'B-time'),\n",
              "  ('s', 'I-time')],\n",
              " [('Get', 'O'),\n",
              "  ('invalid', 'B-value'),\n",
              "  ('message', 'I-value'),\n",
              "  ('text', 'I-value')],\n",
              " [('Verify', 'O'),\n",
              "  ('that', 'O'),\n",
              "  ('the', 'O'),\n",
              "  ('invalid', 'O'),\n",
              "  ('message', 'O'),\n",
              "  ('text', 'O'),\n",
              "  ('is', 'O'),\n",
              "  ('This', 'B-value'),\n",
              "  ('field', 'I-value'),\n",
              "  ('is', 'I-value'),\n",
              "  ('required.', 'I-value')],\n",
              " [('Click', 'O'), ('button', 'O'), ('Cancel', 'B-value')],\n",
              " [('Click', 'O'),\n",
              "  ('library', 'B-value'),\n",
              "  ('navigation', 'I-value'),\n",
              "  ('item', 'I-value')],\n",
              " [('Verify', 'O'),\n",
              "  ('the', 'O'),\n",
              "  ('add', 'B-value'),\n",
              "  ('question', 'I-value'),\n",
              "  ('button', 'I-value'),\n",
              "  ('appears', 'O')],\n",
              " [('Verify', 'O'),\n",
              "  ('Multiple', 'B-value'),\n",
              "  ('Choice', 'I-value'),\n",
              "  ('question', 'I-value'),\n",
              "  ('shows', 'O'),\n",
              "  ('up', 'O')],\n",
              " [('Verify', 'O'),\n",
              "  ('Subjective', 'B-value'),\n",
              "  ('question', 'I-value'),\n",
              "  ('shows', 'O'),\n",
              "  ('up', 'O')],\n",
              " [('Verify', 'O'),\n",
              "  ('Programming', 'B-value'),\n",
              "  ('question', 'I-value'),\n",
              "  ('shows', 'O'),\n",
              "  ('up', 'O')],\n",
              " [('Verify', 'O'),\n",
              "  ('File', 'B-value'),\n",
              "  ('Upload', 'I-value'),\n",
              "  ('question', 'I-value'),\n",
              "  ('shows', 'O'),\n",
              "  ('up', 'O')],\n",
              " [('Click', 'O'),\n",
              "  ('library', 'B-value'),\n",
              "  ('navigation', 'I-value'),\n",
              "  ('item', 'I-value')],\n",
              " [('Click', 'O'),\n",
              "  ('library', 'B-value'),\n",
              "  ('name', 'I-value'),\n",
              "  ('with', 'I-value'),\n",
              "  ('rely', 'I-value'),\n",
              "  ('on', 'I-value'),\n",
              "  ('name', 'I-value'),\n",
              "  ('with', 'I-value'),\n",
              "  ('test', 'I-value'),\n",
              "  ('library', 'I-value'),\n",
              "  ('name', 'I-value')],\n",
              " [('Click', 'O'),\n",
              "  ('update', 'B-value'),\n",
              "  ('option', 'I-value'),\n",
              "  ('with', 'I-value'),\n",
              "  ('rely', 'I-value'),\n",
              "  ('on', 'I-value'),\n",
              "  ('name', 'I-value'),\n",
              "  ('with', 'I-value'),\n",
              "  ('test', 'I-value'),\n",
              "  ('library', 'I-value'),\n",
              "  ('name', 'I-value')],\n",
              " [('Verify', 'O'),\n",
              "  ('update', 'B-value'),\n",
              "  ('library', 'I-value'),\n",
              "  ('dialog', 'I-value'),\n",
              "  ('shows', 'O'),\n",
              "  ('up', 'O'),\n",
              "  ('for', 'O'),\n",
              "  ('30', 'B-time'),\n",
              "  ('seconds', 'O')],\n",
              " [('Input', 'O'),\n",
              "  ('update', 'B-value'),\n",
              "  ('library', 'I-value'),\n",
              "  ('name', 'I-value'),\n",
              "  ('to', 'O'),\n",
              "  ('library', 'B-location'),\n",
              "  ('name', 'I-location'),\n",
              "  ('textbox', 'I-location')]]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#To inspect our data, it corresponds to our defined columns\n",
        "sents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuMZF3crH-i1",
        "outputId": "df6e788a-3379-45a6-e431-fa5c1a9be509"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done\n"
          ]
        }
      ],
      "source": [
        "#It only supports txt file, so we need to convert our processed data into txt file\n",
        "with open(data_folder+ \"/train.txt\", \"w\") as file:\n",
        "  for sent in sents:\n",
        "    file.write(\"\\n\")\n",
        "    for item in sent:\n",
        "      file.write(\"\\n\" + \" \".join(item))\n",
        "  print(\"Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZ02FhusEhp0",
        "outputId": "75c79d45-5916-4600-e3aa-f53bd18360ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-06-17 00:13:46,091 Reading data from /content/drive/MyDrive/Colab Notebooks/data\n",
            "2022-06-17 00:13:46,096 Train: /content/drive/MyDrive/Colab Notebooks/data/train.txt\n",
            "2022-06-17 00:13:46,098 Dev: None\n",
            "2022-06-17 00:13:46,101 Test: None\n"
          ]
        }
      ],
      "source": [
        "#To build the corpus, specify the file path, columns we defined above, load the training file in txt format\n",
        "corpus: Corpus = ColumnCorpus(data_folder, columns, train_file = 'train.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B67QcaIPFSAN",
        "outputId": "07cf7597-e8c5-4789-ce16-8570e1d7603a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "70\n"
          ]
        }
      ],
      "source": [
        "#There are 70 training sentences, it will treat the duplicates as one\n",
        "print(len(corpus.train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zwuxPKmKFVyq",
        "outputId": "50182215-e9c7-4a9b-a77e-9973f2d7113e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Sentence: \"Enter email address to Email textbox admin1@mail.com\" → [\"Email textbox\"/location, \"admin1@mail.com\"/value]'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#To inspect the first sentence from training\n",
        "corpus.train[0].to_tagged_string('ner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5xX7AALKItc",
        "outputId": "3bc5d257-df57-4297-a0ae-fcc638d6a804"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: \"Input update library name to library name textbox\" → [\"update library name\"/value, \"library name textbox\"/location]\n"
          ]
        }
      ],
      "source": [
        "#To inspect the last sentence from training\n",
        "print(corpus.train[-1].to_tagged_string('ner'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nZnvf-uJD7F"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "rI1Jwj4wJFCn"
      },
      "outputs": [],
      "source": [
        "#specify the labeling type as named entity recognition\n",
        "label_type = \"ner\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKTcgiRHJI7Y",
        "outputId": "09afd174-ecd6-427d-f396-bfccacb820cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-06-17 00:13:46,185 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "70it [00:00, 21230.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-06-17 00:13:46,199 Dictionary created for label 'ner' with 4 values: value (seen 67 times), location (seen 15 times), time (seen 10 times)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#build named entity recognition dictionaries\n",
        "tag_dictionary = corpus.make_label_dictionary(label_type=label_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThYT_Dr9TIz5",
        "outputId": "ca5b5d57-664f-4886-d33e-66c11f51a355"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dictionary with 4 tags: <unk>, value, location, time\n"
          ]
        }
      ],
      "source": [
        "#There are four tags of our interest\n",
        "print(tag_dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Dwrzhj9ISvVa"
      },
      "outputs": [],
      "source": [
        "from flair.embeddings import TransformerWordEmbeddings\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer\n",
        "#load the embeddings, models and trainer from Flair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "d22a752e5ef146b7af184267986ded06",
            "8451b60eb99c401aa85fcb46c737fb0d",
            "4da03010fb6f4116b2b05c835835f4da",
            "f543edb9673e47c78271a037cbd554dd",
            "be6cf05acb2f4cca96d9e3e3f51682dc",
            "c93ec3228fae4458868098f4905ea13a",
            "5cf55188ebc549b8a9699d1b09670ff3",
            "984f383d4d4f46688e536635d3aef559",
            "4e15f98fbd40496680f68243df2c8312",
            "21ad1609d1e84e2991c0872d21302211",
            "a0be565d90a84c909ea2241ae70aa3d4",
            "e03ee3fd506e4f90826f272c298590a4",
            "0f8a626f3fa94a7fa4cb257e965c5863",
            "2464d79d4ff44e4bb8352ebdd9ce6d2b",
            "ad7dc3f26fa343b18cbee3070bc28ce7",
            "690ef6034ac14d41802b26a4c928025b",
            "b6bd178ab1ef4480adfca55a3d0b8e88",
            "20b769d011eb447080bd90bc373b6deb",
            "fdc2f872d9254f7298d79af4614e7627",
            "cba15c49e89149ed9de8f4bd40a6698e",
            "55f79b6251494023bf4c36a6a38e4e08",
            "0faf8b84b2764ba28b5789e5c9102670",
            "def12bfc548f4f8e9d338d6949bb57fa",
            "d7e777c6e0244d469d8fe73780ee7614",
            "4e6704c6b83e4300a8a72e276542b072",
            "755d0a19e54044c0b29d4ff5fe79be20",
            "a738ec6a28034e1db872297c9ca1ad8b",
            "35293f9414c844659488474cac468b87",
            "2aca863784cc4db48be6cf18ad3c2942",
            "dfdec0f039454ba6bbdf57f381221234",
            "b6de886d26934007ace4f7529b5d5b05",
            "9635d2378c15480bb0b47891c031e2e6",
            "30f2156b6d0845158a37f38ed9d4854c",
            "8180beee4609430696e9e73ce1b8be8f",
            "b8046e01636949408734e0c11bb09331",
            "78c1f36532f648669a0c440ebd019f11",
            "6d84aefd5c394a1ba14b71952ac1ccd9",
            "571775fba4bf458e8b7c8ee8647c4b45",
            "cbea62b7f9ad46b1b41cea2a9f8d9862",
            "1f281277d9db42348870be3a7e193ec6",
            "3618de10e66d4d36a2d722264a43fb2e",
            "626b091c15eb45f09ff768bc1dc12549",
            "00eceaf352ca44409aa3f7b1f5a9679c",
            "b3d08217411247998945b55ff053c9bb"
          ]
        },
        "id": "GrGCsSu_TQfx",
        "outputId": "45841221-cb1c-4400-8557-d7b19f59a720"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d22a752e5ef146b7af184267986ded06",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/616 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e03ee3fd506e4f90826f272c298590a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "def12bfc548f4f8e9d338d6949bb57fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/8.68M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8180beee4609430696e9e73ce1b8be8f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.09G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#use transformer to embed the words by using xlm-roberta-large\n",
        "#for details of this roberta, refer to https://huggingface.co/xlm-roberta-large\n",
        "#check the documentation https://github.com/flairNLP/flair/blob/master/resources/docs/embeddings/TRANSFORMER_EMBEDDINGS.md\n",
        "#layer means the layers of the transformer-based model that produce embeddings\n",
        "#fine-tune means whehter or not embeddings are fine-tunable\n",
        "#use-context Set to True to include context outside of sentences. \n",
        "#This can greatly increase accuracy on some tasks, \n",
        "# but slows down embedding generation\n",
        "embeddings = TransformerWordEmbeddings(model='xlm-roberta-large',\n",
        "                                       layers=\"-1\",\n",
        "                                       subtoken_pooling=\"first\",\n",
        "                                       fine_tune=True,\n",
        "                                       use_context=True,\n",
        "                                       )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGmxaT9qTWDz",
        "outputId": "dd2933d2-11e1-4725-cfa5-26877c8d3a74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-06-17 00:15:16,565 SequenceTagger predicts: Dictionary with 13 tags: O, S-value, B-value, E-value, I-value, S-location, B-location, E-location, I-location, S-time, B-time, E-time, I-time\n"
          ]
        }
      ],
      "source": [
        "#for more information of the tagger, check https://github.com/flairNLP/flair/blob/master/flair/models/sequence_tagger_model.py\n",
        "#hidden_size:  hidden size of RNN layer\n",
        "#embeddings: embeddings to use during training and prediction\n",
        "#tag_dictionary: Dictionary containing all tags from corpus which can be predicted\n",
        "#tag_type: type of tag which is going to be predicted in case a corpus has multiple annotations\n",
        "#use_crf: If True, use a Conditional Random Field for prediction, else linear map to tag space.\n",
        "#project_embeddings: If True, add a linear layer on top of embeddings, if you want to imitate\n",
        "#fine tune non-trainable embeddings.\n",
        "#use_rnn: If true, use a RNN, else Linear layer.\n",
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                        embeddings=embeddings,\n",
        "                        tag_dictionary=tag_dictionary,\n",
        "                        tag_type=label_type,\n",
        "                        use_crf=False,\n",
        "                        use_rnn=False,\n",
        "                        reproject_embeddings=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "GpikiU2yTYDk"
      },
      "outputs": [],
      "source": [
        "#training\n",
        "trainer = ModelTrainer(tagger, corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35B5on1BTfoB",
        "outputId": "2b57c78f-afd4-4d87-93a5-5e78f539d5cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-06-17 00:15:16,604 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:15:16,609 Model: \"SequenceTagger(\n",
            "  (embeddings): TransformerWordEmbeddings(\n",
            "    (model): XLMRobertaModel(\n",
            "      (embeddings): RobertaEmbeddings(\n",
            "        (word_embeddings): Embedding(250002, 1024, padding_idx=1)\n",
            "        (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
            "        (token_type_embeddings): Embedding(1, 1024)\n",
            "        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): RobertaEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (12): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (13): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (14): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (15): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (16): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (17): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (18): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (19): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (20): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (21): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (22): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (23): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): RobertaPooler(\n",
            "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (linear): Linear(in_features=1024, out_features=13, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            ")\"\n",
            "2022-06-17 00:15:16,610 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:15:16,612 Corpus: \"Corpus: 70 train + 8 dev + 9 test sentences\"\n",
            "2022-06-17 00:15:16,614 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:15:16,625 Parameters:\n",
            "2022-06-17 00:15:16,626  - learning_rate: \"0.000005\"\n",
            "2022-06-17 00:15:16,628  - mini_batch_size: \"1\"\n",
            "2022-06-17 00:15:16,630  - patience: \"3\"\n",
            "2022-06-17 00:15:16,634  - anneal_factor: \"0.5\"\n",
            "2022-06-17 00:15:16,636  - max_epochs: \"50\"\n",
            "2022-06-17 00:15:16,638  - shuffle: \"True\"\n",
            "2022-06-17 00:15:16,639  - train_with_dev: \"True\"\n",
            "2022-06-17 00:15:16,642  - batch_growth_annealing: \"False\"\n",
            "2022-06-17 00:15:16,643 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:15:16,649 Model training base path: \"resources/taggers/sota-ner-flair\"\n",
            "2022-06-17 00:15:16,650 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:15:16,651 Device: cuda:0\n",
            "2022-06-17 00:15:16,652 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:15:16,654 Embeddings storage mode: none\n",
            "2022-06-17 00:15:16,655 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:15:19,576 epoch 1 - iter 7/78 - loss 2.53584405 - samples/sec: 2.40 - lr: 0.000000\n",
            "2022-06-17 00:15:22,064 epoch 1 - iter 14/78 - loss 2.58644118 - samples/sec: 2.82 - lr: 0.000000\n",
            "2022-06-17 00:15:24,553 epoch 1 - iter 21/78 - loss 2.59799150 - samples/sec: 2.82 - lr: 0.000000\n",
            "2022-06-17 00:15:27,004 epoch 1 - iter 28/78 - loss 2.69245889 - samples/sec: 2.86 - lr: 0.000000\n",
            "2022-06-17 00:15:29,417 epoch 1 - iter 35/78 - loss 2.72824719 - samples/sec: 2.90 - lr: 0.000000\n",
            "2022-06-17 00:15:31,863 epoch 1 - iter 42/78 - loss 2.73558662 - samples/sec: 2.86 - lr: 0.000001\n",
            "2022-06-17 00:15:34,361 epoch 1 - iter 49/78 - loss 2.70767915 - samples/sec: 2.80 - lr: 0.000001\n",
            "2022-06-17 00:15:36,817 epoch 1 - iter 56/78 - loss 2.67860372 - samples/sec: 2.85 - lr: 0.000001\n",
            "2022-06-17 00:15:39,330 epoch 1 - iter 63/78 - loss 2.69070969 - samples/sec: 2.79 - lr: 0.000001\n",
            "2022-06-17 00:15:41,781 epoch 1 - iter 70/78 - loss 2.74723138 - samples/sec: 2.86 - lr: 0.000001\n",
            "2022-06-17 00:15:44,229 epoch 1 - iter 77/78 - loss 2.71811839 - samples/sec: 2.86 - lr: 0.000001\n",
            "2022-06-17 00:15:44,570 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:15:44,571 EPOCH 1 done: loss 2.7226 - lr 0.000001\n",
            "2022-06-17 00:15:44,575 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:15:44,579 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:15:47,055 epoch 2 - iter 7/78 - loss 2.17609909 - samples/sec: 2.84 - lr: 0.000001\n",
            "2022-06-17 00:15:49,569 epoch 2 - iter 14/78 - loss 2.32473648 - samples/sec: 2.79 - lr: 0.000001\n",
            "2022-06-17 00:15:52,073 epoch 2 - iter 21/78 - loss 2.39818253 - samples/sec: 2.80 - lr: 0.000001\n",
            "2022-06-17 00:15:54,632 epoch 2 - iter 28/78 - loss 2.39706034 - samples/sec: 2.74 - lr: 0.000001\n",
            "2022-06-17 00:15:57,140 epoch 2 - iter 35/78 - loss 2.39509231 - samples/sec: 2.79 - lr: 0.000001\n",
            "2022-06-17 00:15:59,762 epoch 2 - iter 42/78 - loss 2.46715827 - samples/sec: 2.67 - lr: 0.000002\n",
            "2022-06-17 00:16:02,322 epoch 2 - iter 49/78 - loss 2.44456836 - samples/sec: 2.74 - lr: 0.000002\n",
            "2022-06-17 00:16:04,881 epoch 2 - iter 56/78 - loss 2.45776722 - samples/sec: 2.74 - lr: 0.000002\n",
            "2022-06-17 00:16:07,394 epoch 2 - iter 63/78 - loss 2.45326355 - samples/sec: 2.79 - lr: 0.000002\n",
            "2022-06-17 00:16:09,859 epoch 2 - iter 70/78 - loss 2.43710700 - samples/sec: 2.84 - lr: 0.000002\n",
            "2022-06-17 00:16:12,428 epoch 2 - iter 77/78 - loss 2.46942072 - samples/sec: 2.73 - lr: 0.000002\n",
            "2022-06-17 00:16:12,797 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:16:12,802 EPOCH 2 done: loss 2.4710 - lr 0.000002\n",
            "2022-06-17 00:16:12,804 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:16:12,807 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:16:15,363 epoch 3 - iter 7/78 - loss 2.20403373 - samples/sec: 2.75 - lr: 0.000002\n",
            "2022-06-17 00:16:18,004 epoch 3 - iter 14/78 - loss 2.27931130 - samples/sec: 2.66 - lr: 0.000002\n",
            "2022-06-17 00:16:20,593 epoch 3 - iter 21/78 - loss 2.19118057 - samples/sec: 2.71 - lr: 0.000002\n",
            "2022-06-17 00:16:23,162 epoch 3 - iter 28/78 - loss 2.12260764 - samples/sec: 2.73 - lr: 0.000002\n",
            "2022-06-17 00:16:25,625 epoch 3 - iter 35/78 - loss 2.22469466 - samples/sec: 2.84 - lr: 0.000002\n",
            "2022-06-17 00:16:28,158 epoch 3 - iter 42/78 - loss 2.17618556 - samples/sec: 2.77 - lr: 0.000003\n",
            "2022-06-17 00:16:30,606 epoch 3 - iter 49/78 - loss 2.16018990 - samples/sec: 2.86 - lr: 0.000003\n",
            "2022-06-17 00:16:33,108 epoch 3 - iter 56/78 - loss 2.19145344 - samples/sec: 2.80 - lr: 0.000003\n",
            "2022-06-17 00:16:35,637 epoch 3 - iter 63/78 - loss 2.18747313 - samples/sec: 2.77 - lr: 0.000003\n",
            "2022-06-17 00:16:38,270 epoch 3 - iter 70/78 - loss 2.15067684 - samples/sec: 2.66 - lr: 0.000003\n",
            "2022-06-17 00:16:40,633 epoch 3 - iter 77/78 - loss 2.14033831 - samples/sec: 2.97 - lr: 0.000003\n",
            "2022-06-17 00:16:40,969 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:16:40,970 EPOCH 3 done: loss 2.1365 - lr 0.000003\n",
            "2022-06-17 00:16:40,975 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:16:40,979 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:16:43,525 epoch 4 - iter 7/78 - loss 1.54649686 - samples/sec: 2.76 - lr: 0.000003\n",
            "2022-06-17 00:16:46,137 epoch 4 - iter 14/78 - loss 1.69593243 - samples/sec: 2.68 - lr: 0.000003\n",
            "2022-06-17 00:16:48,844 epoch 4 - iter 21/78 - loss 1.80788947 - samples/sec: 2.59 - lr: 0.000003\n",
            "2022-06-17 00:16:51,493 epoch 4 - iter 28/78 - loss 1.64029562 - samples/sec: 2.64 - lr: 0.000003\n",
            "2022-06-17 00:16:54,026 epoch 4 - iter 35/78 - loss 1.71538450 - samples/sec: 2.77 - lr: 0.000003\n",
            "2022-06-17 00:16:56,472 epoch 4 - iter 42/78 - loss 1.81167570 - samples/sec: 2.86 - lr: 0.000004\n",
            "2022-06-17 00:16:58,943 epoch 4 - iter 49/78 - loss 1.81548904 - samples/sec: 2.84 - lr: 0.000004\n",
            "2022-06-17 00:17:01,401 epoch 4 - iter 56/78 - loss 1.80928353 - samples/sec: 2.85 - lr: 0.000004\n",
            "2022-06-17 00:17:03,855 epoch 4 - iter 63/78 - loss 1.82898684 - samples/sec: 2.85 - lr: 0.000004\n",
            "2022-06-17 00:17:06,410 epoch 4 - iter 70/78 - loss 1.83086813 - samples/sec: 2.74 - lr: 0.000004\n",
            "2022-06-17 00:17:08,884 epoch 4 - iter 77/78 - loss 1.83827835 - samples/sec: 2.83 - lr: 0.000004\n",
            "2022-06-17 00:17:09,224 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:17:09,226 EPOCH 4 done: loss 1.8482 - lr 0.000004\n",
            "2022-06-17 00:17:09,234 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:17:09,236 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:17:11,923 epoch 5 - iter 7/78 - loss 2.00307508 - samples/sec: 2.61 - lr: 0.000004\n",
            "2022-06-17 00:17:14,504 epoch 5 - iter 14/78 - loss 1.96048475 - samples/sec: 2.72 - lr: 0.000004\n",
            "2022-06-17 00:17:17,009 epoch 5 - iter 21/78 - loss 1.88658514 - samples/sec: 2.80 - lr: 0.000004\n",
            "2022-06-17 00:17:19,493 epoch 5 - iter 28/78 - loss 1.79985975 - samples/sec: 2.82 - lr: 0.000004\n",
            "2022-06-17 00:17:22,008 epoch 5 - iter 35/78 - loss 1.80770780 - samples/sec: 2.79 - lr: 0.000004\n",
            "2022-06-17 00:17:24,568 epoch 5 - iter 42/78 - loss 1.78169902 - samples/sec: 2.74 - lr: 0.000005\n",
            "2022-06-17 00:17:27,024 epoch 5 - iter 49/78 - loss 1.73200574 - samples/sec: 2.85 - lr: 0.000005\n",
            "2022-06-17 00:17:29,566 epoch 5 - iter 56/78 - loss 1.71402911 - samples/sec: 2.76 - lr: 0.000005\n",
            "2022-06-17 00:17:32,186 epoch 5 - iter 63/78 - loss 1.64475897 - samples/sec: 2.67 - lr: 0.000005\n",
            "2022-06-17 00:17:34,736 epoch 5 - iter 70/78 - loss 1.64256378 - samples/sec: 2.75 - lr: 0.000005\n",
            "2022-06-17 00:17:37,183 epoch 5 - iter 77/78 - loss 1.64131462 - samples/sec: 2.86 - lr: 0.000005\n",
            "2022-06-17 00:17:37,531 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:17:37,532 EPOCH 5 done: loss 1.6379 - lr 0.000005\n",
            "2022-06-17 00:17:37,537 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:17:37,540 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:17:39,963 epoch 6 - iter 7/78 - loss 1.80255557 - samples/sec: 2.90 - lr: 0.000005\n",
            "2022-06-17 00:17:42,463 epoch 6 - iter 14/78 - loss 1.73890611 - samples/sec: 2.80 - lr: 0.000005\n",
            "2022-06-17 00:17:44,828 epoch 6 - iter 21/78 - loss 1.70092761 - samples/sec: 2.96 - lr: 0.000005\n",
            "2022-06-17 00:17:47,366 epoch 6 - iter 28/78 - loss 1.66710056 - samples/sec: 2.76 - lr: 0.000005\n",
            "2022-06-17 00:17:49,874 epoch 6 - iter 35/78 - loss 1.63321755 - samples/sec: 2.79 - lr: 0.000005\n",
            "2022-06-17 00:17:52,384 epoch 6 - iter 42/78 - loss 1.59774344 - samples/sec: 2.79 - lr: 0.000005\n",
            "2022-06-17 00:17:54,983 epoch 6 - iter 49/78 - loss 1.60876258 - samples/sec: 2.69 - lr: 0.000005\n",
            "2022-06-17 00:17:57,452 epoch 6 - iter 56/78 - loss 1.56731275 - samples/sec: 2.84 - lr: 0.000005\n",
            "2022-06-17 00:17:59,930 epoch 6 - iter 63/78 - loss 1.57284972 - samples/sec: 2.83 - lr: 0.000005\n",
            "2022-06-17 00:18:02,459 epoch 6 - iter 70/78 - loss 1.56944281 - samples/sec: 2.77 - lr: 0.000005\n",
            "2022-06-17 00:18:04,997 epoch 6 - iter 77/78 - loss 1.51792261 - samples/sec: 2.76 - lr: 0.000005\n",
            "2022-06-17 00:18:05,332 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:18:05,334 EPOCH 6 done: loss 1.5181 - lr 0.000005\n",
            "2022-06-17 00:18:05,338 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:18:05,342 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:18:07,889 epoch 7 - iter 7/78 - loss 1.60448713 - samples/sec: 2.76 - lr: 0.000005\n",
            "2022-06-17 00:18:10,331 epoch 7 - iter 14/78 - loss 1.43105858 - samples/sec: 2.87 - lr: 0.000005\n",
            "2022-06-17 00:18:12,923 epoch 7 - iter 21/78 - loss 1.37154312 - samples/sec: 2.70 - lr: 0.000005\n",
            "2022-06-17 00:18:15,336 epoch 7 - iter 28/78 - loss 1.33680385 - samples/sec: 2.90 - lr: 0.000005\n",
            "2022-06-17 00:18:17,901 epoch 7 - iter 35/78 - loss 1.29268503 - samples/sec: 2.73 - lr: 0.000005\n",
            "2022-06-17 00:18:20,424 epoch 7 - iter 42/78 - loss 1.33597287 - samples/sec: 2.78 - lr: 0.000005\n",
            "2022-06-17 00:18:22,863 epoch 7 - iter 49/78 - loss 1.34377147 - samples/sec: 2.87 - lr: 0.000005\n",
            "2022-06-17 00:18:25,507 epoch 7 - iter 56/78 - loss 1.34095452 - samples/sec: 2.65 - lr: 0.000005\n",
            "2022-06-17 00:18:27,899 epoch 7 - iter 63/78 - loss 1.36688794 - samples/sec: 2.93 - lr: 0.000005\n",
            "2022-06-17 00:18:30,492 epoch 7 - iter 70/78 - loss 1.36673884 - samples/sec: 2.70 - lr: 0.000005\n",
            "2022-06-17 00:18:33,015 epoch 7 - iter 77/78 - loss 1.35121345 - samples/sec: 2.78 - lr: 0.000005\n",
            "2022-06-17 00:18:33,407 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:18:33,409 EPOCH 7 done: loss 1.3374 - lr 0.000005\n",
            "2022-06-17 00:18:33,414 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:18:33,416 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:18:35,935 epoch 8 - iter 7/78 - loss 1.16470654 - samples/sec: 2.79 - lr: 0.000005\n",
            "2022-06-17 00:18:38,378 epoch 8 - iter 14/78 - loss 1.17478899 - samples/sec: 2.87 - lr: 0.000005\n",
            "2022-06-17 00:18:40,909 epoch 8 - iter 21/78 - loss 1.18018174 - samples/sec: 2.77 - lr: 0.000005\n",
            "2022-06-17 00:18:43,541 epoch 8 - iter 28/78 - loss 1.22115607 - samples/sec: 2.66 - lr: 0.000005\n",
            "2022-06-17 00:18:45,983 epoch 8 - iter 35/78 - loss 1.20869575 - samples/sec: 2.87 - lr: 0.000005\n",
            "2022-06-17 00:18:48,593 epoch 8 - iter 42/78 - loss 1.16159204 - samples/sec: 2.68 - lr: 0.000005\n",
            "2022-06-17 00:18:51,137 epoch 8 - iter 49/78 - loss 1.17483378 - samples/sec: 2.76 - lr: 0.000005\n",
            "2022-06-17 00:18:53,640 epoch 8 - iter 56/78 - loss 1.20428138 - samples/sec: 2.80 - lr: 0.000005\n",
            "2022-06-17 00:18:56,266 epoch 8 - iter 63/78 - loss 1.19721274 - samples/sec: 2.67 - lr: 0.000005\n",
            "2022-06-17 00:18:58,743 epoch 8 - iter 70/78 - loss 1.14203768 - samples/sec: 2.83 - lr: 0.000005\n",
            "2022-06-17 00:19:01,239 epoch 8 - iter 77/78 - loss 1.16109369 - samples/sec: 2.81 - lr: 0.000005\n",
            "2022-06-17 00:19:01,641 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:19:01,644 EPOCH 8 done: loss 1.1500 - lr 0.000005\n",
            "2022-06-17 00:19:01,648 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:19:01,651 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:19:04,191 epoch 9 - iter 7/78 - loss 1.03609186 - samples/sec: 2.76 - lr: 0.000005\n",
            "2022-06-17 00:19:06,805 epoch 9 - iter 14/78 - loss 1.19529179 - samples/sec: 2.68 - lr: 0.000005\n",
            "2022-06-17 00:19:09,352 epoch 9 - iter 21/78 - loss 1.12078852 - samples/sec: 2.75 - lr: 0.000005\n",
            "2022-06-17 00:19:11,990 epoch 9 - iter 28/78 - loss 1.08719854 - samples/sec: 2.66 - lr: 0.000005\n",
            "2022-06-17 00:19:14,458 epoch 9 - iter 35/78 - loss 1.13196876 - samples/sec: 2.84 - lr: 0.000005\n",
            "2022-06-17 00:19:17,000 epoch 9 - iter 42/78 - loss 1.06638408 - samples/sec: 2.76 - lr: 0.000005\n",
            "2022-06-17 00:19:19,470 epoch 9 - iter 49/78 - loss 1.02274217 - samples/sec: 2.84 - lr: 0.000005\n",
            "2022-06-17 00:19:21,981 epoch 9 - iter 56/78 - loss 1.04121226 - samples/sec: 2.79 - lr: 0.000005\n",
            "2022-06-17 00:19:24,668 epoch 9 - iter 63/78 - loss 0.99929255 - samples/sec: 2.61 - lr: 0.000005\n",
            "2022-06-17 00:19:27,273 epoch 9 - iter 70/78 - loss 0.98517779 - samples/sec: 2.69 - lr: 0.000005\n",
            "2022-06-17 00:19:29,790 epoch 9 - iter 77/78 - loss 0.99334132 - samples/sec: 2.78 - lr: 0.000005\n",
            "2022-06-17 00:19:30,130 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:19:30,132 EPOCH 9 done: loss 1.0002 - lr 0.000005\n",
            "2022-06-17 00:19:30,136 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:19:30,138 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:19:32,608 epoch 10 - iter 7/78 - loss 1.02193009 - samples/sec: 2.85 - lr: 0.000005\n",
            "2022-06-17 00:19:35,071 epoch 10 - iter 14/78 - loss 0.83192700 - samples/sec: 2.84 - lr: 0.000005\n",
            "2022-06-17 00:19:37,674 epoch 10 - iter 21/78 - loss 0.79286167 - samples/sec: 2.69 - lr: 0.000005\n",
            "2022-06-17 00:19:40,178 epoch 10 - iter 28/78 - loss 0.88265407 - samples/sec: 2.80 - lr: 0.000005\n",
            "2022-06-17 00:19:42,765 epoch 10 - iter 35/78 - loss 0.84716256 - samples/sec: 2.71 - lr: 0.000005\n",
            "2022-06-17 00:19:45,396 epoch 10 - iter 42/78 - loss 0.81171567 - samples/sec: 2.66 - lr: 0.000004\n",
            "2022-06-17 00:19:48,017 epoch 10 - iter 49/78 - loss 0.81204961 - samples/sec: 2.67 - lr: 0.000004\n",
            "2022-06-17 00:19:50,624 epoch 10 - iter 56/78 - loss 0.75864750 - samples/sec: 2.69 - lr: 0.000004\n",
            "2022-06-17 00:19:53,190 epoch 10 - iter 63/78 - loss 0.73609049 - samples/sec: 2.73 - lr: 0.000004\n",
            "2022-06-17 00:19:55,723 epoch 10 - iter 70/78 - loss 0.73278224 - samples/sec: 2.77 - lr: 0.000004\n",
            "2022-06-17 00:19:58,364 epoch 10 - iter 77/78 - loss 0.74868849 - samples/sec: 2.65 - lr: 0.000004\n",
            "2022-06-17 00:19:58,753 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:19:58,755 EPOCH 10 done: loss 0.7411 - lr 0.000004\n",
            "2022-06-17 00:19:58,760 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:19:58,767 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:20:01,402 epoch 11 - iter 7/78 - loss 0.67332613 - samples/sec: 2.66 - lr: 0.000004\n",
            "2022-06-17 00:20:03,997 epoch 11 - iter 14/78 - loss 0.69417578 - samples/sec: 2.70 - lr: 0.000004\n",
            "2022-06-17 00:20:06,560 epoch 11 - iter 21/78 - loss 0.75392505 - samples/sec: 2.73 - lr: 0.000004\n",
            "2022-06-17 00:20:09,054 epoch 11 - iter 28/78 - loss 0.69951301 - samples/sec: 2.81 - lr: 0.000004\n",
            "2022-06-17 00:20:11,613 epoch 11 - iter 35/78 - loss 0.68020788 - samples/sec: 2.74 - lr: 0.000004\n",
            "2022-06-17 00:20:14,034 epoch 11 - iter 42/78 - loss 0.62953514 - samples/sec: 2.89 - lr: 0.000004\n",
            "2022-06-17 00:20:16,624 epoch 11 - iter 49/78 - loss 0.60113100 - samples/sec: 2.70 - lr: 0.000004\n",
            "2022-06-17 00:20:19,036 epoch 11 - iter 56/78 - loss 0.61456118 - samples/sec: 2.91 - lr: 0.000004\n",
            "2022-06-17 00:20:21,564 epoch 11 - iter 63/78 - loss 0.60677080 - samples/sec: 2.77 - lr: 0.000004\n",
            "2022-06-17 00:20:24,137 epoch 11 - iter 70/78 - loss 0.64851749 - samples/sec: 2.72 - lr: 0.000004\n",
            "2022-06-17 00:20:26,835 epoch 11 - iter 77/78 - loss 0.63914259 - samples/sec: 2.60 - lr: 0.000004\n",
            "2022-06-17 00:20:27,211 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:20:27,213 EPOCH 11 done: loss 0.6574 - lr 0.000004\n",
            "2022-06-17 00:20:27,221 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:20:27,223 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:20:29,651 epoch 12 - iter 7/78 - loss 0.51884747 - samples/sec: 2.89 - lr: 0.000004\n",
            "2022-06-17 00:20:32,231 epoch 12 - iter 14/78 - loss 0.61119953 - samples/sec: 2.72 - lr: 0.000004\n",
            "2022-06-17 00:20:34,682 epoch 12 - iter 21/78 - loss 0.66353765 - samples/sec: 2.86 - lr: 0.000004\n",
            "2022-06-17 00:20:37,158 epoch 12 - iter 28/78 - loss 0.70503136 - samples/sec: 2.83 - lr: 0.000004\n",
            "2022-06-17 00:20:39,634 epoch 12 - iter 35/78 - loss 0.67644485 - samples/sec: 2.83 - lr: 0.000004\n",
            "2022-06-17 00:20:42,113 epoch 12 - iter 42/78 - loss 0.67333906 - samples/sec: 2.83 - lr: 0.000004\n",
            "2022-06-17 00:20:44,619 epoch 12 - iter 49/78 - loss 0.63454593 - samples/sec: 2.80 - lr: 0.000004\n",
            "2022-06-17 00:20:47,222 epoch 12 - iter 56/78 - loss 0.60424086 - samples/sec: 2.69 - lr: 0.000004\n",
            "2022-06-17 00:20:49,698 epoch 12 - iter 63/78 - loss 0.59687375 - samples/sec: 2.83 - lr: 0.000004\n",
            "2022-06-17 00:20:52,185 epoch 12 - iter 70/78 - loss 0.58777288 - samples/sec: 2.82 - lr: 0.000004\n",
            "2022-06-17 00:20:54,615 epoch 12 - iter 77/78 - loss 0.62407790 - samples/sec: 2.88 - lr: 0.000004\n",
            "2022-06-17 00:20:55,008 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:20:55,010 EPOCH 12 done: loss 0.6162 - lr 0.000004\n",
            "2022-06-17 00:20:55,014 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:20:55,020 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:20:57,579 epoch 13 - iter 7/78 - loss 0.47633834 - samples/sec: 2.74 - lr: 0.000004\n",
            "2022-06-17 00:21:00,100 epoch 13 - iter 14/78 - loss 0.70970964 - samples/sec: 2.78 - lr: 0.000004\n",
            "2022-06-17 00:21:02,644 epoch 13 - iter 21/78 - loss 0.59467034 - samples/sec: 2.75 - lr: 0.000004\n",
            "2022-06-17 00:21:05,181 epoch 13 - iter 28/78 - loss 0.57990419 - samples/sec: 2.76 - lr: 0.000004\n",
            "2022-06-17 00:21:07,923 epoch 13 - iter 35/78 - loss 0.54309752 - samples/sec: 2.56 - lr: 0.000004\n",
            "2022-06-17 00:21:10,479 epoch 13 - iter 42/78 - loss 0.54079493 - samples/sec: 2.74 - lr: 0.000004\n",
            "2022-06-17 00:21:12,963 epoch 13 - iter 49/78 - loss 0.53554141 - samples/sec: 2.82 - lr: 0.000004\n",
            "2022-06-17 00:21:15,424 epoch 13 - iter 56/78 - loss 0.52116047 - samples/sec: 2.85 - lr: 0.000004\n",
            "2022-06-17 00:21:18,036 epoch 13 - iter 63/78 - loss 0.49786092 - samples/sec: 2.68 - lr: 0.000004\n",
            "2022-06-17 00:21:20,563 epoch 13 - iter 70/78 - loss 0.47096208 - samples/sec: 2.77 - lr: 0.000004\n",
            "2022-06-17 00:21:23,129 epoch 13 - iter 77/78 - loss 0.43885647 - samples/sec: 2.73 - lr: 0.000004\n",
            "2022-06-17 00:21:23,470 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:21:23,471 EPOCH 13 done: loss 0.4340 - lr 0.000004\n",
            "2022-06-17 00:21:23,476 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:21:23,482 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:21:25,966 epoch 14 - iter 7/78 - loss 0.74021758 - samples/sec: 2.82 - lr: 0.000004\n",
            "2022-06-17 00:21:28,489 epoch 14 - iter 14/78 - loss 0.58576239 - samples/sec: 2.78 - lr: 0.000004\n",
            "2022-06-17 00:21:30,968 epoch 14 - iter 21/78 - loss 0.55257286 - samples/sec: 2.83 - lr: 0.000004\n",
            "2022-06-17 00:21:33,449 epoch 14 - iter 28/78 - loss 0.54188711 - samples/sec: 2.82 - lr: 0.000004\n",
            "2022-06-17 00:21:36,022 epoch 14 - iter 35/78 - loss 0.50622566 - samples/sec: 2.72 - lr: 0.000004\n",
            "2022-06-17 00:21:38,542 epoch 14 - iter 42/78 - loss 0.49326066 - samples/sec: 2.78 - lr: 0.000004\n",
            "2022-06-17 00:21:41,000 epoch 14 - iter 49/78 - loss 0.51661363 - samples/sec: 2.85 - lr: 0.000004\n",
            "2022-06-17 00:21:43,653 epoch 14 - iter 56/78 - loss 0.48195718 - samples/sec: 2.64 - lr: 0.000004\n",
            "2022-06-17 00:21:46,194 epoch 14 - iter 63/78 - loss 0.46323538 - samples/sec: 2.76 - lr: 0.000004\n",
            "2022-06-17 00:21:48,774 epoch 14 - iter 70/78 - loss 0.44503043 - samples/sec: 2.72 - lr: 0.000004\n",
            "2022-06-17 00:21:51,281 epoch 14 - iter 77/78 - loss 0.43378906 - samples/sec: 2.79 - lr: 0.000004\n",
            "2022-06-17 00:21:51,625 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:21:51,627 EPOCH 14 done: loss 0.4342 - lr 0.000004\n",
            "2022-06-17 00:21:51,631 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:21:51,635 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:21:54,096 epoch 15 - iter 7/78 - loss 0.30864950 - samples/sec: 2.85 - lr: 0.000004\n",
            "2022-06-17 00:21:56,619 epoch 15 - iter 14/78 - loss 0.46912810 - samples/sec: 2.78 - lr: 0.000004\n",
            "2022-06-17 00:21:59,145 epoch 15 - iter 21/78 - loss 0.45127100 - samples/sec: 2.77 - lr: 0.000004\n",
            "2022-06-17 00:22:01,567 epoch 15 - iter 28/78 - loss 0.45548013 - samples/sec: 2.89 - lr: 0.000004\n",
            "2022-06-17 00:22:04,121 epoch 15 - iter 35/78 - loss 0.43557595 - samples/sec: 2.74 - lr: 0.000004\n",
            "2022-06-17 00:22:06,772 epoch 15 - iter 42/78 - loss 0.41430739 - samples/sec: 2.64 - lr: 0.000004\n",
            "2022-06-17 00:22:09,302 epoch 15 - iter 49/78 - loss 0.40364686 - samples/sec: 2.77 - lr: 0.000004\n",
            "2022-06-17 00:22:11,766 epoch 15 - iter 56/78 - loss 0.39568884 - samples/sec: 2.84 - lr: 0.000004\n",
            "2022-06-17 00:22:14,353 epoch 15 - iter 63/78 - loss 0.38017616 - samples/sec: 2.71 - lr: 0.000004\n",
            "2022-06-17 00:22:16,819 epoch 15 - iter 70/78 - loss 0.40308981 - samples/sec: 2.84 - lr: 0.000004\n",
            "2022-06-17 00:22:19,427 epoch 15 - iter 77/78 - loss 0.39688875 - samples/sec: 2.69 - lr: 0.000004\n",
            "2022-06-17 00:22:19,766 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:22:19,768 EPOCH 15 done: loss 0.4007 - lr 0.000004\n",
            "2022-06-17 00:22:19,772 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:22:19,774 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:22:22,294 epoch 16 - iter 7/78 - loss 0.19174785 - samples/sec: 2.79 - lr: 0.000004\n",
            "2022-06-17 00:22:24,725 epoch 16 - iter 14/78 - loss 0.23053265 - samples/sec: 2.88 - lr: 0.000004\n",
            "2022-06-17 00:22:27,248 epoch 16 - iter 21/78 - loss 0.29064336 - samples/sec: 2.78 - lr: 0.000004\n",
            "2022-06-17 00:22:29,813 epoch 16 - iter 28/78 - loss 0.30839544 - samples/sec: 2.73 - lr: 0.000004\n",
            "2022-06-17 00:22:32,321 epoch 16 - iter 35/78 - loss 0.29773219 - samples/sec: 2.79 - lr: 0.000004\n",
            "2022-06-17 00:22:34,907 epoch 16 - iter 42/78 - loss 0.27870700 - samples/sec: 2.71 - lr: 0.000004\n",
            "2022-06-17 00:22:37,489 epoch 16 - iter 49/78 - loss 0.29393407 - samples/sec: 2.72 - lr: 0.000004\n",
            "2022-06-17 00:22:40,093 epoch 16 - iter 56/78 - loss 0.27706241 - samples/sec: 2.69 - lr: 0.000004\n",
            "2022-06-17 00:22:42,652 epoch 16 - iter 63/78 - loss 0.29773251 - samples/sec: 2.74 - lr: 0.000004\n",
            "2022-06-17 00:22:45,235 epoch 16 - iter 70/78 - loss 0.30255796 - samples/sec: 2.71 - lr: 0.000004\n",
            "2022-06-17 00:22:47,665 epoch 16 - iter 77/78 - loss 0.30452719 - samples/sec: 2.88 - lr: 0.000004\n",
            "2022-06-17 00:22:48,004 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:22:48,006 EPOCH 16 done: loss 0.3004 - lr 0.000004\n",
            "2022-06-17 00:22:48,009 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:22:48,013 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:22:50,540 epoch 17 - iter 7/78 - loss 0.19706169 - samples/sec: 2.78 - lr: 0.000004\n",
            "2022-06-17 00:22:53,106 epoch 17 - iter 14/78 - loss 0.23614420 - samples/sec: 2.73 - lr: 0.000004\n",
            "2022-06-17 00:22:55,610 epoch 17 - iter 21/78 - loss 0.27902187 - samples/sec: 2.80 - lr: 0.000004\n",
            "2022-06-17 00:22:58,166 epoch 17 - iter 28/78 - loss 0.29625582 - samples/sec: 2.74 - lr: 0.000004\n",
            "2022-06-17 00:23:00,761 epoch 17 - iter 35/78 - loss 0.28508800 - samples/sec: 2.70 - lr: 0.000004\n",
            "2022-06-17 00:23:03,325 epoch 17 - iter 42/78 - loss 0.30536087 - samples/sec: 2.73 - lr: 0.000004\n",
            "2022-06-17 00:23:05,866 epoch 17 - iter 49/78 - loss 0.31966681 - samples/sec: 2.76 - lr: 0.000004\n",
            "2022-06-17 00:23:08,398 epoch 17 - iter 56/78 - loss 0.31230257 - samples/sec: 2.77 - lr: 0.000004\n",
            "2022-06-17 00:23:10,862 epoch 17 - iter 63/78 - loss 0.29957854 - samples/sec: 2.84 - lr: 0.000004\n",
            "2022-06-17 00:23:13,456 epoch 17 - iter 70/78 - loss 0.30422053 - samples/sec: 2.70 - lr: 0.000004\n",
            "2022-06-17 00:23:15,979 epoch 17 - iter 77/78 - loss 0.29412841 - samples/sec: 2.78 - lr: 0.000004\n",
            "2022-06-17 00:23:16,355 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:23:16,358 EPOCH 17 done: loss 0.2976 - lr 0.000004\n",
            "2022-06-17 00:23:16,360 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:23:16,363 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:23:18,921 epoch 18 - iter 7/78 - loss 0.09570041 - samples/sec: 2.74 - lr: 0.000004\n",
            "2022-06-17 00:23:21,449 epoch 18 - iter 14/78 - loss 0.21220919 - samples/sec: 2.77 - lr: 0.000004\n",
            "2022-06-17 00:23:24,016 epoch 18 - iter 21/78 - loss 0.34636153 - samples/sec: 2.73 - lr: 0.000004\n",
            "2022-06-17 00:23:26,647 epoch 18 - iter 28/78 - loss 0.30415547 - samples/sec: 2.66 - lr: 0.000004\n",
            "2022-06-17 00:23:29,270 epoch 18 - iter 35/78 - loss 0.28123694 - samples/sec: 2.67 - lr: 0.000004\n",
            "2022-06-17 00:23:31,912 epoch 18 - iter 42/78 - loss 0.28061014 - samples/sec: 2.65 - lr: 0.000004\n",
            "2022-06-17 00:23:34,385 epoch 18 - iter 49/78 - loss 0.26937313 - samples/sec: 2.83 - lr: 0.000004\n",
            "2022-06-17 00:23:36,844 epoch 18 - iter 56/78 - loss 0.28533447 - samples/sec: 2.85 - lr: 0.000004\n",
            "2022-06-17 00:23:39,471 epoch 18 - iter 63/78 - loss 0.27276813 - samples/sec: 2.67 - lr: 0.000004\n",
            "2022-06-17 00:23:41,935 epoch 18 - iter 70/78 - loss 0.26386188 - samples/sec: 2.84 - lr: 0.000004\n",
            "2022-06-17 00:23:44,525 epoch 18 - iter 77/78 - loss 0.26050805 - samples/sec: 2.71 - lr: 0.000004\n",
            "2022-06-17 00:23:44,865 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:23:44,866 EPOCH 18 done: loss 0.2871 - lr 0.000004\n",
            "2022-06-17 00:23:44,874 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:23:44,876 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:23:47,309 epoch 19 - iter 7/78 - loss 0.16251378 - samples/sec: 2.89 - lr: 0.000004\n",
            "2022-06-17 00:23:49,743 epoch 19 - iter 14/78 - loss 0.16477621 - samples/sec: 2.88 - lr: 0.000004\n",
            "2022-06-17 00:23:52,248 epoch 19 - iter 21/78 - loss 0.16683971 - samples/sec: 2.80 - lr: 0.000004\n",
            "2022-06-17 00:23:54,817 epoch 19 - iter 28/78 - loss 0.16222416 - samples/sec: 2.73 - lr: 0.000004\n",
            "2022-06-17 00:23:57,444 epoch 19 - iter 35/78 - loss 0.16541415 - samples/sec: 2.67 - lr: 0.000004\n",
            "2022-06-17 00:23:59,882 epoch 19 - iter 42/78 - loss 0.19658134 - samples/sec: 2.87 - lr: 0.000003\n",
            "2022-06-17 00:24:02,506 epoch 19 - iter 49/78 - loss 0.23186564 - samples/sec: 2.67 - lr: 0.000003\n",
            "2022-06-17 00:24:05,091 epoch 19 - iter 56/78 - loss 0.23418814 - samples/sec: 2.71 - lr: 0.000003\n",
            "2022-06-17 00:24:07,559 epoch 19 - iter 63/78 - loss 0.25540608 - samples/sec: 2.84 - lr: 0.000003\n",
            "2022-06-17 00:24:10,120 epoch 19 - iter 70/78 - loss 0.24025615 - samples/sec: 2.74 - lr: 0.000003\n",
            "2022-06-17 00:24:12,666 epoch 19 - iter 77/78 - loss 0.24528286 - samples/sec: 2.75 - lr: 0.000003\n",
            "2022-06-17 00:24:13,004 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:24:13,008 EPOCH 19 done: loss 0.2411 - lr 0.000003\n",
            "2022-06-17 00:24:13,011 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:24:13,020 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:24:15,473 epoch 20 - iter 7/78 - loss 0.20920714 - samples/sec: 2.86 - lr: 0.000003\n",
            "2022-06-17 00:24:17,878 epoch 20 - iter 14/78 - loss 0.23467294 - samples/sec: 2.91 - lr: 0.000003\n",
            "2022-06-17 00:24:20,485 epoch 20 - iter 21/78 - loss 0.18187726 - samples/sec: 2.69 - lr: 0.000003\n",
            "2022-06-17 00:24:23,115 epoch 20 - iter 28/78 - loss 0.18925415 - samples/sec: 2.66 - lr: 0.000003\n",
            "2022-06-17 00:24:25,638 epoch 20 - iter 35/78 - loss 0.17631733 - samples/sec: 2.78 - lr: 0.000003\n",
            "2022-06-17 00:24:28,104 epoch 20 - iter 42/78 - loss 0.22068854 - samples/sec: 2.84 - lr: 0.000003\n",
            "2022-06-17 00:24:30,635 epoch 20 - iter 49/78 - loss 0.20692200 - samples/sec: 2.77 - lr: 0.000003\n",
            "2022-06-17 00:24:33,264 epoch 20 - iter 56/78 - loss 0.18086350 - samples/sec: 2.66 - lr: 0.000003\n",
            "2022-06-17 00:24:36,008 epoch 20 - iter 63/78 - loss 0.18941522 - samples/sec: 2.55 - lr: 0.000003\n",
            "2022-06-17 00:24:38,520 epoch 20 - iter 70/78 - loss 0.18120255 - samples/sec: 2.79 - lr: 0.000003\n",
            "2022-06-17 00:24:41,087 epoch 20 - iter 77/78 - loss 0.20152743 - samples/sec: 2.73 - lr: 0.000003\n",
            "2022-06-17 00:24:41,425 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:24:41,427 EPOCH 20 done: loss 0.2005 - lr 0.000003\n",
            "2022-06-17 00:24:41,431 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:24:41,435 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:24:43,865 epoch 21 - iter 7/78 - loss 0.55811222 - samples/sec: 2.89 - lr: 0.000003\n",
            "2022-06-17 00:24:46,483 epoch 21 - iter 14/78 - loss 0.37319424 - samples/sec: 2.68 - lr: 0.000003\n",
            "2022-06-17 00:24:49,109 epoch 21 - iter 21/78 - loss 0.29569056 - samples/sec: 2.67 - lr: 0.000003\n",
            "2022-06-17 00:24:51,677 epoch 21 - iter 28/78 - loss 0.26245863 - samples/sec: 2.73 - lr: 0.000003\n",
            "2022-06-17 00:24:54,303 epoch 21 - iter 35/78 - loss 0.24293513 - samples/sec: 2.67 - lr: 0.000003\n",
            "2022-06-17 00:24:56,801 epoch 21 - iter 42/78 - loss 0.26188251 - samples/sec: 2.81 - lr: 0.000003\n",
            "2022-06-17 00:24:59,238 epoch 21 - iter 49/78 - loss 0.26483417 - samples/sec: 2.87 - lr: 0.000003\n",
            "2022-06-17 00:25:01,664 epoch 21 - iter 56/78 - loss 0.24523597 - samples/sec: 2.89 - lr: 0.000003\n",
            "2022-06-17 00:25:04,137 epoch 21 - iter 63/78 - loss 0.24362032 - samples/sec: 2.83 - lr: 0.000003\n",
            "2022-06-17 00:25:06,738 epoch 21 - iter 70/78 - loss 0.24749100 - samples/sec: 2.69 - lr: 0.000003\n",
            "2022-06-17 00:25:09,122 epoch 21 - iter 77/78 - loss 0.24422444 - samples/sec: 2.94 - lr: 0.000003\n",
            "2022-06-17 00:25:09,526 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:25:09,528 EPOCH 21 done: loss 0.2401 - lr 0.000003\n",
            "2022-06-17 00:25:09,535 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:25:09,537 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:25:12,051 epoch 22 - iter 7/78 - loss 0.53628384 - samples/sec: 2.79 - lr: 0.000003\n",
            "2022-06-17 00:25:14,634 epoch 22 - iter 14/78 - loss 0.33413809 - samples/sec: 2.71 - lr: 0.000003\n",
            "2022-06-17 00:25:17,245 epoch 22 - iter 21/78 - loss 0.27064900 - samples/sec: 2.68 - lr: 0.000003\n",
            "2022-06-17 00:25:19,906 epoch 22 - iter 28/78 - loss 0.25199273 - samples/sec: 2.63 - lr: 0.000003\n",
            "2022-06-17 00:25:22,455 epoch 22 - iter 35/78 - loss 0.23597586 - samples/sec: 2.76 - lr: 0.000003\n",
            "2022-06-17 00:25:24,866 epoch 22 - iter 42/78 - loss 0.25916538 - samples/sec: 2.91 - lr: 0.000003\n",
            "2022-06-17 00:25:27,400 epoch 22 - iter 49/78 - loss 0.26738768 - samples/sec: 2.76 - lr: 0.000003\n",
            "2022-06-17 00:25:29,969 epoch 22 - iter 56/78 - loss 0.26814724 - samples/sec: 2.73 - lr: 0.000003\n",
            "2022-06-17 00:25:32,424 epoch 22 - iter 63/78 - loss 0.26307174 - samples/sec: 2.85 - lr: 0.000003\n",
            "2022-06-17 00:25:34,995 epoch 22 - iter 70/78 - loss 0.25086821 - samples/sec: 2.73 - lr: 0.000003\n",
            "2022-06-17 00:25:37,569 epoch 22 - iter 77/78 - loss 0.24595589 - samples/sec: 2.72 - lr: 0.000003\n",
            "2022-06-17 00:25:37,908 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:25:37,909 EPOCH 22 done: loss 0.2433 - lr 0.000003\n",
            "2022-06-17 00:25:37,914 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:25:37,918 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:25:40,523 epoch 23 - iter 7/78 - loss 0.04604871 - samples/sec: 2.69 - lr: 0.000003\n",
            "2022-06-17 00:25:43,036 epoch 23 - iter 14/78 - loss 0.15520847 - samples/sec: 2.79 - lr: 0.000003\n",
            "2022-06-17 00:25:45,702 epoch 23 - iter 21/78 - loss 0.16720336 - samples/sec: 2.63 - lr: 0.000003\n",
            "2022-06-17 00:25:48,239 epoch 23 - iter 28/78 - loss 0.18534218 - samples/sec: 2.76 - lr: 0.000003\n",
            "2022-06-17 00:25:50,799 epoch 23 - iter 35/78 - loss 0.18255633 - samples/sec: 2.74 - lr: 0.000003\n",
            "2022-06-17 00:25:53,378 epoch 23 - iter 42/78 - loss 0.21060110 - samples/sec: 2.72 - lr: 0.000003\n",
            "2022-06-17 00:25:55,981 epoch 23 - iter 49/78 - loss 0.22353249 - samples/sec: 2.69 - lr: 0.000003\n",
            "2022-06-17 00:25:58,590 epoch 23 - iter 56/78 - loss 0.23488555 - samples/sec: 2.69 - lr: 0.000003\n",
            "2022-06-17 00:26:01,126 epoch 23 - iter 63/78 - loss 0.22297178 - samples/sec: 2.76 - lr: 0.000003\n",
            "2022-06-17 00:26:03,605 epoch 23 - iter 70/78 - loss 0.22823513 - samples/sec: 2.83 - lr: 0.000003\n",
            "2022-06-17 00:26:06,211 epoch 23 - iter 77/78 - loss 0.21303292 - samples/sec: 2.69 - lr: 0.000003\n",
            "2022-06-17 00:26:06,552 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:26:06,553 EPOCH 23 done: loss 0.2155 - lr 0.000003\n",
            "2022-06-17 00:26:06,560 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:26:06,564 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:26:09,104 epoch 24 - iter 7/78 - loss 0.12803619 - samples/sec: 2.76 - lr: 0.000003\n",
            "2022-06-17 00:26:11,613 epoch 24 - iter 14/78 - loss 0.12846993 - samples/sec: 2.79 - lr: 0.000003\n",
            "2022-06-17 00:26:14,095 epoch 24 - iter 21/78 - loss 0.12848730 - samples/sec: 2.82 - lr: 0.000003\n",
            "2022-06-17 00:26:16,631 epoch 24 - iter 28/78 - loss 0.16009106 - samples/sec: 2.76 - lr: 0.000003\n",
            "2022-06-17 00:26:19,243 epoch 24 - iter 35/78 - loss 0.12615241 - samples/sec: 2.68 - lr: 0.000003\n",
            "2022-06-17 00:26:21,772 epoch 24 - iter 42/78 - loss 0.14022965 - samples/sec: 2.77 - lr: 0.000003\n",
            "2022-06-17 00:26:24,318 epoch 24 - iter 49/78 - loss 0.15369951 - samples/sec: 2.75 - lr: 0.000003\n",
            "2022-06-17 00:26:26,845 epoch 24 - iter 56/78 - loss 0.14423875 - samples/sec: 2.77 - lr: 0.000003\n",
            "2022-06-17 00:26:29,458 epoch 24 - iter 63/78 - loss 0.15238171 - samples/sec: 2.68 - lr: 0.000003\n",
            "2022-06-17 00:26:32,021 epoch 24 - iter 70/78 - loss 0.18073038 - samples/sec: 2.73 - lr: 0.000003\n",
            "2022-06-17 00:26:34,530 epoch 24 - iter 77/78 - loss 0.17627794 - samples/sec: 2.79 - lr: 0.000003\n",
            "2022-06-17 00:26:34,934 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:26:34,937 EPOCH 24 done: loss 0.1774 - lr 0.000003\n",
            "2022-06-17 00:26:34,941 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:26:34,945 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:26:37,510 epoch 25 - iter 7/78 - loss 0.30563023 - samples/sec: 2.73 - lr: 0.000003\n",
            "2022-06-17 00:26:40,002 epoch 25 - iter 14/78 - loss 0.28203624 - samples/sec: 2.81 - lr: 0.000003\n",
            "2022-06-17 00:26:42,463 epoch 25 - iter 21/78 - loss 0.30721899 - samples/sec: 2.85 - lr: 0.000003\n",
            "2022-06-17 00:26:45,112 epoch 25 - iter 28/78 - loss 0.26142893 - samples/sec: 2.64 - lr: 0.000003\n",
            "2022-06-17 00:26:47,677 epoch 25 - iter 35/78 - loss 0.25872502 - samples/sec: 2.73 - lr: 0.000003\n",
            "2022-06-17 00:26:50,194 epoch 25 - iter 42/78 - loss 0.24328708 - samples/sec: 2.78 - lr: 0.000003\n",
            "2022-06-17 00:26:52,669 epoch 25 - iter 49/78 - loss 0.22768109 - samples/sec: 2.83 - lr: 0.000003\n",
            "2022-06-17 00:26:55,185 epoch 25 - iter 56/78 - loss 0.23300231 - samples/sec: 2.78 - lr: 0.000003\n",
            "2022-06-17 00:26:57,754 epoch 25 - iter 63/78 - loss 0.21188610 - samples/sec: 2.73 - lr: 0.000003\n",
            "2022-06-17 00:27:00,414 epoch 25 - iter 70/78 - loss 0.19242169 - samples/sec: 2.63 - lr: 0.000003\n",
            "2022-06-17 00:27:02,932 epoch 25 - iter 77/78 - loss 0.17605715 - samples/sec: 2.78 - lr: 0.000003\n",
            "2022-06-17 00:27:03,321 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:27:03,323 EPOCH 25 done: loss 0.1738 - lr 0.000003\n",
            "2022-06-17 00:27:03,325 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:27:03,331 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:27:05,982 epoch 26 - iter 7/78 - loss 0.17355598 - samples/sec: 2.65 - lr: 0.000003\n",
            "2022-06-17 00:27:08,505 epoch 26 - iter 14/78 - loss 0.13082161 - samples/sec: 2.78 - lr: 0.000003\n",
            "2022-06-17 00:27:10,975 epoch 26 - iter 21/78 - loss 0.12215563 - samples/sec: 2.84 - lr: 0.000003\n",
            "2022-06-17 00:27:13,414 epoch 26 - iter 28/78 - loss 0.11269010 - samples/sec: 2.87 - lr: 0.000003\n",
            "2022-06-17 00:27:16,056 epoch 26 - iter 35/78 - loss 0.09838832 - samples/sec: 2.65 - lr: 0.000003\n",
            "2022-06-17 00:27:18,651 epoch 26 - iter 42/78 - loss 0.09065881 - samples/sec: 2.70 - lr: 0.000003\n",
            "2022-06-17 00:27:21,168 epoch 26 - iter 49/78 - loss 0.09776263 - samples/sec: 2.78 - lr: 0.000003\n",
            "2022-06-17 00:27:23,778 epoch 26 - iter 56/78 - loss 0.12154266 - samples/sec: 2.68 - lr: 0.000003\n",
            "2022-06-17 00:27:26,190 epoch 26 - iter 63/78 - loss 0.11613362 - samples/sec: 2.90 - lr: 0.000003\n",
            "2022-06-17 00:27:28,638 epoch 26 - iter 70/78 - loss 0.13605969 - samples/sec: 2.86 - lr: 0.000003\n",
            "2022-06-17 00:27:31,224 epoch 26 - iter 77/78 - loss 0.13975543 - samples/sec: 2.71 - lr: 0.000003\n",
            "2022-06-17 00:27:31,562 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:27:31,563 EPOCH 26 done: loss 0.1390 - lr 0.000003\n",
            "2022-06-17 00:27:31,568 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:27:31,576 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:27:34,176 epoch 27 - iter 7/78 - loss 0.09981070 - samples/sec: 2.70 - lr: 0.000003\n",
            "2022-06-17 00:27:36,575 epoch 27 - iter 14/78 - loss 0.17079133 - samples/sec: 2.92 - lr: 0.000003\n",
            "2022-06-17 00:27:39,123 epoch 27 - iter 21/78 - loss 0.15110887 - samples/sec: 2.75 - lr: 0.000003\n",
            "2022-06-17 00:27:41,688 epoch 27 - iter 28/78 - loss 0.13153814 - samples/sec: 2.73 - lr: 0.000003\n",
            "2022-06-17 00:27:44,143 epoch 27 - iter 35/78 - loss 0.12492743 - samples/sec: 2.85 - lr: 0.000003\n",
            "2022-06-17 00:27:46,708 epoch 27 - iter 42/78 - loss 0.13206078 - samples/sec: 2.73 - lr: 0.000003\n",
            "2022-06-17 00:27:49,186 epoch 27 - iter 49/78 - loss 0.15481297 - samples/sec: 2.83 - lr: 0.000003\n",
            "2022-06-17 00:27:51,555 epoch 27 - iter 56/78 - loss 0.14947256 - samples/sec: 2.96 - lr: 0.000003\n",
            "2022-06-17 00:27:54,253 epoch 27 - iter 63/78 - loss 0.13971773 - samples/sec: 2.60 - lr: 0.000003\n",
            "2022-06-17 00:27:56,855 epoch 27 - iter 70/78 - loss 0.14743175 - samples/sec: 2.69 - lr: 0.000003\n",
            "2022-06-17 00:27:59,455 epoch 27 - iter 77/78 - loss 0.15224539 - samples/sec: 2.69 - lr: 0.000003\n",
            "2022-06-17 00:27:59,867 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:27:59,869 EPOCH 27 done: loss 0.1590 - lr 0.000003\n",
            "2022-06-17 00:27:59,873 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:27:59,879 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:28:02,460 epoch 28 - iter 7/78 - loss 0.19945717 - samples/sec: 2.72 - lr: 0.000003\n",
            "2022-06-17 00:28:05,075 epoch 28 - iter 14/78 - loss 0.15293719 - samples/sec: 2.68 - lr: 0.000003\n",
            "2022-06-17 00:28:07,728 epoch 28 - iter 21/78 - loss 0.18563652 - samples/sec: 2.64 - lr: 0.000003\n",
            "2022-06-17 00:28:10,207 epoch 28 - iter 28/78 - loss 0.15434093 - samples/sec: 2.83 - lr: 0.000003\n",
            "2022-06-17 00:28:12,688 epoch 28 - iter 35/78 - loss 0.14023959 - samples/sec: 2.82 - lr: 0.000003\n",
            "2022-06-17 00:28:15,286 epoch 28 - iter 42/78 - loss 0.15032164 - samples/sec: 2.70 - lr: 0.000002\n",
            "2022-06-17 00:28:17,913 epoch 28 - iter 49/78 - loss 0.14505054 - samples/sec: 2.67 - lr: 0.000002\n",
            "2022-06-17 00:28:20,442 epoch 28 - iter 56/78 - loss 0.13045592 - samples/sec: 2.77 - lr: 0.000002\n",
            "2022-06-17 00:28:23,061 epoch 28 - iter 63/78 - loss 0.14185239 - samples/sec: 2.68 - lr: 0.000002\n",
            "2022-06-17 00:28:25,670 epoch 28 - iter 70/78 - loss 0.14027456 - samples/sec: 2.68 - lr: 0.000002\n",
            "2022-06-17 00:28:28,245 epoch 28 - iter 77/78 - loss 0.15420590 - samples/sec: 2.72 - lr: 0.000002\n",
            "2022-06-17 00:28:28,585 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:28:28,586 EPOCH 28 done: loss 0.1643 - lr 0.000002\n",
            "2022-06-17 00:28:28,591 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:28:28,595 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:28:31,174 epoch 29 - iter 7/78 - loss 0.16295758 - samples/sec: 2.72 - lr: 0.000002\n",
            "2022-06-17 00:28:33,821 epoch 29 - iter 14/78 - loss 0.12512875 - samples/sec: 2.65 - lr: 0.000002\n",
            "2022-06-17 00:28:36,338 epoch 29 - iter 21/78 - loss 0.16460283 - samples/sec: 2.78 - lr: 0.000002\n",
            "2022-06-17 00:28:38,952 epoch 29 - iter 28/78 - loss 0.18471324 - samples/sec: 2.68 - lr: 0.000002\n",
            "2022-06-17 00:28:41,653 epoch 29 - iter 35/78 - loss 0.18480565 - samples/sec: 2.59 - lr: 0.000002\n",
            "2022-06-17 00:28:44,215 epoch 29 - iter 42/78 - loss 0.20393918 - samples/sec: 2.73 - lr: 0.000002\n",
            "2022-06-17 00:28:46,764 epoch 29 - iter 49/78 - loss 0.18142241 - samples/sec: 2.75 - lr: 0.000002\n",
            "2022-06-17 00:28:49,331 epoch 29 - iter 56/78 - loss 0.18231587 - samples/sec: 2.73 - lr: 0.000002\n",
            "2022-06-17 00:28:51,810 epoch 29 - iter 63/78 - loss 0.16191977 - samples/sec: 2.83 - lr: 0.000002\n",
            "2022-06-17 00:28:54,304 epoch 29 - iter 70/78 - loss 0.15153172 - samples/sec: 2.81 - lr: 0.000002\n",
            "2022-06-17 00:28:56,737 epoch 29 - iter 77/78 - loss 0.15147134 - samples/sec: 2.88 - lr: 0.000002\n",
            "2022-06-17 00:28:57,139 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:28:57,141 EPOCH 29 done: loss 0.1531 - lr 0.000002\n",
            "2022-06-17 00:28:57,146 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:28:57,150 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:28:59,648 epoch 30 - iter 7/78 - loss 0.05105284 - samples/sec: 2.81 - lr: 0.000002\n",
            "2022-06-17 00:29:02,235 epoch 30 - iter 14/78 - loss 0.08423256 - samples/sec: 2.71 - lr: 0.000002\n",
            "2022-06-17 00:29:04,783 epoch 30 - iter 21/78 - loss 0.09174075 - samples/sec: 2.75 - lr: 0.000002\n",
            "2022-06-17 00:29:07,278 epoch 30 - iter 28/78 - loss 0.11569604 - samples/sec: 2.81 - lr: 0.000002\n",
            "2022-06-17 00:29:09,951 epoch 30 - iter 35/78 - loss 0.10383649 - samples/sec: 2.62 - lr: 0.000002\n",
            "2022-06-17 00:29:12,468 epoch 30 - iter 42/78 - loss 0.09941935 - samples/sec: 2.78 - lr: 0.000002\n",
            "2022-06-17 00:29:15,077 epoch 30 - iter 49/78 - loss 0.09470401 - samples/sec: 2.68 - lr: 0.000002\n",
            "2022-06-17 00:29:17,587 epoch 30 - iter 56/78 - loss 0.13203161 - samples/sec: 2.79 - lr: 0.000002\n",
            "2022-06-17 00:29:20,165 epoch 30 - iter 63/78 - loss 0.13428018 - samples/sec: 2.72 - lr: 0.000002\n",
            "2022-06-17 00:29:22,743 epoch 30 - iter 70/78 - loss 0.15159465 - samples/sec: 2.72 - lr: 0.000002\n",
            "2022-06-17 00:29:25,256 epoch 30 - iter 77/78 - loss 0.15353905 - samples/sec: 2.79 - lr: 0.000002\n",
            "2022-06-17 00:29:25,593 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:29:25,596 EPOCH 30 done: loss 0.1563 - lr 0.000002\n",
            "2022-06-17 00:29:25,603 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:29:25,604 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:29:28,121 epoch 31 - iter 7/78 - loss 0.18230589 - samples/sec: 2.79 - lr: 0.000002\n",
            "2022-06-17 00:29:30,675 epoch 31 - iter 14/78 - loss 0.11467458 - samples/sec: 2.74 - lr: 0.000002\n",
            "2022-06-17 00:29:33,290 epoch 31 - iter 21/78 - loss 0.13417667 - samples/sec: 2.68 - lr: 0.000002\n",
            "2022-06-17 00:29:35,783 epoch 31 - iter 28/78 - loss 0.15116663 - samples/sec: 2.81 - lr: 0.000002\n",
            "2022-06-17 00:29:38,300 epoch 31 - iter 35/78 - loss 0.16668925 - samples/sec: 2.78 - lr: 0.000002\n",
            "2022-06-17 00:29:40,980 epoch 31 - iter 42/78 - loss 0.18013764 - samples/sec: 2.62 - lr: 0.000002\n",
            "2022-06-17 00:29:43,533 epoch 31 - iter 49/78 - loss 0.16503497 - samples/sec: 2.74 - lr: 0.000002\n",
            "2022-06-17 00:29:46,006 epoch 31 - iter 56/78 - loss 0.15872111 - samples/sec: 2.83 - lr: 0.000002\n",
            "2022-06-17 00:29:48,561 epoch 31 - iter 63/78 - loss 0.14966538 - samples/sec: 2.74 - lr: 0.000002\n",
            "2022-06-17 00:29:51,098 epoch 31 - iter 70/78 - loss 0.16645465 - samples/sec: 2.76 - lr: 0.000002\n",
            "2022-06-17 00:29:53,566 epoch 31 - iter 77/78 - loss 0.17570236 - samples/sec: 2.84 - lr: 0.000002\n",
            "2022-06-17 00:29:53,961 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:29:53,965 EPOCH 31 done: loss 0.1744 - lr 0.000002\n",
            "2022-06-17 00:29:53,968 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:29:53,972 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:29:56,474 epoch 32 - iter 7/78 - loss 0.06613512 - samples/sec: 2.80 - lr: 0.000002\n",
            "2022-06-17 00:29:59,075 epoch 32 - iter 14/78 - loss 0.10341731 - samples/sec: 2.69 - lr: 0.000002\n",
            "2022-06-17 00:30:01,583 epoch 32 - iter 21/78 - loss 0.08188353 - samples/sec: 2.79 - lr: 0.000002\n",
            "2022-06-17 00:30:04,125 epoch 32 - iter 28/78 - loss 0.07684083 - samples/sec: 2.76 - lr: 0.000002\n",
            "2022-06-17 00:30:06,740 epoch 32 - iter 35/78 - loss 0.07642857 - samples/sec: 2.68 - lr: 0.000002\n",
            "2022-06-17 00:30:09,172 epoch 32 - iter 42/78 - loss 0.08870619 - samples/sec: 2.88 - lr: 0.000002\n",
            "2022-06-17 00:30:11,640 epoch 32 - iter 49/78 - loss 0.09947268 - samples/sec: 2.84 - lr: 0.000002\n",
            "2022-06-17 00:30:14,264 epoch 32 - iter 56/78 - loss 0.12472402 - samples/sec: 2.67 - lr: 0.000002\n",
            "2022-06-17 00:30:16,721 epoch 32 - iter 63/78 - loss 0.11890460 - samples/sec: 2.85 - lr: 0.000002\n",
            "2022-06-17 00:30:19,141 epoch 32 - iter 70/78 - loss 0.12442448 - samples/sec: 2.90 - lr: 0.000002\n",
            "2022-06-17 00:30:21,639 epoch 32 - iter 77/78 - loss 0.11908611 - samples/sec: 2.80 - lr: 0.000002\n",
            "2022-06-17 00:30:21,978 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:30:21,980 EPOCH 32 done: loss 0.1220 - lr 0.000002\n",
            "2022-06-17 00:30:21,984 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:30:21,987 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:30:24,388 epoch 33 - iter 7/78 - loss 0.05137912 - samples/sec: 2.92 - lr: 0.000002\n",
            "2022-06-17 00:30:26,950 epoch 33 - iter 14/78 - loss 0.10514579 - samples/sec: 2.74 - lr: 0.000002\n",
            "2022-06-17 00:30:29,525 epoch 33 - iter 21/78 - loss 0.16960967 - samples/sec: 2.72 - lr: 0.000002\n",
            "2022-06-17 00:30:32,089 epoch 33 - iter 28/78 - loss 0.17083762 - samples/sec: 2.73 - lr: 0.000002\n",
            "2022-06-17 00:30:34,768 epoch 33 - iter 35/78 - loss 0.18284393 - samples/sec: 2.62 - lr: 0.000002\n",
            "2022-06-17 00:30:37,270 epoch 33 - iter 42/78 - loss 0.18908473 - samples/sec: 2.80 - lr: 0.000002\n",
            "2022-06-17 00:30:39,765 epoch 33 - iter 49/78 - loss 0.19449470 - samples/sec: 2.81 - lr: 0.000002\n",
            "2022-06-17 00:30:42,180 epoch 33 - iter 56/78 - loss 0.17023720 - samples/sec: 2.90 - lr: 0.000002\n",
            "2022-06-17 00:30:44,727 epoch 33 - iter 63/78 - loss 0.15883626 - samples/sec: 2.75 - lr: 0.000002\n",
            "2022-06-17 00:30:47,202 epoch 33 - iter 70/78 - loss 0.15613402 - samples/sec: 2.83 - lr: 0.000002\n",
            "2022-06-17 00:30:49,706 epoch 33 - iter 77/78 - loss 0.16628093 - samples/sec: 2.80 - lr: 0.000002\n",
            "2022-06-17 00:30:50,048 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:30:50,050 EPOCH 33 done: loss 0.1642 - lr 0.000002\n",
            "2022-06-17 00:30:50,057 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:30:50,059 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:30:52,627 epoch 34 - iter 7/78 - loss 0.11393709 - samples/sec: 2.73 - lr: 0.000002\n",
            "2022-06-17 00:30:55,199 epoch 34 - iter 14/78 - loss 0.15845092 - samples/sec: 2.72 - lr: 0.000002\n",
            "2022-06-17 00:30:57,750 epoch 34 - iter 21/78 - loss 0.17809836 - samples/sec: 2.75 - lr: 0.000002\n",
            "2022-06-17 00:31:00,264 epoch 34 - iter 28/78 - loss 0.22826836 - samples/sec: 2.79 - lr: 0.000002\n",
            "2022-06-17 00:31:02,746 epoch 34 - iter 35/78 - loss 0.25504310 - samples/sec: 2.82 - lr: 0.000002\n",
            "2022-06-17 00:31:05,237 epoch 34 - iter 42/78 - loss 0.21821353 - samples/sec: 2.81 - lr: 0.000002\n",
            "2022-06-17 00:31:07,790 epoch 34 - iter 49/78 - loss 0.20898191 - samples/sec: 2.74 - lr: 0.000002\n",
            "2022-06-17 00:31:10,293 epoch 34 - iter 56/78 - loss 0.20814563 - samples/sec: 2.80 - lr: 0.000002\n",
            "2022-06-17 00:31:12,842 epoch 34 - iter 63/78 - loss 0.21642580 - samples/sec: 2.75 - lr: 0.000002\n",
            "2022-06-17 00:31:15,459 epoch 34 - iter 70/78 - loss 0.20189388 - samples/sec: 2.68 - lr: 0.000002\n",
            "2022-06-17 00:31:18,028 epoch 34 - iter 77/78 - loss 0.20632700 - samples/sec: 2.73 - lr: 0.000002\n",
            "2022-06-17 00:31:18,365 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:31:18,366 EPOCH 34 done: loss 0.2087 - lr 0.000002\n",
            "2022-06-17 00:31:18,371 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:31:18,375 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:31:20,877 epoch 35 - iter 7/78 - loss 0.29183355 - samples/sec: 2.80 - lr: 0.000002\n",
            "2022-06-17 00:31:23,434 epoch 35 - iter 14/78 - loss 0.23619057 - samples/sec: 2.74 - lr: 0.000002\n",
            "2022-06-17 00:31:25,936 epoch 35 - iter 21/78 - loss 0.32143991 - samples/sec: 2.80 - lr: 0.000002\n",
            "2022-06-17 00:31:28,569 epoch 35 - iter 28/78 - loss 0.26404931 - samples/sec: 2.66 - lr: 0.000002\n",
            "2022-06-17 00:31:31,295 epoch 35 - iter 35/78 - loss 0.21241112 - samples/sec: 2.57 - lr: 0.000002\n",
            "2022-06-17 00:31:33,862 epoch 35 - iter 42/78 - loss 0.18813998 - samples/sec: 2.73 - lr: 0.000002\n",
            "2022-06-17 00:31:36,398 epoch 35 - iter 49/78 - loss 0.19274414 - samples/sec: 2.76 - lr: 0.000002\n",
            "2022-06-17 00:31:38,948 epoch 35 - iter 56/78 - loss 0.19165971 - samples/sec: 2.75 - lr: 0.000002\n",
            "2022-06-17 00:31:41,554 epoch 35 - iter 63/78 - loss 0.17054844 - samples/sec: 2.69 - lr: 0.000002\n",
            "2022-06-17 00:31:44,075 epoch 35 - iter 70/78 - loss 0.16871102 - samples/sec: 2.78 - lr: 0.000002\n",
            "2022-06-17 00:31:46,489 epoch 35 - iter 77/78 - loss 0.15484251 - samples/sec: 2.90 - lr: 0.000002\n",
            "2022-06-17 00:31:46,879 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:31:46,880 EPOCH 35 done: loss 0.1537 - lr 0.000002\n",
            "2022-06-17 00:31:46,885 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:31:46,889 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:31:49,431 epoch 36 - iter 7/78 - loss 0.31460850 - samples/sec: 2.76 - lr: 0.000002\n",
            "2022-06-17 00:31:51,906 epoch 36 - iter 14/78 - loss 0.27525636 - samples/sec: 2.83 - lr: 0.000002\n",
            "2022-06-17 00:31:54,639 epoch 36 - iter 21/78 - loss 0.22772151 - samples/sec: 2.56 - lr: 0.000002\n",
            "2022-06-17 00:31:57,269 epoch 36 - iter 28/78 - loss 0.19962192 - samples/sec: 2.66 - lr: 0.000002\n",
            "2022-06-17 00:31:59,803 epoch 36 - iter 35/78 - loss 0.20395718 - samples/sec: 2.76 - lr: 0.000002\n",
            "2022-06-17 00:32:02,290 epoch 36 - iter 42/78 - loss 0.21559931 - samples/sec: 2.82 - lr: 0.000002\n",
            "2022-06-17 00:32:04,798 epoch 36 - iter 49/78 - loss 0.20622186 - samples/sec: 2.79 - lr: 0.000002\n",
            "2022-06-17 00:32:07,389 epoch 36 - iter 56/78 - loss 0.21519754 - samples/sec: 2.70 - lr: 0.000002\n",
            "2022-06-17 00:32:09,803 epoch 36 - iter 63/78 - loss 0.20963943 - samples/sec: 2.90 - lr: 0.000002\n",
            "2022-06-17 00:32:12,315 epoch 36 - iter 70/78 - loss 0.21546051 - samples/sec: 2.79 - lr: 0.000002\n",
            "2022-06-17 00:32:14,750 epoch 36 - iter 77/78 - loss 0.19804167 - samples/sec: 2.88 - lr: 0.000002\n",
            "2022-06-17 00:32:15,088 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:32:15,090 EPOCH 36 done: loss 0.1966 - lr 0.000002\n",
            "2022-06-17 00:32:15,093 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:32:15,100 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:32:17,516 epoch 37 - iter 7/78 - loss 0.06001211 - samples/sec: 2.91 - lr: 0.000002\n",
            "2022-06-17 00:32:20,168 epoch 37 - iter 14/78 - loss 0.07653706 - samples/sec: 2.64 - lr: 0.000002\n",
            "2022-06-17 00:32:22,594 epoch 37 - iter 21/78 - loss 0.15291700 - samples/sec: 2.89 - lr: 0.000002\n",
            "2022-06-17 00:32:24,968 epoch 37 - iter 28/78 - loss 0.18490440 - samples/sec: 2.95 - lr: 0.000002\n",
            "2022-06-17 00:32:27,481 epoch 37 - iter 35/78 - loss 0.16213267 - samples/sec: 2.79 - lr: 0.000002\n",
            "2022-06-17 00:32:30,100 epoch 37 - iter 42/78 - loss 0.14724774 - samples/sec: 2.67 - lr: 0.000001\n",
            "2022-06-17 00:32:32,635 epoch 37 - iter 49/78 - loss 0.20389219 - samples/sec: 2.76 - lr: 0.000001\n",
            "2022-06-17 00:32:35,137 epoch 37 - iter 56/78 - loss 0.19372223 - samples/sec: 2.80 - lr: 0.000001\n",
            "2022-06-17 00:32:37,721 epoch 37 - iter 63/78 - loss 0.19103270 - samples/sec: 2.71 - lr: 0.000001\n",
            "2022-06-17 00:32:40,278 epoch 37 - iter 70/78 - loss 0.17405743 - samples/sec: 2.74 - lr: 0.000001\n",
            "2022-06-17 00:32:42,903 epoch 37 - iter 77/78 - loss 0.18185263 - samples/sec: 2.67 - lr: 0.000001\n",
            "2022-06-17 00:32:43,240 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:32:43,242 EPOCH 37 done: loss 0.1805 - lr 0.000001\n",
            "2022-06-17 00:32:43,247 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:32:43,250 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:32:45,763 epoch 38 - iter 7/78 - loss 0.33613172 - samples/sec: 2.79 - lr: 0.000001\n",
            "2022-06-17 00:32:48,174 epoch 38 - iter 14/78 - loss 0.24786245 - samples/sec: 2.91 - lr: 0.000001\n",
            "2022-06-17 00:32:50,833 epoch 38 - iter 21/78 - loss 0.17839305 - samples/sec: 2.63 - lr: 0.000001\n",
            "2022-06-17 00:32:53,428 epoch 38 - iter 28/78 - loss 0.18990663 - samples/sec: 2.70 - lr: 0.000001\n",
            "2022-06-17 00:32:56,043 epoch 38 - iter 35/78 - loss 0.18910343 - samples/sec: 2.68 - lr: 0.000001\n",
            "2022-06-17 00:32:58,600 epoch 38 - iter 42/78 - loss 0.15655316 - samples/sec: 2.74 - lr: 0.000001\n",
            "2022-06-17 00:33:01,108 epoch 38 - iter 49/78 - loss 0.16572551 - samples/sec: 2.79 - lr: 0.000001\n",
            "2022-06-17 00:33:03,558 epoch 38 - iter 56/78 - loss 0.15649958 - samples/sec: 2.86 - lr: 0.000001\n",
            "2022-06-17 00:33:06,049 epoch 38 - iter 63/78 - loss 0.14581248 - samples/sec: 2.81 - lr: 0.000001\n",
            "2022-06-17 00:33:08,675 epoch 38 - iter 70/78 - loss 0.14023389 - samples/sec: 2.67 - lr: 0.000001\n",
            "2022-06-17 00:33:11,248 epoch 38 - iter 77/78 - loss 0.14135007 - samples/sec: 2.72 - lr: 0.000001\n",
            "2022-06-17 00:33:11,590 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:33:11,591 EPOCH 38 done: loss 0.1419 - lr 0.000001\n",
            "2022-06-17 00:33:11,597 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:33:11,599 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:33:14,184 epoch 39 - iter 7/78 - loss 0.39432562 - samples/sec: 2.71 - lr: 0.000001\n",
            "2022-06-17 00:33:16,684 epoch 39 - iter 14/78 - loss 0.24445600 - samples/sec: 2.80 - lr: 0.000001\n",
            "2022-06-17 00:33:19,147 epoch 39 - iter 21/78 - loss 0.17952189 - samples/sec: 2.84 - lr: 0.000001\n",
            "2022-06-17 00:33:21,627 epoch 39 - iter 28/78 - loss 0.21788586 - samples/sec: 2.83 - lr: 0.000001\n",
            "2022-06-17 00:33:24,181 epoch 39 - iter 35/78 - loss 0.21746711 - samples/sec: 2.74 - lr: 0.000001\n",
            "2022-06-17 00:33:26,688 epoch 39 - iter 42/78 - loss 0.18539082 - samples/sec: 2.79 - lr: 0.000001\n",
            "2022-06-17 00:33:29,231 epoch 39 - iter 49/78 - loss 0.15654391 - samples/sec: 2.76 - lr: 0.000001\n",
            "2022-06-17 00:33:31,695 epoch 39 - iter 56/78 - loss 0.15100562 - samples/sec: 2.84 - lr: 0.000001\n",
            "2022-06-17 00:33:34,109 epoch 39 - iter 63/78 - loss 0.14715154 - samples/sec: 2.90 - lr: 0.000001\n",
            "2022-06-17 00:33:36,560 epoch 39 - iter 70/78 - loss 0.13554961 - samples/sec: 2.86 - lr: 0.000001\n",
            "2022-06-17 00:33:39,058 epoch 39 - iter 77/78 - loss 0.12773765 - samples/sec: 2.80 - lr: 0.000001\n",
            "2022-06-17 00:33:39,402 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:33:39,406 EPOCH 39 done: loss 0.1240 - lr 0.000001\n",
            "2022-06-17 00:33:39,410 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:33:39,412 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:33:41,895 epoch 40 - iter 7/78 - loss 0.27428644 - samples/sec: 2.83 - lr: 0.000001\n",
            "2022-06-17 00:33:44,469 epoch 40 - iter 14/78 - loss 0.20760120 - samples/sec: 2.72 - lr: 0.000001\n",
            "2022-06-17 00:33:46,883 epoch 40 - iter 21/78 - loss 0.22233016 - samples/sec: 2.90 - lr: 0.000001\n",
            "2022-06-17 00:33:49,533 epoch 40 - iter 28/78 - loss 0.18734531 - samples/sec: 2.64 - lr: 0.000001\n",
            "2022-06-17 00:33:52,014 epoch 40 - iter 35/78 - loss 0.15780293 - samples/sec: 2.83 - lr: 0.000001\n",
            "2022-06-17 00:33:54,551 epoch 40 - iter 42/78 - loss 0.17307719 - samples/sec: 2.76 - lr: 0.000001\n",
            "2022-06-17 00:33:57,141 epoch 40 - iter 49/78 - loss 0.16106520 - samples/sec: 2.70 - lr: 0.000001\n",
            "2022-06-17 00:33:59,641 epoch 40 - iter 56/78 - loss 0.15830591 - samples/sec: 2.80 - lr: 0.000001\n",
            "2022-06-17 00:34:02,238 epoch 40 - iter 63/78 - loss 0.16732666 - samples/sec: 2.70 - lr: 0.000001\n",
            "2022-06-17 00:34:04,684 epoch 40 - iter 70/78 - loss 0.16728802 - samples/sec: 2.86 - lr: 0.000001\n",
            "2022-06-17 00:34:07,186 epoch 40 - iter 77/78 - loss 0.16301341 - samples/sec: 2.80 - lr: 0.000001\n",
            "2022-06-17 00:34:07,575 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:34:07,576 EPOCH 40 done: loss 0.1618 - lr 0.000001\n",
            "2022-06-17 00:34:07,582 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:34:07,584 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:34:10,106 epoch 41 - iter 7/78 - loss 0.32841883 - samples/sec: 2.79 - lr: 0.000001\n",
            "2022-06-17 00:34:12,655 epoch 41 - iter 14/78 - loss 0.22626756 - samples/sec: 2.75 - lr: 0.000001\n",
            "2022-06-17 00:34:15,236 epoch 41 - iter 21/78 - loss 0.18562871 - samples/sec: 2.71 - lr: 0.000001\n",
            "2022-06-17 00:34:17,881 epoch 41 - iter 28/78 - loss 0.15718507 - samples/sec: 2.65 - lr: 0.000001\n",
            "2022-06-17 00:34:20,427 epoch 41 - iter 35/78 - loss 0.15808925 - samples/sec: 2.75 - lr: 0.000001\n",
            "2022-06-17 00:34:23,088 epoch 41 - iter 42/78 - loss 0.14360075 - samples/sec: 2.63 - lr: 0.000001\n",
            "2022-06-17 00:34:25,582 epoch 41 - iter 49/78 - loss 0.14466506 - samples/sec: 2.81 - lr: 0.000001\n",
            "2022-06-17 00:34:28,214 epoch 41 - iter 56/78 - loss 0.13991881 - samples/sec: 2.66 - lr: 0.000001\n",
            "2022-06-17 00:34:30,886 epoch 41 - iter 63/78 - loss 0.13823005 - samples/sec: 2.62 - lr: 0.000001\n",
            "2022-06-17 00:34:33,369 epoch 41 - iter 70/78 - loss 0.13027936 - samples/sec: 2.82 - lr: 0.000001\n",
            "2022-06-17 00:34:35,845 epoch 41 - iter 77/78 - loss 0.13820243 - samples/sec: 2.83 - lr: 0.000001\n",
            "2022-06-17 00:34:36,243 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:34:36,245 EPOCH 41 done: loss 0.1367 - lr 0.000001\n",
            "2022-06-17 00:34:36,252 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:34:36,255 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:34:38,744 epoch 42 - iter 7/78 - loss 0.12226231 - samples/sec: 2.82 - lr: 0.000001\n",
            "2022-06-17 00:34:41,407 epoch 42 - iter 14/78 - loss 0.10002070 - samples/sec: 2.63 - lr: 0.000001\n",
            "2022-06-17 00:34:43,967 epoch 42 - iter 21/78 - loss 0.16633470 - samples/sec: 2.74 - lr: 0.000001\n",
            "2022-06-17 00:34:46,556 epoch 42 - iter 28/78 - loss 0.14093179 - samples/sec: 2.71 - lr: 0.000001\n",
            "2022-06-17 00:34:49,111 epoch 42 - iter 35/78 - loss 0.16619664 - samples/sec: 2.74 - lr: 0.000001\n",
            "2022-06-17 00:34:51,633 epoch 42 - iter 42/78 - loss 0.14452533 - samples/sec: 2.78 - lr: 0.000001\n",
            "2022-06-17 00:34:54,121 epoch 42 - iter 49/78 - loss 0.13720261 - samples/sec: 2.82 - lr: 0.000001\n",
            "2022-06-17 00:34:56,664 epoch 42 - iter 56/78 - loss 0.13028478 - samples/sec: 2.76 - lr: 0.000001\n",
            "2022-06-17 00:34:59,108 epoch 42 - iter 63/78 - loss 0.14052733 - samples/sec: 2.87 - lr: 0.000001\n",
            "2022-06-17 00:35:01,616 epoch 42 - iter 70/78 - loss 0.14029532 - samples/sec: 2.79 - lr: 0.000001\n",
            "2022-06-17 00:35:04,249 epoch 42 - iter 77/78 - loss 0.13770113 - samples/sec: 2.66 - lr: 0.000001\n",
            "2022-06-17 00:35:04,592 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:35:04,594 EPOCH 42 done: loss 0.1406 - lr 0.000001\n",
            "2022-06-17 00:35:04,599 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:35:04,604 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:35:07,211 epoch 43 - iter 7/78 - loss 0.16708982 - samples/sec: 2.69 - lr: 0.000001\n",
            "2022-06-17 00:35:09,747 epoch 43 - iter 14/78 - loss 0.12938157 - samples/sec: 2.76 - lr: 0.000001\n",
            "2022-06-17 00:35:12,279 epoch 43 - iter 21/78 - loss 0.10847839 - samples/sec: 2.77 - lr: 0.000001\n",
            "2022-06-17 00:35:14,905 epoch 43 - iter 28/78 - loss 0.11339724 - samples/sec: 2.67 - lr: 0.000001\n",
            "2022-06-17 00:35:17,382 epoch 43 - iter 35/78 - loss 0.12252684 - samples/sec: 2.83 - lr: 0.000001\n",
            "2022-06-17 00:35:19,949 epoch 43 - iter 42/78 - loss 0.10856103 - samples/sec: 2.73 - lr: 0.000001\n",
            "2022-06-17 00:35:22,396 epoch 43 - iter 49/78 - loss 0.11309826 - samples/sec: 2.86 - lr: 0.000001\n",
            "2022-06-17 00:35:24,925 epoch 43 - iter 56/78 - loss 0.11592321 - samples/sec: 2.77 - lr: 0.000001\n",
            "2022-06-17 00:35:27,397 epoch 43 - iter 63/78 - loss 0.12220534 - samples/sec: 2.83 - lr: 0.000001\n",
            "2022-06-17 00:35:30,098 epoch 43 - iter 70/78 - loss 0.13050533 - samples/sec: 2.59 - lr: 0.000001\n",
            "2022-06-17 00:35:32,631 epoch 43 - iter 77/78 - loss 0.14198459 - samples/sec: 2.77 - lr: 0.000001\n",
            "2022-06-17 00:35:33,025 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:35:33,027 EPOCH 43 done: loss 0.1402 - lr 0.000001\n",
            "2022-06-17 00:35:33,032 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:35:33,036 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:35:35,515 epoch 44 - iter 7/78 - loss 0.10478041 - samples/sec: 2.83 - lr: 0.000001\n",
            "2022-06-17 00:35:38,200 epoch 44 - iter 14/78 - loss 0.14673949 - samples/sec: 2.61 - lr: 0.000001\n",
            "2022-06-17 00:35:40,882 epoch 44 - iter 21/78 - loss 0.10145440 - samples/sec: 2.61 - lr: 0.000001\n",
            "2022-06-17 00:35:43,402 epoch 44 - iter 28/78 - loss 0.10288245 - samples/sec: 2.78 - lr: 0.000001\n",
            "2022-06-17 00:35:46,010 epoch 44 - iter 35/78 - loss 0.11346522 - samples/sec: 2.69 - lr: 0.000001\n",
            "2022-06-17 00:35:48,648 epoch 44 - iter 42/78 - loss 0.11123982 - samples/sec: 2.66 - lr: 0.000001\n",
            "2022-06-17 00:35:51,240 epoch 44 - iter 49/78 - loss 0.12052960 - samples/sec: 2.70 - lr: 0.000001\n",
            "2022-06-17 00:35:53,824 epoch 44 - iter 56/78 - loss 0.13777481 - samples/sec: 2.71 - lr: 0.000001\n",
            "2022-06-17 00:35:56,345 epoch 44 - iter 63/78 - loss 0.14440892 - samples/sec: 2.78 - lr: 0.000001\n",
            "2022-06-17 00:35:58,982 epoch 44 - iter 70/78 - loss 0.15155554 - samples/sec: 2.66 - lr: 0.000001\n",
            "2022-06-17 00:36:01,532 epoch 44 - iter 77/78 - loss 0.14984817 - samples/sec: 2.75 - lr: 0.000001\n",
            "2022-06-17 00:36:01,927 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:36:01,929 EPOCH 44 done: loss 0.1488 - lr 0.000001\n",
            "2022-06-17 00:36:01,935 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:36:01,938 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:36:04,447 epoch 45 - iter 7/78 - loss 0.14666754 - samples/sec: 2.80 - lr: 0.000001\n",
            "2022-06-17 00:36:07,092 epoch 45 - iter 14/78 - loss 0.08823217 - samples/sec: 2.65 - lr: 0.000001\n",
            "2022-06-17 00:36:09,546 epoch 45 - iter 21/78 - loss 0.09650632 - samples/sec: 2.86 - lr: 0.000001\n",
            "2022-06-17 00:36:12,068 epoch 45 - iter 28/78 - loss 0.14534009 - samples/sec: 2.78 - lr: 0.000001\n",
            "2022-06-17 00:36:14,701 epoch 45 - iter 35/78 - loss 0.12752040 - samples/sec: 2.66 - lr: 0.000001\n",
            "2022-06-17 00:36:17,257 epoch 45 - iter 42/78 - loss 0.11680351 - samples/sec: 2.74 - lr: 0.000001\n",
            "2022-06-17 00:36:19,812 epoch 45 - iter 49/78 - loss 0.12600452 - samples/sec: 2.74 - lr: 0.000001\n",
            "2022-06-17 00:36:22,296 epoch 45 - iter 56/78 - loss 0.11681103 - samples/sec: 2.82 - lr: 0.000001\n",
            "2022-06-17 00:36:24,886 epoch 45 - iter 63/78 - loss 0.11243989 - samples/sec: 2.71 - lr: 0.000001\n",
            "2022-06-17 00:36:27,492 epoch 45 - iter 70/78 - loss 0.11775358 - samples/sec: 2.69 - lr: 0.000001\n",
            "2022-06-17 00:36:30,048 epoch 45 - iter 77/78 - loss 0.13260247 - samples/sec: 2.74 - lr: 0.000001\n",
            "2022-06-17 00:36:30,389 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:36:30,390 EPOCH 45 done: loss 0.1348 - lr 0.000001\n",
            "2022-06-17 00:36:30,394 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:36:30,402 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:36:33,008 epoch 46 - iter 7/78 - loss 0.16702304 - samples/sec: 2.69 - lr: 0.000001\n",
            "2022-06-17 00:36:35,507 epoch 46 - iter 14/78 - loss 0.16784269 - samples/sec: 2.80 - lr: 0.000001\n",
            "2022-06-17 00:36:38,069 epoch 46 - iter 21/78 - loss 0.20748860 - samples/sec: 2.73 - lr: 0.000001\n",
            "2022-06-17 00:36:40,730 epoch 46 - iter 28/78 - loss 0.18051442 - samples/sec: 2.63 - lr: 0.000001\n",
            "2022-06-17 00:36:43,320 epoch 46 - iter 35/78 - loss 0.18179228 - samples/sec: 2.70 - lr: 0.000001\n",
            "2022-06-17 00:36:45,825 epoch 46 - iter 42/78 - loss 0.16531425 - samples/sec: 2.80 - lr: 0.000000\n",
            "2022-06-17 00:36:48,248 epoch 46 - iter 49/78 - loss 0.15500694 - samples/sec: 2.89 - lr: 0.000000\n",
            "2022-06-17 00:36:50,701 epoch 46 - iter 56/78 - loss 0.14610281 - samples/sec: 2.86 - lr: 0.000000\n",
            "2022-06-17 00:36:53,345 epoch 46 - iter 63/78 - loss 0.14514606 - samples/sec: 2.65 - lr: 0.000000\n",
            "2022-06-17 00:36:55,893 epoch 46 - iter 70/78 - loss 0.15029426 - samples/sec: 2.75 - lr: 0.000000\n",
            "2022-06-17 00:36:58,430 epoch 46 - iter 77/78 - loss 0.14232746 - samples/sec: 2.76 - lr: 0.000000\n",
            "2022-06-17 00:36:58,834 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:36:58,836 EPOCH 46 done: loss 0.1444 - lr 0.000000\n",
            "2022-06-17 00:36:58,839 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:36:58,842 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:37:01,367 epoch 47 - iter 7/78 - loss 0.15214942 - samples/sec: 2.78 - lr: 0.000000\n",
            "2022-06-17 00:37:03,890 epoch 47 - iter 14/78 - loss 0.27775672 - samples/sec: 2.78 - lr: 0.000000\n",
            "2022-06-17 00:37:06,478 epoch 47 - iter 21/78 - loss 0.22347608 - samples/sec: 2.71 - lr: 0.000000\n",
            "2022-06-17 00:37:08,993 epoch 47 - iter 28/78 - loss 0.18800703 - samples/sec: 2.79 - lr: 0.000000\n",
            "2022-06-17 00:37:11,621 epoch 47 - iter 35/78 - loss 0.18469620 - samples/sec: 2.67 - lr: 0.000000\n",
            "2022-06-17 00:37:14,203 epoch 47 - iter 42/78 - loss 0.17209965 - samples/sec: 2.71 - lr: 0.000000\n",
            "2022-06-17 00:37:16,759 epoch 47 - iter 49/78 - loss 0.18966778 - samples/sec: 2.74 - lr: 0.000000\n",
            "2022-06-17 00:37:19,241 epoch 47 - iter 56/78 - loss 0.17030310 - samples/sec: 2.82 - lr: 0.000000\n",
            "2022-06-17 00:37:21,858 epoch 47 - iter 63/78 - loss 0.16578913 - samples/sec: 2.68 - lr: 0.000000\n",
            "2022-06-17 00:37:24,385 epoch 47 - iter 70/78 - loss 0.15562625 - samples/sec: 2.77 - lr: 0.000000\n",
            "2022-06-17 00:37:26,949 epoch 47 - iter 77/78 - loss 0.17277912 - samples/sec: 2.73 - lr: 0.000000\n",
            "2022-06-17 00:37:27,290 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:37:27,292 EPOCH 47 done: loss 0.1795 - lr 0.000000\n",
            "2022-06-17 00:37:27,299 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:37:27,300 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:37:29,833 epoch 48 - iter 7/78 - loss 0.10998436 - samples/sec: 2.77 - lr: 0.000000\n",
            "2022-06-17 00:37:32,337 epoch 48 - iter 14/78 - loss 0.18971137 - samples/sec: 2.80 - lr: 0.000000\n",
            "2022-06-17 00:37:34,948 epoch 48 - iter 21/78 - loss 0.13888386 - samples/sec: 2.68 - lr: 0.000000\n",
            "2022-06-17 00:37:37,382 epoch 48 - iter 28/78 - loss 0.15413255 - samples/sec: 2.88 - lr: 0.000000\n",
            "2022-06-17 00:37:39,904 epoch 48 - iter 35/78 - loss 0.13471096 - samples/sec: 2.78 - lr: 0.000000\n",
            "2022-06-17 00:37:42,427 epoch 48 - iter 42/78 - loss 0.12976096 - samples/sec: 2.78 - lr: 0.000000\n",
            "2022-06-17 00:37:45,084 epoch 48 - iter 49/78 - loss 0.15574741 - samples/sec: 2.64 - lr: 0.000000\n",
            "2022-06-17 00:37:47,622 epoch 48 - iter 56/78 - loss 0.15357163 - samples/sec: 2.76 - lr: 0.000000\n",
            "2022-06-17 00:37:50,110 epoch 48 - iter 63/78 - loss 0.14523316 - samples/sec: 2.82 - lr: 0.000000\n",
            "2022-06-17 00:37:52,677 epoch 48 - iter 70/78 - loss 0.16432664 - samples/sec: 2.73 - lr: 0.000000\n",
            "2022-06-17 00:37:55,214 epoch 48 - iter 77/78 - loss 0.15406175 - samples/sec: 2.76 - lr: 0.000000\n",
            "2022-06-17 00:37:55,551 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:37:55,553 EPOCH 48 done: loss 0.1578 - lr 0.000000\n",
            "2022-06-17 00:37:55,558 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:37:55,562 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:37:57,939 epoch 49 - iter 7/78 - loss 0.09101447 - samples/sec: 2.95 - lr: 0.000000\n",
            "2022-06-17 00:38:00,324 epoch 49 - iter 14/78 - loss 0.05496458 - samples/sec: 2.94 - lr: 0.000000\n",
            "2022-06-17 00:38:02,881 epoch 49 - iter 21/78 - loss 0.08441940 - samples/sec: 2.74 - lr: 0.000000\n",
            "2022-06-17 00:38:05,410 epoch 49 - iter 28/78 - loss 0.12057385 - samples/sec: 2.77 - lr: 0.000000\n",
            "2022-06-17 00:38:08,025 epoch 49 - iter 35/78 - loss 0.11342254 - samples/sec: 2.68 - lr: 0.000000\n",
            "2022-06-17 00:38:10,590 epoch 49 - iter 42/78 - loss 0.10934612 - samples/sec: 2.74 - lr: 0.000000\n",
            "2022-06-17 00:38:13,225 epoch 49 - iter 49/78 - loss 0.11822640 - samples/sec: 2.66 - lr: 0.000000\n",
            "2022-06-17 00:38:15,695 epoch 49 - iter 56/78 - loss 0.15839209 - samples/sec: 2.84 - lr: 0.000000\n",
            "2022-06-17 00:38:18,377 epoch 49 - iter 63/78 - loss 0.14699752 - samples/sec: 2.61 - lr: 0.000000\n",
            "2022-06-17 00:38:20,933 epoch 49 - iter 70/78 - loss 0.15671989 - samples/sec: 2.75 - lr: 0.000000\n",
            "2022-06-17 00:38:23,559 epoch 49 - iter 77/78 - loss 0.14800067 - samples/sec: 2.67 - lr: 0.000000\n",
            "2022-06-17 00:38:23,900 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:38:23,901 EPOCH 49 done: loss 0.1459 - lr 0.000000\n",
            "2022-06-17 00:38:23,906 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:38:23,913 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:38:26,461 epoch 50 - iter 7/78 - loss 0.15281503 - samples/sec: 2.75 - lr: 0.000000\n",
            "2022-06-17 00:38:28,938 epoch 50 - iter 14/78 - loss 0.15376557 - samples/sec: 2.83 - lr: 0.000000\n",
            "2022-06-17 00:38:31,500 epoch 50 - iter 21/78 - loss 0.14602801 - samples/sec: 2.74 - lr: 0.000000\n",
            "2022-06-17 00:38:33,936 epoch 50 - iter 28/78 - loss 0.14667172 - samples/sec: 2.88 - lr: 0.000000\n",
            "2022-06-17 00:38:36,472 epoch 50 - iter 35/78 - loss 0.14070497 - samples/sec: 2.76 - lr: 0.000000\n",
            "2022-06-17 00:38:39,055 epoch 50 - iter 42/78 - loss 0.13000608 - samples/sec: 2.71 - lr: 0.000000\n",
            "2022-06-17 00:38:41,690 epoch 50 - iter 49/78 - loss 0.11464785 - samples/sec: 2.66 - lr: 0.000000\n",
            "2022-06-17 00:38:44,260 epoch 50 - iter 56/78 - loss 0.15684895 - samples/sec: 2.73 - lr: 0.000000\n",
            "2022-06-17 00:38:46,821 epoch 50 - iter 63/78 - loss 0.14807194 - samples/sec: 2.74 - lr: 0.000000\n",
            "2022-06-17 00:38:49,415 epoch 50 - iter 70/78 - loss 0.13783162 - samples/sec: 2.70 - lr: 0.000000\n",
            "2022-06-17 00:38:51,992 epoch 50 - iter 77/78 - loss 0.14878327 - samples/sec: 2.72 - lr: 0.000000\n",
            "2022-06-17 00:38:52,331 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:38:52,334 EPOCH 50 done: loss 0.1464 - lr 0.000000\n",
            "2022-06-17 00:38:52,339 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 00:39:02,580 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 00:39:02,611 Testing using last state of model ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [00:00<00:00, 13.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-06-17 00:39:03,352 Evaluating as a multi-label problem: False\n",
            "2022-06-17 00:39:03,391 1.0\t0.9167\t0.9565\t0.9167\n",
            "2022-06-17 00:39:03,392 \n",
            "Results:\n",
            "- F-score (micro) 0.9565\n",
            "- F-score (macro) 0.9804\n",
            "- Accuracy 0.9167\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       value     1.0000    0.8889    0.9412         9\n",
            "        time     1.0000    1.0000    1.0000         2\n",
            "    location     1.0000    1.0000    1.0000         1\n",
            "\n",
            "   micro avg     1.0000    0.9167    0.9565        12\n",
            "   macro avg     1.0000    0.9630    0.9804        12\n",
            "weighted avg     1.0000    0.9167    0.9559        12\n",
            "\n",
            "2022-06-17 00:39:03,401 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'dev_loss_history': [],\n",
              " 'dev_score_history': [],\n",
              " 'test_score': 0.9565217391304348,\n",
              " 'train_loss_history': [2.722585264856087,\n",
              "  2.470999058935569,\n",
              "  2.1364900481636226,\n",
              "  1.848151976118036,\n",
              "  1.6379481499128812,\n",
              "  1.518113443476382,\n",
              "  1.337381136029366,\n",
              "  1.1499917338843075,\n",
              "  1.0001730969029177,\n",
              "  0.7410793297437388,\n",
              "  0.6573708765141356,\n",
              "  0.6162003181606555,\n",
              "  0.4340319993668261,\n",
              "  0.4341696045870066,\n",
              "  0.4007213225404633,\n",
              "  0.30042234880224067,\n",
              "  0.2975536773124858,\n",
              "  0.28709505285382914,\n",
              "  0.24107371452973927,\n",
              "  0.20050468981148606,\n",
              "  0.2401336455337912,\n",
              "  0.24329374690385036,\n",
              "  0.21551417591762653,\n",
              "  0.177431264928449,\n",
              "  0.1738303332843712,\n",
              "  0.13900103293242824,\n",
              "  0.15901276053910965,\n",
              "  0.16430658266920828,\n",
              "  0.15309569181420574,\n",
              "  0.15630163440193107,\n",
              "  0.17443185864020308,\n",
              "  0.1220006901083114,\n",
              "  0.1641782878566627,\n",
              "  0.20872237410305067,\n",
              "  0.15372303058118642,\n",
              "  0.19661230594553275,\n",
              "  0.1805420212465432,\n",
              "  0.1418951555182269,\n",
              "  0.12404439752025533,\n",
              "  0.16183435700280377,\n",
              "  0.13670893659056071,\n",
              "  0.1405934446169567,\n",
              "  0.14018813816230388,\n",
              "  0.1487644802487513,\n",
              "  0.1348436966392226,\n",
              "  0.1443875573074495,\n",
              "  0.1795242922647231,\n",
              "  0.15784567013626202,\n",
              "  0.14586057246769685,\n",
              "  0.14637319207161653]}"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#check the details of the trainer https://github.com/flairNLP/flair/blob/master/flair/trainers/trainer.py\n",
        "#It will print out the model details and the training accuracy and F1 score\n",
        "#The loss will also be printed out for each epoch\n",
        "#The path means where the model is saved for future loading\n",
        "trainer.fine_tune('resources/taggers/sota-ner-flair',\n",
        "              learning_rate=5.0e-6,\n",
        "              train_with_dev=True,\n",
        "              mini_batch_size=1,\n",
        "              mini_batch_chunk_size=1,\n",
        "              max_epochs=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hLksstNUTl4"
      },
      "source": [
        "# Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "tQjZ0ylxVCgi"
      },
      "outputs": [],
      "source": [
        "#import the packages\n",
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BStzRtYTvt8",
        "outputId": "8b3f9eb5-4e6d-45d6-deef-e17d37b00778"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-06-17 00:41:25,080 loading file resources/taggers/sota-ner-flair/final-model.pt\n",
            "2022-06-17 00:41:47,997 SequenceTagger predicts: Dictionary with 13 tags: O, S-value, B-value, E-value, I-value, S-location, B-location, E-location, I-location, S-time, B-time, E-time, I-time\n"
          ]
        }
      ],
      "source": [
        "#To load the trained model directly\n",
        "model = SequenceTagger.load('resources/taggers/sota-ner-flair/final-model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Qm1ciRhWb57",
        "outputId": "19f759fd-7956-4789-d8a8-f57dcd82f2a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: \"Enter email address to Email textbox admin @ gmail.com\" → [\"Email textbox\"/location, \"admin\"/value, \"@\"/value]\n"
          ]
        }
      ],
      "source": [
        "#Use the model\n",
        "#Demo\n",
        "sentence = Sentence(\"Enter email address to Email textbox admin@gmail.com\")\n",
        "model.predict(sentence)\n",
        "print(sentence.to_tagged_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_lTMTGAXkUx",
        "outputId": "43b7510e-c92b-46dd-93bb-d47afe521f58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: \"Wait for email to appear for 20s\" → [\"email\"/value, \"20s\"/time]\n"
          ]
        }
      ],
      "source": [
        "sentence = Sentence(\"Wait for email to appear for 20s\")\n",
        "model.predict(sentence)\n",
        "print(sentence.to_tagged_string())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "bert_sequence_tagger.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00eceaf352ca44409aa3f7b1f5a9679c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b2bedf9e2f84d8eafd850054d70c764": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f8a626f3fa94a7fa4cb257e965c5863": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6bd178ab1ef4480adfca55a3d0b8e88",
            "placeholder": "​",
            "style": "IPY_MODEL_20b769d011eb447080bd90bc373b6deb",
            "value": "Downloading: 100%"
          }
        },
        "0faf8b84b2764ba28b5789e5c9102670": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f281277d9db42348870be3a7e193ec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20b769d011eb447080bd90bc373b6deb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21ad1609d1e84e2991c0872d21302211": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2464d79d4ff44e4bb8352ebdd9ce6d2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdc2f872d9254f7298d79af4614e7627",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cba15c49e89149ed9de8f4bd40a6698e",
            "value": 5069051
          }
        },
        "2aca863784cc4db48be6cf18ad3c2942": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30f2156b6d0845158a37f38ed9d4854c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35293f9414c844659488474cac468b87": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3618de10e66d4d36a2d722264a43fb2e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3daab240581343be96014ea9b69b64e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e9486701051494aa3e07272092c01ff",
              "IPY_MODEL_a40f442c26b6484790eac008afab50ca",
              "IPY_MODEL_90bcb8820adc41cc9ca6e3ff35a6c7f0"
            ],
            "layout": "IPY_MODEL_0b2bedf9e2f84d8eafd850054d70c764"
          }
        },
        "4da03010fb6f4116b2b05c835835f4da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_984f383d4d4f46688e536635d3aef559",
            "max": 616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e15f98fbd40496680f68243df2c8312",
            "value": 616
          }
        },
        "4e15f98fbd40496680f68243df2c8312": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e6704c6b83e4300a8a72e276542b072": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfdec0f039454ba6bbdf57f381221234",
            "max": 9096718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b6de886d26934007ace4f7529b5d5b05",
            "value": 9096718
          }
        },
        "55f79b6251494023bf4c36a6a38e4e08": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "571775fba4bf458e8b7c8ee8647c4b45": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "582d072d25464fd4a9903d16d03a12e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cf55188ebc549b8a9699d1b09670ff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60c0e6a92c5143e9bd63729dc56df4f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "626b091c15eb45f09ff768bc1dc12549": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "690ef6034ac14d41802b26a4c928025b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d84aefd5c394a1ba14b71952ac1ccd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00eceaf352ca44409aa3f7b1f5a9679c",
            "placeholder": "​",
            "style": "IPY_MODEL_b3d08217411247998945b55ff053c9bb",
            "value": " 2.09G/2.09G [01:16&lt;00:00, 35.8MB/s]"
          }
        },
        "755d0a19e54044c0b29d4ff5fe79be20": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9635d2378c15480bb0b47891c031e2e6",
            "placeholder": "​",
            "style": "IPY_MODEL_30f2156b6d0845158a37f38ed9d4854c",
            "value": " 8.68M/8.68M [00:00&lt;00:00, 17.6MB/s]"
          }
        },
        "78c1f36532f648669a0c440ebd019f11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3618de10e66d4d36a2d722264a43fb2e",
            "max": 2244861551,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_626b091c15eb45f09ff768bc1dc12549",
            "value": 2244861551
          }
        },
        "8180beee4609430696e9e73ce1b8be8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b8046e01636949408734e0c11bb09331",
              "IPY_MODEL_78c1f36532f648669a0c440ebd019f11",
              "IPY_MODEL_6d84aefd5c394a1ba14b71952ac1ccd9"
            ],
            "layout": "IPY_MODEL_571775fba4bf458e8b7c8ee8647c4b45"
          }
        },
        "8451b60eb99c401aa85fcb46c737fb0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c93ec3228fae4458868098f4905ea13a",
            "placeholder": "​",
            "style": "IPY_MODEL_5cf55188ebc549b8a9699d1b09670ff3",
            "value": "Downloading: 100%"
          }
        },
        "86883fdbe0b44daea0dfc362d65e1970": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "897f670f9ce640869c71b5659849adbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e9486701051494aa3e07272092c01ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcd6b3f5666446da93b1ee4290c7cfa2",
            "placeholder": "​",
            "style": "IPY_MODEL_582d072d25464fd4a9903d16d03a12e4",
            "value": "Downloading: 100%"
          }
        },
        "90bcb8820adc41cc9ca6e3ff35a6c7f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba08420a176e4c3c8dffe5025475b9bd",
            "placeholder": "​",
            "style": "IPY_MODEL_60c0e6a92c5143e9bd63729dc56df4f4",
            "value": " 432M/432M [00:13&lt;00:00, 57.3MB/s]"
          }
        },
        "9635d2378c15480bb0b47891c031e2e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "984f383d4d4f46688e536635d3aef559": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0be565d90a84c909ea2241ae70aa3d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a40f442c26b6484790eac008afab50ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86883fdbe0b44daea0dfc362d65e1970",
            "max": 432176557,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_897f670f9ce640869c71b5659849adbe",
            "value": 432176557
          }
        },
        "a738ec6a28034e1db872297c9ca1ad8b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad7dc3f26fa343b18cbee3070bc28ce7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55f79b6251494023bf4c36a6a38e4e08",
            "placeholder": "​",
            "style": "IPY_MODEL_0faf8b84b2764ba28b5789e5c9102670",
            "value": " 4.83M/4.83M [00:00&lt;00:00, 8.89MB/s]"
          }
        },
        "b3d08217411247998945b55ff053c9bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6bd178ab1ef4480adfca55a3d0b8e88": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6de886d26934007ace4f7529b5d5b05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8046e01636949408734e0c11bb09331": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbea62b7f9ad46b1b41cea2a9f8d9862",
            "placeholder": "​",
            "style": "IPY_MODEL_1f281277d9db42348870be3a7e193ec6",
            "value": "Downloading: 100%"
          }
        },
        "ba08420a176e4c3c8dffe5025475b9bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcd6b3f5666446da93b1ee4290c7cfa2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be6cf05acb2f4cca96d9e3e3f51682dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c93ec3228fae4458868098f4905ea13a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cba15c49e89149ed9de8f4bd40a6698e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cbea62b7f9ad46b1b41cea2a9f8d9862": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d22a752e5ef146b7af184267986ded06": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8451b60eb99c401aa85fcb46c737fb0d",
              "IPY_MODEL_4da03010fb6f4116b2b05c835835f4da",
              "IPY_MODEL_f543edb9673e47c78271a037cbd554dd"
            ],
            "layout": "IPY_MODEL_be6cf05acb2f4cca96d9e3e3f51682dc"
          }
        },
        "d7e777c6e0244d469d8fe73780ee7614": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35293f9414c844659488474cac468b87",
            "placeholder": "​",
            "style": "IPY_MODEL_2aca863784cc4db48be6cf18ad3c2942",
            "value": "Downloading: 100%"
          }
        },
        "def12bfc548f4f8e9d338d6949bb57fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7e777c6e0244d469d8fe73780ee7614",
              "IPY_MODEL_4e6704c6b83e4300a8a72e276542b072",
              "IPY_MODEL_755d0a19e54044c0b29d4ff5fe79be20"
            ],
            "layout": "IPY_MODEL_a738ec6a28034e1db872297c9ca1ad8b"
          }
        },
        "dfdec0f039454ba6bbdf57f381221234": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e03ee3fd506e4f90826f272c298590a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f8a626f3fa94a7fa4cb257e965c5863",
              "IPY_MODEL_2464d79d4ff44e4bb8352ebdd9ce6d2b",
              "IPY_MODEL_ad7dc3f26fa343b18cbee3070bc28ce7"
            ],
            "layout": "IPY_MODEL_690ef6034ac14d41802b26a4c928025b"
          }
        },
        "f543edb9673e47c78271a037cbd554dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21ad1609d1e84e2991c0872d21302211",
            "placeholder": "​",
            "style": "IPY_MODEL_a0be565d90a84c909ea2241ae70aa3d4",
            "value": " 616/616 [00:00&lt;00:00, 15.2kB/s]"
          }
        },
        "fdc2f872d9254f7298d79af4614e7627": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
