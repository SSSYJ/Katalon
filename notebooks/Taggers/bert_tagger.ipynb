{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_tagger.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Reference: https://towardsdatascience.com/named-entity-recognition-with-bert-in-pytorch-a454405e0b6a"
      ],
      "metadata": {
        "id": "UEFv3NKurA49"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "3yDN347uHXsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGteDEb3W3OL",
        "outputId": "cf75053a-9f2a-4a3e-8a88-b0283b2b2826"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizerFast, BertForTokenClassification\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import SGD\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "PQaLS6CeV3-b"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FW2Avk_nECSa",
        "outputId": "314402f5-c13c-47b2-ab37-748a005bf64c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Please update the file path here\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/data/capstone/anno_14_tc.csv'"
      ],
      "metadata": {
        "id": "XMPcUYUxECVU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "IkH946qg_-x4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load in data"
      ],
      "metadata": {
        "id": "LfPryO18JyqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(file_path)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "s_BnbPV4WEag",
        "outputId": "2e6a6543-8776-493c-efeb-0fdb49b0c3c6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Word IOB-tag\n",
              "0       S1       *\n",
              "1    Enter       O\n",
              "2    email       O\n",
              "3  address       O\n",
              "4       to       O"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b9f59f2-a9cb-434f-b918-a689c4763fab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>IOB-tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>S1</td>\n",
              "      <td>*</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Enter</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>email</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>address</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>to</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b9f59f2-a9cb-434f-b918-a689c4763fab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7b9f59f2-a9cb-434f-b918-a689c4763fab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7b9f59f2-a9cb-434f-b918-a689c4763fab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reformat dataset"
      ],
      "metadata": {
        "id": "F5x0OHml5vCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sents -- list of tuples (sentence, tags)\n",
        "sents = []\n",
        "sent, tags = [], []\n",
        "for idx, row in df.iterrows():\n",
        "  word, tag = row['Word'], row['IOB-tag']\n",
        "  if tag == '*':\n",
        "    if len(sent) > 0:\n",
        "        # sent = ' '.join(sent)\n",
        "        sents.append((sent, tags))\n",
        "        sent, tags = [], []\n",
        "    else:\n",
        "        continue\n",
        "  else:\n",
        "    sent.append(word)\n",
        "    tags.append(tag)"
      ],
      "metadata": {
        "id": "LJgyFB2j3l5-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter - Max length\n",
        "MAX_LENGTH = max(len(sent) for sent, _ in sents)\n",
        "MAX_LENGTH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCeN5eH_ZmzC",
        "outputId": "b138b333-64fd-4693-9673-092d539906cd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tags\n",
        "tags = df['IOB-tag'].values.tolist()\n",
        "unique_tags = set(tags) - set('*')\n",
        "\n",
        "tags2ids = {k: v for v, k in enumerate(sorted(unique_tags))}\n",
        "ids2tags = {v: k for v, k in enumerate(sorted(unique_tags))}\n",
        "\n",
        "print(tags2ids)\n",
        "print(ids2tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHY_vFFUkB3C",
        "outputId": "d59b6f54-5cc8-45c6-97c3-151b02bf83d4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'B-location': 0, 'B-time': 1, 'B-value': 2, 'I-location': 3, 'I-time': 4, 'I-value': 5, 'O': 6}\n",
            "{0: 'B-location', 1: 'B-time', 2: 'B-value', 3: 'I-location', 4: 'I-time', 5: 'I-value', 6: 'O'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenization\n",
        "\n"
      ],
      "metadata": {
        "id": "eIDMYyIXXLSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')"
      ],
      "metadata": {
        "id": "b742ycE3XPDa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Try tokenization with one example"
      ],
      "metadata": {
        "id": "QmvxPDNNqnfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ' '.join(sents[1][0])"
      ],
      "metadata": {
        "id": "_05wAR407Go4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text_tokenized = tokenizer(' '.join(sents[1][0]), padding='max_length', max_length=MAX_LENGTH, return_tensors=\"pt\")\n",
        "# text_tokenized['input_ids']"
      ],
      "metadata": {
        "id": "0XaWH_qOaNYX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer.convert_ids_to_tokens(text_tokenized[\"input_ids\"][0])"
      ],
      "metadata": {
        "id": "ncRn3NmZg_Qk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word_ids = text_tokenized.word_ids()\n",
        "# print(tokenizer.convert_ids_to_tokens(text_tokenized[\"input_ids\"][0]))\n",
        "# print(word_ids)"
      ],
      "metadata": {
        "id": "9Z7iXAWbhHJC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Align tags to tokenized texts"
      ],
      "metadata": {
        "id": "-MqlfVrxxHob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def align_label(texts, labels):\n",
        "    tokenized_inputs = tokenizer(texts, padding='max_length', max_length=MAX_LENGTH)\n",
        "\n",
        "    word_ids = tokenized_inputs.word_ids()\n",
        "\n",
        "    previous_word_idx = None\n",
        "    label_ids = []\n",
        "\n",
        "    for word_idx in word_ids:\n",
        "\n",
        "        if word_idx is None:\n",
        "            label_ids.append(-100)\n",
        "\n",
        "        elif word_idx != previous_word_idx:\n",
        "            try:\n",
        "                label_ids.append(tags2ids[labels[word_idx]])\n",
        "            except:\n",
        "                label_ids.append(-100)\n",
        "        else:\n",
        "            try:\n",
        "                label_ids.append(tags2ids[labels[word_idx]])\n",
        "            except:\n",
        "                label_ids.append(-100)\n",
        "        previous_word_idx = word_idx\n",
        "\n",
        "    return label_ids"
      ],
      "metadata": {
        "id": "Os_zrHglhW_1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Try align tags for one"
      ],
      "metadata": {
        "id": "6vBhwREwq0xC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print(tokenizer.convert_ids_to_tokens(text_tokenized[\"input_ids\"][0]))\n",
        "# print(align_label(' '.join(sents[1][0]), sents[1][1]))"
      ],
      "metadata": {
        "id": "CAHHsAMfoy-W"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Class"
      ],
      "metadata": {
        "id": "WSNBhpLHxSLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataSequence(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, tagged_sents):\n",
        "        self.sents = [' '.join(sent) for sent, _ in tagged_sents]\n",
        "        self.tags = [tags for _, tags in tagged_sents]\n",
        "        self.texts = [tokenizer(' '.join(sent), padding='max_length', max_length = MAX_LENGTH, return_tensors=\"pt\") for sent, _ in tagged_sents]\n",
        "        self.labels = [align_label(' '.join(sent), tag) for sent, tag in tagged_sents]\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_batch_data(self, idx):\n",
        "\n",
        "        return self.texts[idx]\n",
        "\n",
        "    def get_batch_labels(self, idx):\n",
        "\n",
        "        return torch.LongTensor(self.labels[idx])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        batch_data = self.get_batch_data(idx)\n",
        "        batch_labels = self.get_batch_labels(idx)\n",
        "\n",
        "        return batch_data, batch_labels"
      ],
      "metadata": {
        "id": "hYWKunhOnSEq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split train and test "
      ],
      "metadata": {
        "id": "whiwkGWm50Df"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set, dev_set = train_test_split(sents, test_size=0.2, shuffle=True)"
      ],
      "metadata": {
        "id": "2SJoPwOlJv6b"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_set), len(dev_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmW5Aaaw6ObV",
        "outputId": "c4b11bc2-54a7-46f1-bb34-c4d0abc5f4b0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NER Model"
      ],
      "metadata": {
        "id": "_yOO3GT66aOy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load pre-trained BERT model"
      ],
      "metadata": {
        "id": "Hq782fpK64XY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(BertModel, self).__init__()\n",
        "\n",
        "        self.bert = BertForTokenClassification.from_pretrained('bert-base-cased', num_labels=len(unique_tags))\n",
        "\n",
        "    def forward(self, input_id, mask, label):\n",
        "\n",
        "        output = self.bert(input_ids=input_id, attention_mask=mask, labels=label, return_dict=False)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "Dtia6npzmD76"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "kRXYgGt2vFpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(sys_spacy_data, gold_spacy_data):\n",
        "    precision, recall, fscore = 0, 0, 0\n",
        "\n",
        "    tp = 0\n",
        "    fp = 0\n",
        "    fn = 0\n",
        "\n",
        "    for sys_ex, gold_ex in zip(sys_spacy_data, gold_spacy_data):\n",
        "        gold_annotations = set([tuple(e) for e in gold_ex])\n",
        "        sys_annotations = set([tuple(e) for e in sys_ex])\n",
        "\n",
        "        tp += len(sys_annotations.intersection(gold_annotations))\n",
        "        fp += len(sys_annotations.difference(gold_annotations))\n",
        "        fn += len(gold_annotations.difference(sys_annotations))\n",
        "\n",
        "    if tp != 0:\n",
        "        recall = (tp/(tp+fn)) * 100\n",
        "        precision = (tp/(tp+fp)) * 100\n",
        "        fscore = 2*recall*precision/(recall+precision)\n",
        "\n",
        "    return precision, recall, fscore"
      ],
      "metadata": {
        "id": "kbgi2fRZIt-7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tagger"
      ],
      "metadata": {
        "id": "A7BZVGLWQzqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predict tags for sentences\n",
        "def align_word_ids(texts):\n",
        "  \n",
        "    tokenized_inputs = tokenizer(texts, padding='max_length', max_length=MAX_LENGTH)\n",
        "\n",
        "    word_ids = tokenized_inputs.word_ids()\n",
        "\n",
        "    previous_word_idx = None\n",
        "    label_ids = []\n",
        "\n",
        "    for word_idx in word_ids:\n",
        "\n",
        "        if word_idx is None:\n",
        "            label_ids.append(-100)\n",
        "\n",
        "        elif word_idx != previous_word_idx:\n",
        "            try:\n",
        "                label_ids.append(1)\n",
        "            except:\n",
        "                label_ids.append(-100)\n",
        "        else:\n",
        "          label_ids.append(-100)\n",
        "        previous_word_idx = word_idx\n",
        "\n",
        "    return label_ids\n",
        "\n",
        "\n",
        "def predict(model, sentence):\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "\n",
        "    text = tokenizer(sentence, padding='max_length', max_length = MAX_LENGTH, return_tensors=\"pt\")\n",
        "\n",
        "    mask = text['attention_mask'][0].unsqueeze(0).to(device)\n",
        "\n",
        "    input_id = text['input_ids'][0].unsqueeze(0).to(device)\n",
        "    label_ids = torch.Tensor(align_word_ids(sentence)).unsqueeze(0).to(device)\n",
        "\n",
        "    logits = model(input_id, mask, None)\n",
        "    logits_clean = logits[0][label_ids != -100]\n",
        "\n",
        "    predictions = logits_clean.argmax(dim=1).tolist()\n",
        "    prediction_label = [ids2tags[i] for i in predictions]\n",
        "    return prediction_label"
      ],
      "metadata": {
        "id": "_ylC_3k4LOsc"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train data"
      ],
      "metadata": {
        "id": "yf2as7n8-tAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(model, train_set, dev_set):\n",
        "\n",
        "    train_dataset = DataSequence(train_set)\n",
        "    dev_dataset = DataSequence(dev_set)\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, num_workers=4, batch_size=1, shuffle=True)\n",
        "    dev_dataloader = DataLoader(dev_dataset, num_workers=4, batch_size=1)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    optimizer = SGD(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "\n",
        "    best_acc = 0\n",
        "    best_loss = 1000\n",
        "\n",
        "    for epoch_num in range(EPOCHS):\n",
        "\n",
        "        total_acc_train = 0\n",
        "        total_loss_train = 0\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        for train_data, train_label in tqdm(train_dataloader):\n",
        "\n",
        "            train_label = train_label[0].to(device)\n",
        "            mask = train_data['attention_mask'][0].to(device)\n",
        "            input_id = train_data['input_ids'][0].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss, logits = model(input_id, mask, train_label)\n",
        "\n",
        "            logits_clean = logits[0][train_label != -100]\n",
        "            label_clean = train_label[train_label != -100]\n",
        "\n",
        "            predictions = logits_clean.argmax(dim=1)\n",
        "\n",
        "            acc = (predictions == label_clean).float().mean()\n",
        "            total_acc_train += acc\n",
        "            total_loss_train += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        predictions = [predict(model, sent) for sent in dev_dataset.sents]\n",
        "        p,r,f = evaluate(predictions, dev_dataset.tags)\n",
        "        print(\"  PRECISION: %.2f%%, RECALL: %.2f%%, F-SCORE: %.2f%%\" % (p,r,f))"
      ],
      "metadata": {
        "id": "yPQFRzg4mgs7"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "LEARNING_RATE = 1e-2\n",
        "EPOCHS = 5\n",
        "\n",
        "model = BertModel()\n",
        "train_loop(model, train_set, dev_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FG9Rr3o6mnzB",
        "outputId": "59c9334a-b995-4d2d-cc73-6508a110ff4f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 69/69 [00:06<00:00,  9.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  PRECISION: 94.34%, RECALL: 86.21%, F-SCORE: 90.09%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [00:03<00:00, 17.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  PRECISION: 98.15%, RECALL: 91.38%, F-SCORE: 94.64%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [00:03<00:00, 22.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  PRECISION: 100.00%, RECALL: 96.55%, F-SCORE: 98.25%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [00:03<00:00, 22.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  PRECISION: 95.08%, RECALL: 100.00%, F-SCORE: 97.48%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [00:03<00:00, 22.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  PRECISION: 100.00%, RECALL: 100.00%, F-SCORE: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save model"
      ],
      "metadata": {
        "id": "l-yB0Q7rhQTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/drive/MyDrive/Colab Notebooks/ckpt/katalon-bert-tagger.pt'\n",
        "torch.save(model.state_dict(), model_path)"
      ],
      "metadata": {
        "id": "UFxuHreThTKW"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load model"
      ],
      "metadata": {
        "id": "SR0l_gCvj2uQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertModel()\n",
        "model.load_state_dict(torch.load(model_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2UKM1cZiLAO",
        "outputId": "1af146fe-8040-4817-f66f-0314fd9ba9d6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results on Dev set"
      ],
      "metadata": {
        "id": "GASHWGRWMYpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for sent, gold_tags in dev_set: \n",
        "    sent = ' '.join(sent)\n",
        "    sys = predict(model, sent)\n",
        "    print(sent)\n",
        "    print('Predict: ')\n",
        "    print(sys)\n",
        "    print('Gold: ')\n",
        "    print(gold_tags)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXrlQXvXvUGh",
        "outputId": "5cfdbb48-6479-461b-d75d-9d3d74541379"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Click submit button\n",
            "Predict: \n",
            "['O', 'B-value', 'I-value']\n",
            "Gold: \n",
            "['O', 'B-value', 'I-value']\n",
            "\n",
            "Click submit button\n",
            "Predict: \n",
            "['O', 'B-value', 'I-value']\n",
            "Gold: \n",
            "['O', 'B-value', 'I-value']\n",
            "\n",
            "Click button Create Library\n",
            "Predict: \n",
            "['O', 'O', 'B-value', 'I-value']\n",
            "Gold: \n",
            "['O', 'O', 'B-value', 'I-value']\n",
            "\n",
            "Click button Submit\n",
            "Predict: \n",
            "['O', 'O', 'B-value']\n",
            "Gold: \n",
            "['O', 'O', 'B-value']\n",
            "\n",
            "Verify create library button appears\n",
            "Predict: \n",
            "['O', 'B-value', 'I-value', 'I-value', 'O']\n",
            "Gold: \n",
            "['O', 'B-value', 'I-value', 'I-value', 'O']\n",
            "\n",
            "Enter password to Password textbox Admin@123\n",
            "Predict: \n",
            "['O', 'O', 'O', 'B-location', 'I-location', 'B-value', 'B-value', 'B-value']\n",
            "Gold: \n",
            "['O', 'O', 'O', 'B-location', 'I-location', 'B-value']\n",
            "\n",
            "Click submit button\n",
            "Predict: \n",
            "['O', 'B-value', 'I-value']\n",
            "Gold: \n",
            "['O', 'B-value', 'I-value']\n",
            "\n",
            "Verify the add question button appears\n",
            "Predict: \n",
            "['O', 'O', 'B-value', 'I-value', 'I-value', 'O']\n",
            "Gold: \n",
            "['O', 'O', 'B-value', 'I-value', 'I-value', 'O']\n",
            "\n",
            "Get password error message\n",
            "Predict: \n",
            "['O', 'B-value', 'I-value', 'I-value']\n",
            "Gold: \n",
            "['O', 'B-value', 'I-value', 'I-value']\n",
            "\n",
            "Verify that the invalid message text is This field is required.\n",
            "Predict: \n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-value', 'I-value', 'I-value', 'I-value', 'O']\n",
            "Gold: \n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-value', 'I-value', 'I-value', 'I-value']\n",
            "\n",
            "Click library name with rely on name with test library name\n",
            "Predict: \n",
            "['O', 'B-value', 'I-value', 'I-value', 'I-value', 'I-value', 'I-value', 'I-value', 'B-value', 'I-value', 'I-value']\n",
            "Gold: \n",
            "['O', 'B-value', 'I-value', 'I-value', 'I-value', 'I-value', 'I-value', 'I-value', 'I-value', 'I-value', 'I-value']\n",
            "\n",
            "Wait for success message text to be present for 20 s\n",
            "Predict: \n",
            "['O', 'O', 'B-value', 'I-value', 'I-value', 'O', 'O', 'O', 'O', 'B-time', 'I-time']\n",
            "Gold: \n",
            "['O', 'O', 'B-value', 'I-value', 'I-value', 'O', 'O', 'O', 'O', 'B-time', 'I-time']\n",
            "\n",
            "Get invalid message text\n",
            "Predict: \n",
            "['O', 'B-value', 'I-value', 'I-value']\n",
            "Gold: \n",
            "['O', 'B-value', 'I-value', 'I-value']\n",
            "\n",
            "Click Change Password link\n",
            "Predict: \n",
            "['O', 'B-value', 'B-value', 'I-value']\n",
            "Gold: \n",
            "['O', 'B-value', 'I-value', 'I-value']\n",
            "\n",
            "Enter new password to new password text box Admin@1234\n",
            "Predict: \n",
            "['O', 'O', 'O', 'O', 'B-location', 'I-location', 'I-location', 'I-location', 'B-value', 'B-value', 'B-value']\n",
            "Gold: \n",
            "['O', 'O', 'O', 'O', 'B-location', 'I-location', 'I-location', 'I-location', 'B-value']\n",
            "\n",
            "Input update library name to library name textbox\n",
            "Predict: \n",
            "['O', 'B-value', 'I-value', 'I-value', 'O', 'B-location', 'I-location', 'I-location']\n",
            "Gold: \n",
            "['O', 'B-value', 'I-value', 'I-value', 'O', 'B-location', 'I-location', 'I-location']\n",
            "\n",
            "Enter new password again to confirm password Admin@1234\n",
            "Predict: \n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-value', 'B-value', 'B-value']\n",
            "Gold: \n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-value']\n",
            "\n",
            "Click button Add Library\n",
            "Predict: \n",
            "['O', 'O', 'B-value', 'I-value']\n",
            "Gold: \n",
            "['O', 'O', 'B-value', 'I-value']\n",
            "\n"
          ]
        }
      ]
    }
  ]
}